metric_name,metric_type,interval,unit_name,per_unit_name,description,orientation,integration,short_name,curated_metric,sample_tags
nvidia_nim.e2e_request_latency.seconds.bucket,count,,,,The observations of end to end request latency bucketed by seconds.,0,nvidia_nim,,,
nvidia_nim.e2e_request_latency.seconds.count,count,,,,The total number of observations of end to end request latency.,0,nvidia_nim,,,
nvidia_nim.e2e_request_latency.seconds.sum,count,,second,,The sum of end to end request latency in seconds.,0,nvidia_nim,,,
nvidia_nim.generation_tokens.count,count,,token,,Number of generation tokens processed.,0,nvidia_nim,,,
nvidia_nim.gpu_cache_usage_percent,gauge,,fraction,,GPU KV-cache usage. 1 means 100 percent usage.,0,nvidia_nim,,,
nvidia_nim.num_request.max,gauge,,request,,The max number of concurrently running requests.,0,nvidia_nim,,,
nvidia_nim.num_requests.running,gauge,,request,,Number of requests currently running on GPU.,0,nvidia_nim,,,
nvidia_nim.num_requests.waiting,gauge,,request,,Number of requests waiting.,0,nvidia_nim,,,
nvidia_nim.process.cpu_seconds.count,count,,second,,Total user and system CPU time spent in seconds.,0,nvidia_nim,,,
nvidia_nim.process.max_fds,gauge,,file,,Maximum number of open file descriptors.,0,nvidia_nim,,,
nvidia_nim.process.open_fds,gauge,,file,,Number of open file descriptors.,0,nvidia_nim,,,
nvidia_nim.process.resident_memory_bytes,gauge,,byte,,Resident memory size in bytes.,0,nvidia_nim,,,
nvidia_nim.process.start_time_seconds,gauge,,second,,Time in seconds since process started.,0,nvidia_nim,,,
nvidia_nim.process.virtual_memory_bytes,gauge,,byte,,Virtual memory size in bytes.,0,nvidia_nim,,,
nvidia_nim.prompt_tokens.count,count,,token,,Number of prefill tokens processed.,0,nvidia_nim,,,
nvidia_nim.python.gc.collections.count,count,,,,Number of times this generation was collected.,0,nvidia_nim,,,
nvidia_nim.python.gc.objects.collected.count,count,,,,Objects collected during GC.,0,nvidia_nim,,,
nvidia_nim.python.gc.objects.uncollectable.count,count,,,,Uncollectable objects found during GC.,0,nvidia_nim,,,
nvidia_nim.python.info,gauge,,,,Python platform information.,0,nvidia_nim,,,
nvidia_nim.request.failure.count,count,,request,,The count of failed requests.,0,nvidia_nim,,,
nvidia_nim.request.finish.count,count,,request,,The count of finished requests.,0,nvidia_nim,,,
nvidia_nim.request.generation_tokens.bucket,count,,,,Number of generation tokens processed.,0,nvidia_nim,,,
nvidia_nim.request.generation_tokens.count,count,,,,Number of generation tokens processed.,0,nvidia_nim,,,
nvidia_nim.request.generation_tokens.sum,count,,token,,Number of generation tokens processed.,0,nvidia_nim,,,
nvidia_nim.request.prompt_tokens.bucket,count,,,,Number of prefill tokens processed.,0,nvidia_nim,,,
nvidia_nim.request.prompt_tokens.count,count,,,,Number of prefill tokens processed.,0,nvidia_nim,,,
nvidia_nim.request.prompt_tokens.sum,count,,token,,Number of prefill tokens processed.,0,nvidia_nim,,,
nvidia_nim.request.success.count,count,,,,Count of successfully processed requests.,0,nvidia_nim,,,
nvidia_nim.time_per_output_token.seconds.bucket,count,,,,The observations of time per output token bucketed by seconds.,0,nvidia_nim,,,
nvidia_nim.time_per_output_token.seconds.count,count,,,,The total number of observations of time per output token.,0,nvidia_nim,,,
nvidia_nim.time_per_output_token.seconds.sum,count,,second,,The sum of time per output token in seconds.,0,nvidia_nim,,,
nvidia_nim.time_to_first_token.seconds.bucket,count,,,,The observations of time to first token bucketed by seconds.,0,nvidia_nim,,,
nvidia_nim.time_to_first_token.seconds.count,count,,,,The total number of observations of time to first token.,0,nvidia_nim,,,
nvidia_nim.time_to_first_token.seconds.sum,count,,second,,The sum of time to first token in seconds.,0,nvidia_nim,,,