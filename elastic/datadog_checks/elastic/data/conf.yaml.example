## All options defined here are available to all instances.
#
init_config:

    ## @param proxy - mapping - optional
    ## Set HTTP or HTTPS proxies for all instances. Use the `no_proxy` list
    ## to specify hosts that must bypass proxies.
    ##
    ## The SOCKS protocol is also supported like so:
    ##
    ##   socks5://user:pass@host:port
    ##
    ## Using the scheme `socks5` causes the DNS resolution to happen on the
    ## client, rather than on the proxy server. This is in line with `curl`,
    ## which uses the scheme to decide whether to do the DNS resolution on
    ## the client or proxy. If you want to resolve the domains on the proxy
    ## server, use `socks5h` as the scheme.
    #
    # proxy:
    #   http: http://<PROXY_SERVER_FOR_HTTP>:<PORT>
    #   https: https://<PROXY_SERVER_FOR_HTTPS>:<PORT>
    #   no_proxy:
    #   - <HOSTNAME_1>
    #   - <HOSTNAME_2>

    ## @param skip_proxy - boolean - optional - default: false
    ## If set to `true`, this makes the check bypass any proxy
    ## settings enabled and attempt to reach services directly.
    #
    # skip_proxy: false

    ## @param timeout - number - optional - default: 10
    ## The timeout for connecting to services.
    #
    # timeout: 10

    ## @param service - string - optional
    ## Attach the tag `service:<SERVICE>` to every metric, event, and service check emitted by this integration.
    ##
    ## Additionally, this sets the default `service` for every log source.
    #
    # service: <SERVICE>

## Every instance is scheduled independently of the others.
#
instances:

    ## @param url - string - required
    ## The URL where elasticsearch accepts HTTP requests. This is used to
    ## fetch statistics from the nodes and information about the cluster health.
    #
  - url: http://localhost:9200

    ## @param node_name_as_host - boolean - optional - default: false
    ## If each machine only runs a single Elasticsearch node per cluster, you
    ## want to set each Elasticsearch `node.name` to the machine hostname. You may
    ## then set `node_name_as_host` to `true` to avoid duplicate hostnames.
    ## See: https://www.elastic.co/guide/en/elasticsearch/reference/current/node.name.html
    #
    # node_name_as_host: false

    ## @param cluster_stats - boolean - optional - default: false
    ## If your cluster is hosted externally (i.e., you're not pointing to localhost)
    ## you must to set `cluster_stats` to true otherwise the check only
    ## submits metrics of the local node.
    ## This parameter was also called `is_external` and you can still use it but it
    ## is removed in Agent version 6+.
    #
    # cluster_stats: false

    ## @param detailed_index_stats - boolean - optional - default: false
    ## If you want to obtain index-specific stats, use this flag with `cluster_stats` and `pshard_stats` set to true.
    ## Without this flag you only get stats from `_all`.
    ## Do not use it if you are pointing to localhost.
    #
    # detailed_index_stats: false

    ## @param index_stats - boolean - optional - default: false
    ## Set "index_stats" to true to collect metrics for individual indices.
    #
    # index_stats: false

    ## @param pshard_stats - boolean - optional - default: false
    ## If you enable the "pshard_stats" flag, statistics over primary shards
    ## are collected by the check and sent to the backend with the
    ## 'elasticsearch.primary' prefix. It is particularly useful if you want to
    ## get certain metrics without taking replicas into account. For instance,
    ## 'elasticsearch.primaries.docs.count` gives you the total number of
    ## documents in your indexes WITHOUT counting duplicates due to the existence
    ## of replica shards in your ES cluster.
    #
    # pshard_stats: false

    ## @param slm_stats - boolean - optional - default: false
    ## Set "slm_stats" to true to collect statistics about Snapshot Lifcycle Management.
    ## The user must have the `read_slm` cluster privilege to get these metrics.
    #
    # slm_stats: false

    ## @param pshard_graceful_timeout - boolean - optional - default: false
    ## Continue gracefully if pshard stats TO
    #
    # pshard_graceful_timeout: false

    ## @param pending_task_stats - boolean - optional - default: true
    ## It specifies whether to collect data exposed by the `pending_tasks` cluster endpoint.
    ## Ref: https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-pending.html
    ## Some managed ElasticSearch services (e.g. AWS ElasticSearch) do not expose this endpoint.
    ## Set `pending_task_stats` to false if you use such a service.
    #
    # pending_task_stats: true

    ## @param cat_allocation_stats - boolean - optional - default: false
    ## Enable to collect Elastic Cat Allocation metrics. Available only for Elasticsearch 5.0 or higher.
    ## Ref: https://www.elastic.co/guide/en/elasticsearch/reference/current/cat-allocation.html.
    #
    # cat_allocation_stats: false

    ## @param admin_forwarder - boolean - optional - default: false
    ## It is used to signify a URL that includes a context root
    ## needed for a forwarder application to access Elasticsearch REST services for example
    ## https://www.ibm.com/support/knowledgecenter/SSFTN5_8.5.6/com.ibm.wbpm.main.doc/topics/tadm_fps_esearch.html
    #
    # admin_forwarder: false

    ## @param gc_collectors_as_rate - boolean - optional - default: false
    ## Submit `jvm.gc.collectors` metrics as rate.
    ## Note: Only for ES versions 0.9.10 or higher.
    #
    # gc_collectors_as_rate: false

    ## @param disable_legacy_cluster_tag - boolean - optional - default: false
    ## Enable to stop submitting the tag `cluster_name`, which has been renamed to `elastic_cluster`.
    #
    disable_legacy_cluster_tag: true

    ## @param custom_queries - list of mappings - optional
    ## Run custom queries for Elasticsearch. Each custom query endpoint can collect multiple metrics and tags.
    ## Note: Each custom query requires an `endpoint`, `data_path`, and `columns` parameter. Each `columns` parameter
    ## should have at least one value containing `name` and `value_path`.
    ##
    ## Each query can have the following parameters:
    ##
    ## 1. endpoint - The Elasticsearch API endpoint to query.
    ##
    ## 2. data_path - The JSON path up to, but not including, the metric. For example, if querying for size of parent
    ##                circuit breaker, the full path is 'breakers.parent.estimated_size_in_bytes', which means the
    ##                `data_path` is 'breakers.parent'. `data_path` cannot contain any wildcards, so accessing data
    ##                indexed by ID (such as node or index) is not possible.
    ##
    ## 3. columns - The list representing the data to be collected from the JSON query. There are two required pieces
    ##              of data:
    ##                a. value_path - This is the JSON path from the `data_path` to the metric. This path may include
    ##                                string keys as well as list indices. For example, if querying for size of parent
    ##                                circuit breaker, the `value_path` is `estimated_size_in_bytes`.
    ##                b. name - The full metric name sent to Datadog. If `type` is `tag`, this column is considered a
    ##                          tag and applied to every metric collected by this particular query.
    ##
    ##                c. type (optional) - An optional parameter to designates the type of data sent. Possible values
    ##                                     for `type` include `gauge`, `monotonic_count`, `rate`, and `tag`, with
    ##                                     `gauge` being the default.
    ##
    ## 4. payload (optional) - An optional payload can be included when querying the endpoint. This turns the GET
    ##                         request into a POST request, so a read-only user should be used when writing
    ##                         custom queries with a payload. Use YAML formatting when including a payload.
    ##
    ## Example:
    ## - endpoint: /_search
    ##   data_path: aggregations.genres.buckets
    ##   payload:
    ##     aggs:
    ##       genres:
    ##         terms:
    ##           field: "id"
    ##   columns:
    ##   - value_path: key
    ##     name: id
    ##     type: tag
    ##   - value_path: doc_count
    ##     name: elasticsearch.doc_count
    ##   tags:
    ##   - custom_tag:1
    #
    # custom_queries: []

    ## @param submit_events - boolean - optional - default: true
    ## By default we submit events to Datadog if the cluster starts unhealthy or anytime its health changes.
    ## You can set this option to `false` to disable submitting the events in case you already implemented
    ## your own custom alerts based on metrics.
    #
    # submit_events: true

    ## @param tags - list of strings - optional
    ## A list of tags to attach to every metric and service check emitted by this instance.
    ##
    ## Learn more about tagging at https://docs.datadoghq.com/tagging
    #
    # tags:
    #   - <KEY_1>:<VALUE_1>
    #   - <KEY_2>:<VALUE_2>

    ## @param service - string - optional
    ## Attach the tag `service:<SERVICE>` to every metric, event, and service check emitted by this integration.
    ##
    ## Overrides any `service` defined in the `init_config` section.
    #
    # service: <SERVICE>

    ## @param min_collection_interval - number - optional - default: 15
    ## This changes the collection interval of the check. For more information, see:
    ## https://docs.datadoghq.com/developers/write_agent_check/#collection-interval
    #
    # min_collection_interval: 15

    ## @param empty_default_hostname - boolean - optional - default: false
    ## This forces the check to send metrics with no hostname.
    ##
    ## This is useful for cluster-level checks.
    #
    # empty_default_hostname: false

    ## @param metric_patterns - mapping - optional
    ## A mapping of metrics to include or exclude, with each entry being a regular expression.
    ##
    ## Metrics defined in `exclude` will take precedence in case of overlap.
    #
    # metric_patterns:
    #   include:
    #   - <INCLUDE_REGEX>
    #   exclude:
    #   - <EXCLUDE_REGEX>

    ## @param proxy - mapping - optional
    ## This overrides the `proxy` setting in `init_config`.
    ##
    ## Set HTTP or HTTPS proxies for this instance. Use the `no_proxy` list
    ## to specify hosts that must bypass proxies.
    ##
    ## The SOCKS protocol is also supported, for example:
    ##
    ##   socks5://user:pass@host:port
    ##
    ## Using the scheme `socks5` causes the DNS resolution to happen on the
    ## client, rather than on the proxy server. This is in line with `curl`,
    ## which uses the scheme to decide whether to do the DNS resolution on
    ## the client or proxy. If you want to resolve the domains on the proxy
    ## server, use `socks5h` as the scheme.
    #
    # proxy:
    #   http: http://<PROXY_SERVER_FOR_HTTP>:<PORT>
    #   https: https://<PROXY_SERVER_FOR_HTTPS>:<PORT>
    #   no_proxy:
    #   - <HOSTNAME_1>
    #   - <HOSTNAME_2>

    ## @param skip_proxy - boolean - optional - default: false
    ## This overrides the `skip_proxy` setting in `init_config`.
    ##
    ## If set to `true`, this makes the check bypass any proxy
    ## settings enabled and attempt to reach services directly.
    #
    # skip_proxy: false

    ## @param auth_type - string - optional - default: basic
    ## The type of authentication to use. The available types (and related options) are:
    ##
    ##   - basic
    ##     |__ username
    ##     |__ password
    ##     |__ use_legacy_auth_encoding
    ##   - digest
    ##     |__ username
    ##     |__ password
    ##   - ntlm
    ##     |__ ntlm_domain
    ##     |__ password
    ##   - kerberos
    ##     |__ kerberos_auth
    ##     |__ kerberos_cache
    ##     |__ kerberos_delegate
    ##     |__ kerberos_force_initiate
    ##     |__ kerberos_hostname
    ##     |__ kerberos_keytab
    ##     |__ kerberos_principal
    ##   - aws
    ##     |__ aws_region
    ##     |__ aws_host
    ##     |__ aws_service
    ##
    ## The `aws` auth type relies on boto3 to automatically gather AWS credentials, for example: from `.aws/credentials`.
    ## Details: https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html#configuring-credentials
    #
    # auth_type: basic

    ## @param use_legacy_auth_encoding - boolean - optional - default: true
    ## When `auth_type` is set to `basic`, this determines whether to encode as `latin1` rather than `utf-8`.
    #
    # use_legacy_auth_encoding: true

    ## @param username - string - optional
    ## The username to use if services are behind basic or digest auth.
    #
    # username: <USERNAME>

    ## @param password - string - optional
    ## The password to use if services are behind basic or NTLM auth.
    #
    # password: <PASSWORD>

    ## @param ntlm_domain - string - optional
    ## If your services use NTLM authentication, specify
    ## the domain used in the check. For NTLM Auth, append
    ## the username to domain, not as the `username` parameter.
    #
    # ntlm_domain: <NTLM_DOMAIN>\<USERNAME>

    ## @param kerberos_auth - string - optional - default: disabled
    ## If your services use Kerberos authentication, you can specify the Kerberos
    ## strategy to use between:
    ##
    ##   - required
    ##   - optional
    ##   - disabled
    ##
    ## See https://github.com/requests/requests-kerberos#mutual-authentication
    #
    # kerberos_auth: disabled

    ## @param kerberos_cache - string - optional
    ## Sets the KRB5CCNAME environment variable.
    ## It should point to a credential cache with a valid TGT.
    #
    # kerberos_cache: <KERBEROS_CACHE>

    ## @param kerberos_delegate - boolean - optional - default: false
    ## Set to `true` to enable Kerberos delegation of credentials to a server that requests delegation.
    ##
    ## See https://github.com/requests/requests-kerberos#delegation
    #
    # kerberos_delegate: false

    ## @param kerberos_force_initiate - boolean - optional - default: false
    ## Set to `true` to preemptively initiate the Kerberos GSS exchange and
    ## present a Kerberos ticket on the initial request (and all subsequent).
    ##
    ## See https://github.com/requests/requests-kerberos#preemptive-authentication
    #
    # kerberos_force_initiate: false

    ## @param kerberos_hostname - string - optional
    ## Override the hostname used for the Kerberos GSS exchange if its DNS name doesn't
    ## match its Kerberos hostname, for example: behind a content switch or load balancer.
    ##
    ## See https://github.com/requests/requests-kerberos#hostname-override
    #
    # kerberos_hostname: <KERBEROS_HOSTNAME>

    ## @param kerberos_principal - string - optional
    ## Set an explicit principal, to force Kerberos to look for a
    ## matching credential cache for the named user.
    ##
    ## See https://github.com/requests/requests-kerberos#explicit-principal
    #
    # kerberos_principal: <KERBEROS_PRINCIPAL>

    ## @param kerberos_keytab - string - optional
    ## Set the path to your Kerberos key tab file.
    #
    # kerberos_keytab: <KEYTAB_FILE_PATH>

    ## @param auth_token - mapping - optional
    ## This allows for the use of authentication information from dynamic sources.
    ## Both a reader and writer must be configured.
    ##
    ## The available readers are:
    ##
    ##   - type: file
    ##     path (required): The absolute path for the file to read from.
    ##     pattern: A regular expression pattern with a single capture group used to find the
    ##              token rather than using the entire file, for example: Your secret is (.+)
    ##   - type: oauth
    ##     url (required): The token endpoint.
    ##     client_id (required): The client identifier.
    ##     client_secret (required): The client secret.
    ##     basic_auth: Whether the provider expects credentials to be transmitted in
    ##                 an HTTP Basic Auth header. The default is: false
    ##
    ## The available writers are:
    ##
    ##   - type: header
    ##     name (required): The name of the field, for example: Authorization
    ##     value: The template value, for example `Bearer <TOKEN>`. The default is: <TOKEN>
    ##     placeholder: The substring in `value` to replace with the token, defaults to: <TOKEN>
    #
    # auth_token:
    #   reader:
    #     type: <READER_TYPE>
    #     <OPTION_1>: <VALUE_1>
    #     <OPTION_2>: <VALUE_2>
    #   writer:
    #     type: <WRITER_TYPE>
    #     <OPTION_1>: <VALUE_1>
    #     <OPTION_2>: <VALUE_2>

    ## @param aws_region - string - optional
    ## If your services require AWS Signature Version 4 signing, set the region.
    ##
    ## See https://docs.aws.amazon.com/general/latest/gr/signature-version-4.html
    #
    # aws_region: <AWS_REGION>

    ## @param aws_host - string - optional
    ## If your services require AWS Signature Version 4 signing, set the host.
    ## This only needs the hostname and does not require the protocol (HTTP, HTTPS, and more).
    ## For example, if connecting to https://us-east-1.amazonaws.com/, set `aws_host` to `us-east-1.amazonaws.com`.
    ##
    ## Note: This setting is not necessary for official integrations.
    ##
    ## See https://docs.aws.amazon.com/general/latest/gr/signature-version-4.html
    #
    # aws_host: <AWS_HOST>

    ## @param aws_service - string - optional
    ## If your services require AWS Signature Version 4 signing, set the service code. For a list
    ## of available service codes, see https://docs.aws.amazon.com/general/latest/gr/rande.html
    ##
    ## Note: This setting is not necessary for official integrations.
    ##
    ## See https://docs.aws.amazon.com/general/latest/gr/signature-version-4.html
    #
    # aws_service: <AWS_SERVICE>

    ## @param tls_verify - boolean - optional - default: true
    ## Instructs the check to validate the TLS certificate of services.
    #
    # tls_verify: true

    ## @param tls_use_host_header - boolean - optional - default: false
    ## If a `Host` header is set, this enables its use for SNI (matching against the TLS certificate CN or SAN).
    #
    # tls_use_host_header: false

    ## @param tls_ignore_warning - boolean - optional - default: false
    ## If `tls_verify` is disabled, security warnings are logged by the check.
    ## Disable those by setting `tls_ignore_warning` to true.
    #
    # tls_ignore_warning: false

    ## @param tls_cert - string - optional
    ## The path to a single file in PEM format containing a certificate as well as any
    ## number of CA certificates needed to establish the certificate's authenticity for
    ## use when connecting to services. It may also contain an unencrypted private key to use.
    #
    # tls_cert: <CERT_PATH>

    ## @param tls_private_key - string - optional
    ## The unencrypted private key to use for `tls_cert` when connecting to services. This is
    ## required if `tls_cert` is set and it does not already contain a private key.
    #
    # tls_private_key: <PRIVATE_KEY_PATH>

    ## @param tls_ca_cert - string - optional
    ## The path to a file of concatenated CA certificates in PEM format or a directory
    ## containing several CA certificates in PEM format. If a directory, the directory
    ## must have been processed using the c_rehash utility supplied with OpenSSL. See:
    ## https://www.openssl.org/docs/manmaster/man3/SSL_CTX_load_verify_locations.html
    #
    # tls_ca_cert: <CA_CERT_PATH>

    ## @param tls_protocols_allowed - list of strings - optional
    ## The expected versions of TLS/SSL when fetching intermediate certificates.
    ## Only `SSLv3`, `TLSv1.2`, `TLSv1.3` are allowed by default. The possible values are:
    ##   SSLv3
    ##   TLSv1
    ##   TLSv1.1
    ##   TLSv1.2
    ##   TLSv1.3
    #
    # tls_protocols_allowed:
    #   - SSLv3
    #   - TLSv1.2
    #   - TLSv1.3

    ## @param headers - mapping - optional
    ## The headers parameter allows you to send specific headers with every request.
    ## You can use it for explicitly specifying the host header or adding headers for
    ## authorization purposes.
    ##
    ## This overrides any default headers.
    #
    # headers:
    #   Host: <ALTERNATIVE_HOSTNAME>
    #   X-Auth-Token: <AUTH_TOKEN>

    ## @param extra_headers - mapping - optional
    ## Additional headers to send with every request.
    #
    # extra_headers:
    #   Host: <ALTERNATIVE_HOSTNAME>
    #   X-Auth-Token: <AUTH_TOKEN>

    ## @param timeout - number - optional - default: 10
    ## The timeout for accessing services.
    ##
    ## This overrides the `timeout` setting in `init_config`.
    #
    # timeout: 10

    ## @param connect_timeout - number - optional
    ## The connect timeout for accessing services. Defaults to `timeout`.
    #
    # connect_timeout: <CONNECT_TIMEOUT>

    ## @param read_timeout - number - optional
    ## The read timeout for accessing services. Defaults to `timeout`.
    #
    # read_timeout: <READ_TIMEOUT>

    ## @param request_size - number - optional - default: 16
    ## The number of kibibytes (KiB) to read from streaming HTTP responses at a time.
    #
    # request_size: 16

    ## @param log_requests - boolean - optional - default: false
    ## Whether or not to debug log the HTTP(S) requests made, including the method and URL.
    #
    # log_requests: false

    ## @param persist_connections - boolean - optional - default: false
    ## Whether or not to persist cookies and use connection pooling for improved performance.
    #
    # persist_connections: false

    ## @param allow_redirects - boolean - optional - default: true
    ## Whether or not to allow URL redirection.
    #
    # allow_redirects: true

## Log Section
##
## type - required - Type of log input source (tcp / udp / file / windows_event).
## port / path / channel_path - required - Set port if type is tcp or udp.
##                                         Set path if type is file.
##                                         Set channel_path if type is windows_event.
## source  - required - Attribute that defines which integration sent the logs.
## encoding - optional - For file specifies the file encoding. Default is utf-8. Other
##                       possible values are utf-16-le and utf-16-be.
## service - optional - The name of the service that generates the log.
##                      Overrides any `service` defined in the `init_config` section.
## tags - optional - Add tags to the collected logs.
##
## Discover Datadog log collection: https://docs.datadoghq.com/logs/log_collection/
#
# logs:
#   - type: file
#     path: /var/log/elasticsearch/*.log
#     source: elasticsearch
#   - type: file
#     path: /var/log/elasticsearch/<CLUSTER_NAME>_index_indexing_slowlog.log
#     source: elasticsearch
#   - type: file
#     path: /var/log/elasticsearch/<CLUSTER_NAME>_index_search_slowlog.log
#     source: elasticsearch
