{
	"version": 2,
	"created_at": "2025-09-16",
	"last_updated_at": "2025-09-16",
	"title": "Slow token generation",
	"description": "This monitor tracks the mean time per token generation for Hugging Face TGI. Slow token generation indicates model inference performance issues, which directly impacts user experience and throughput.",
	"definition": {
		"name": "[Hugging Face TGI] Slow token generation",
		"type": "query alert",
		"query": "sum(last_5m):sum:hugging_face_tgi.request.mean_time_per_token.duration.sum{*}.as_count() / sum:hugging_face_tgi.request.mean_time_per_token.duration.count{*}.as_count() > 0.2",
		"message": "Hugging Face TGI token generation is slow (>200ms per token).\n\nThis indicates:\n* Model inference performance degradation\n* Resource constraints (GPU memory/compute)\n* Inefficient model configuration or parameters\n\n{{#is_alert}}\nMean time per token: {{value}}s\n{{/is_alert}}\n\nInvestigate:\n1. GPU utilization and memory usage\n2. Model configuration and quantization settings\n3. Batch size optimization\n4. Temperature and sampling parameters",
		"tags": [
			"integration:hugging-face-tgi"
		],
		"options": {
			"thresholds": {
				"critical": 0.2,
				"warning": 0.1
			},
			"notify_audit": false,
			"require_full_window": false,
			"renotify_interval": 60,
			"include_tags": true,
			"evaluation_delay": 300,
			"escalation_message": "",
			"on_missing_data": "show_and_notify_no_data",
			"new_host_delay": 300
		},
		"priority": 2
	},
	"tags": [
		"integration:hugging-face-tgi"
	]
}
