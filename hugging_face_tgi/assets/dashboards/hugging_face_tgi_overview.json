{
  "title": "Hugging Face TGI - Overview",
  "description": "# About\nMonitor your Hugging Face Text Generation Inference deployment with real-time metrics for requests, tokens, batching, and system health. (cloned)",
  "widgets": [
    {
      "id": 1,
      "definition": {
        "title": "About",
        "background_color": "vivid_yellow",
        "show_title": true,
        "type": "group",
        "layout_type": "ordered",
        "widgets": [
          {
            "id": 7638856905341489,
            "definition": {
              "type": "image",
              "url": "/static/images/logos/hugging-face-tgi_large.svg",
              "url_dark_theme": "/static/images/logos/hugging-face-tgi_reversed_large.svg",
              "sizing": "contain",
              "has_background": true,
              "has_border": false,
              "vertical_align": "center",
              "horizontal_align": "center"
            },
            "layout": {
              "x": 0,
              "y": 0,
              "width": 5,
              "height": 2
            }
          },
          {
            "id": 2,
            "definition": {
              "type": "note",
              "content": "# Hugging Face TGI Monitoring\n\nTrack your Text Generation Inference server performance with key metrics for throughput, latency, token generation, and batch processing. Identify bottlenecks and optimize your deployment for better efficiency.",
              "background_color": "white",
              "font_size": "14",
              "text_align": "left",
              "vertical_align": "top",
              "show_tick": false,
              "tick_pos": "50%",
              "tick_edge": "left",
              "has_padding": true
            },
            "layout": {
              "x": 0,
              "y": 2,
              "width": 3,
              "height": 3
            }
          },
          {
            "id": 3,
            "definition": {
              "type": "note",
              "content": "# Useful Links\n\n[Hugging Face TGI Integration](https://docs.datadoghq.com/integrations/hugging_face_tgi)\n\n[TGI Documentation](https://huggingface.co/docs/text-generation-inference)\n\n[Hugging Face Hub](https://huggingface.co/)",
              "background_color": "white",
              "font_size": "14",
              "text_align": "left",
              "vertical_align": "top",
              "show_tick": false,
              "tick_pos": "50%",
              "tick_edge": "left",
              "has_padding": true
            },
            "layout": {
              "x": 3,
              "y": 2,
              "width": 2,
              "height": 3
            }
          }
        ]
      },
      "layout": {
        "x": 0,
        "y": 0,
        "width": 5,
        "height": 6
      }
    },
    {
      "id": 4,
      "definition": {
        "title": "System Overview",
        "background_color": "vivid_yellow",
        "show_title": true,
        "type": "group",
        "layout_type": "ordered",
        "widgets": [
          {
            "id": 5,
            "definition": {
              "type": "note",
              "content": "Get an instant overview of your TGI deployment's operational status. These key performance indicators provide immediate visibility into service health, processing capacity, and potential bottlenecks that require attention.",
              "background_color": "yellow",
              "font_size": "16",
              "text_align": "center",
              "vertical_align": "center",
              "show_tick": false,
              "tick_pos": "50%",
              "tick_edge": "left",
              "has_padding": true
            },
            "layout": {
              "x": 0,
              "y": 0,
              "width": 7,
              "height": 1
            }
          },
          {
            "id": 6,
            "definition": {
              "title": "Service Health",
              "title_size": "16",
              "title_align": "left",
              "type": "check_status",
              "check": "hugging_face_tgi.openmetrics.health",
              "grouping": "cluster",
              "group_by": ["host"],
              "tags": ["$host"]
            },
            "layout": {
              "x": 0,
              "y": 1,
              "width": 2,
              "height": 1
            }
          },
          {
            "id": 7,
            "definition": {
              "title": "Average Queue Size",
              "title_size": "16",
              "title_align": "left",
              "type": "query_value",
              "requests": [
                {
                  "formulas": [
                    {
                      "formula": "query1"
                    }
                  ],
                  "queries": [
                    {
                      "data_source": "metrics",
                      "name": "query1",
                      "query": "avg:hugging_face_tgi.queue.size{$host}",
                      "aggregator": "avg"
                    }
                  ],
                  "response_format": "scalar",
                  "conditional_formats": [
                    {
                      "comparator": ">",
                      "value": 50,
                      "palette": "white_on_red"
                    },
                    {
                      "comparator": ">",
                      "value": 30,
                      "palette": "white_on_yellow"
                    },
                    {
                      "comparator": "<=",
                      "value": 30,
                      "palette": "white_on_green"
                    }
                  ]
                }
              ],
              "autoscale": true,
              "precision": 0
            },
            "layout": {
              "x": 2,
              "y": 1,
              "width": 2,
              "height": 1
            }
          },
          {
            "id": 8,
            "definition": {
              "title": "Monitors",
              "type": "manage_status",
              "display_format": "countsAndList",
              "color_preference": "text",
              "hide_zero_counts": true,
              "show_status": true,
              "last_triggered_format": "relative",
              "query": "tag:(integration:hugging-face-tgi)",
              "sort": "status,asc",
              "count": 50,
              "start": 0,
              "summary_type": "monitors",
              "show_priority": false,
              "show_last_triggered": false
            },
            "layout": {
              "x": 4,
              "y": 1,
              "width": 3,
              "height": 4
            }
          },
          {
            "id": 9,
            "definition": {
              "title": "Requests per second",
              "title_size": "16",
              "title_align": "left",
              "type": "query_value",
              "requests": [
                {
                  "formulas": [
                    {
                      "formula": "throughput(query1)"
                    }
                  ],
                  "queries": [
                    {
                      "data_source": "metrics",
                      "name": "query1",
                      "query": "sum:hugging_face_tgi.request.count{$host}.as_count()",
                      "aggregator": "sum"
                    }
                  ],
                  "response_format": "scalar"
                }
              ],
              "autoscale": true,
              "precision": 2,
              "timeseries_background": {
                "yaxis": {},
                "type": "bars"
              }
            },
            "layout": {
              "x": 0,
              "y": 2,
              "width": 2,
              "height": 1
            }
          },
          {
            "id": 10,
            "definition": {
              "title": "Mean Time per Token (ms)",
              "title_size": "16",
              "title_align": "left",
              "type": "query_value",
              "requests": [
                {
                  "formulas": [
                    {
                      "number_format": {
                        "unit": {
                          "type": "canonical_unit",
                          "unit_name": "millisecond"
                        }
                      },
                      "formula": "query1 / query2 * 1000"
                    }
                  ],
                  "queries": [
                    {
                      "data_source": "metrics",
                      "name": "query1",
                      "query": "sum:hugging_face_tgi.request.mean_time_per_token.duration.sum{$host}.as_count()",
                      "aggregator": "avg"
                    },
                    {
                      "data_source": "metrics",
                      "name": "query2",
                      "query": "sum:hugging_face_tgi.request.mean_time_per_token.duration.count{$host}.as_count()",
                      "aggregator": "avg"
                    }
                  ],
                  "response_format": "scalar",
                  "conditional_formats": [
                    {
                      "comparator": ">",
                      "value": 200,
                      "palette": "white_on_red"
                    },
                    {
                      "comparator": ">",
                      "value": 100,
                      "palette": "white_on_yellow"
                    },
                    {
                      "comparator": "<=",
                      "value": 100,
                      "palette": "white_on_green"
                    }
                  ]
                }
              ],
              "autoscale": true,
              "precision": 1
            },
            "layout": {
              "x": 2,
              "y": 2,
              "width": 2,
              "height": 1
            }
          },
          {
            "id": 4097212373930688,
            "definition": {
              "title": "Host performance summary",
              "title_size": "16",
              "title_align": "left",
              "type": "query_table",
              "requests": [
                {
                  "queries": [
                    {
                      "data_source": "metrics",
                      "name": "query1",
                      "query": "sum:hugging_face_tgi.request.count{$host} by {host}.as_count()",
                      "aggregator": "sum"
                    },
                    {
                      "data_source": "metrics",
                      "name": "query3",
                      "query": "avg:hugging_face_tgi.queue.size{$host} by {host}",
                      "aggregator": "avg"
                    },
                    {
                      "data_source": "metrics",
                      "name": "query2",
                      "query": "sum:hugging_face_tgi.request.duration.sum{$host} by {host}.as_count()",
                      "aggregator": "sum"
                    },
                    {
                      "data_source": "metrics",
                      "name": "query4",
                      "query": "sum:hugging_face_tgi.request.duration.count{$host} by {host}.as_count()",
                      "aggregator": "sum"
                    }
                  ],
                  "response_format": "scalar",
                  "sort": {
                    "count": 500,
                    "order_by": [
                      {
                        "type": "formula",
                        "index": 0,
                        "order": "desc"
                      }
                    ]
                  },
                  "formulas": [
                    {
                      "cell_display_mode": "bar",
                      "alias": "Requests per second",
                      "formula": "throughput(query1)"
                    },
                    {
                      "cell_display_mode": "bar",
                      "alias": "Avg queue size",
                      "formula": "query3"
                    },
                    {
                      "alias": "Avg req duration",
                      "number_format": {
                        "unit": {
                          "type": "canonical_unit",
                          "unit_name": "second"
                        }
                      },
                      "formula": "query2 / query4",
                      "cell_display_mode": "bar"
                    }
                  ]
                }
              ],
              "has_search_bar": "auto"
            },
            "layout": {
              "x": 0,
              "y": 3,
              "width": 4,
              "height": 2
            }
          }
        ]
      },
      "layout": {
        "x": 5,
        "y": 0,
        "width": 7,
        "height": 6
      }
    },
    {
      "id": 11,
      "definition": {
        "title": "Request Performance",
        "background_color": "vivid_yellow",
        "show_title": true,
        "type": "group",
        "layout_type": "ordered",
        "widgets": [
          {
            "id": 12,
            "definition": {
              "type": "note",
              "content": "Analyze how your TGI server handles incoming requests over time. These metrics reveal processing patterns, help identify peak usage periods, and show the complete request lifecycle from queuing through validation to final inference completion.",
              "background_color": "yellow",
              "font_size": "16",
              "text_align": "center",
              "vertical_align": "top",
              "show_tick": false,
              "tick_pos": "50%",
              "tick_edge": "left",
              "has_padding": true
            },
            "layout": {
              "x": 0,
              "y": 0,
              "width": 12,
              "height": 1
            }
          },
          {
            "id": 13,
            "definition": {
              "title": "Request count",
              "title_size": "16",
              "title_align": "left",
              "show_legend": true,
              "legend_layout": "auto",
              "legend_columns": ["avg", "min", "max", "value", "sum"],
              "type": "timeseries",
              "requests": [
                {
                  "formulas": [
                    {
                      "alias": "Success",
                      "style": {
                        "palette": "green",
                        "palette_index": 4
                      },
                      "formula": "query2"
                    },
                    {
                      "alias": "Errors",
                      "style": {
                        "palette": "warm",
                        "palette_index": 4
                      },
                      "formula": "query3"
                    }
                  ],
                  "queries": [
                    {
                      "data_source": "metrics",
                      "name": "query2",
                      "query": "sum:hugging_face_tgi.request.success.count{$host}.as_count()"
                    },
                    {
                      "data_source": "metrics",
                      "name": "query3",
                      "query": "sum:hugging_face_tgi.request.failure.count{$host}.as_count()"
                    }
                  ],
                  "response_format": "timeseries",
                  "style": {
                    "line_type": "solid",
                    "line_width": "normal"
                  },
                  "display_type": "bars"
                }
              ]
            },
            "layout": {
              "x": 0,
              "y": 1,
              "width": 6,
              "height": 3
            }
          },
          {
            "id": 26,
            "definition": {
              "title": "Processing timeline per request ",
              "title_size": "16",
              "title_align": "left",
              "show_legend": true,
              "legend_layout": "auto",
              "legend_columns": ["avg", "min", "max", "value", "sum"],
              "type": "timeseries",
              "requests": [
                {
                  "formulas": [
                    {
                      "alias": "Queue Duration",
                      "number_format": {
                        "unit": {
                          "type": "canonical_unit",
                          "unit_name": "second"
                        }
                      },
                      "formula": "query1 / query4"
                    },
                    {
                      "alias": "Validation Duration",
                      "number_format": {
                        "unit": {
                          "type": "canonical_unit",
                          "unit_name": "second"
                        }
                      },
                      "formula": "query2 / query5"
                    },
                    {
                      "alias": "Inference Duration",
                      "number_format": {
                        "unit": {
                          "type": "canonical_unit",
                          "unit_name": "second"
                        }
                      },
                      "formula": "query3 / query6"
                    }
                  ],
                  "queries": [
                    {
                      "data_source": "metrics",
                      "name": "query1",
                      "query": "sum:hugging_face_tgi.request.queue.duration.sum{$host}.as_count()"
                    },
                    {
                      "data_source": "metrics",
                      "name": "query4",
                      "query": "sum:hugging_face_tgi.request.queue.duration.count{$host}.as_count()"
                    },
                    {
                      "data_source": "metrics",
                      "name": "query2",
                      "query": "sum:hugging_face_tgi.request.validation.duration.sum{$host}.as_count()"
                    },
                    {
                      "data_source": "metrics",
                      "name": "query5",
                      "query": "sum:hugging_face_tgi.request.validation.duration.count{$host}.as_count()"
                    },
                    {
                      "data_source": "metrics",
                      "name": "query3",
                      "query": "sum:hugging_face_tgi.request.inference.duration.sum{$host}.as_count()"
                    },
                    {
                      "data_source": "metrics",
                      "name": "query6",
                      "query": "sum:hugging_face_tgi.request.inference.duration.count{$host}.as_count()"
                    }
                  ],
                  "response_format": "timeseries",
                  "style": {
                    "palette": "dog_classic",
                    "line_type": "solid",
                    "line_width": "normal"
                  },
                  "display_type": "bars"
                }
              ]
            },
            "layout": {
              "x": 6,
              "y": 1,
              "width": 6,
              "height": 3
            }
          },
          {
            "id": 25,
            "definition": {
              "title": "Queue depth over time",
              "title_size": "16",
              "title_align": "left",
              "show_legend": true,
              "legend_layout": "auto",
              "legend_columns": ["avg", "min", "max", "value", "sum"],
              "type": "timeseries",
              "requests": [
                {
                  "formulas": [
                    {
                      "alias": "Queue Size",
                      "formula": "query1"
                    }
                  ],
                  "queries": [
                    {
                      "data_source": "metrics",
                      "name": "query1",
                      "query": "sum:hugging_face_tgi.queue.size{$host}"
                    }
                  ],
                  "response_format": "timeseries",
                  "style": {
                    "line_type": "solid",
                    "line_width": "normal"
                  },
                  "display_type": "line"
                }
              ]
            },
            "layout": {
              "x": 0,
              "y": 4,
              "width": 12,
              "height": 3
            }
          }
        ]
      },
      "layout": {
        "x": 0,
        "y": 6,
        "width": 12,
        "height": 8
      }
    },
    {
      "id": 15,
      "definition": {
        "title": "Token Generation Performance",
        "background_color": "vivid_yellow",
        "show_title": true,
        "type": "group",
        "layout_type": "ordered",
        "widgets": [
          {
            "id": 16,
            "definition": {
              "type": "note",
              "content": "Understand your model's token generation characteristics and performance patterns. These metrics help track the model's input and output volumes.",
              "background_color": "yellow",
              "font_size": "16",
              "text_align": "center",
              "vertical_align": "top",
              "show_tick": false,
              "tick_pos": "50%",
              "tick_edge": "left",
              "has_padding": true
            },
            "layout": {
              "x": 0,
              "y": 0,
              "width": 12,
              "height": 1
            }
          },
          {
            "id": 18,
            "definition": {
              "title": "Total Input",
              "title_size": "16",
              "title_align": "left",
              "show_legend": true,
              "legend_layout": "auto",
              "legend_columns": ["avg", "min", "max", "value", "sum"],
              "type": "timeseries",
              "requests": [
                {
                  "formulas": [
                    {
                      "alias": "Input Tokens",
                      "formula": "query1"
                    }
                  ],
                  "queries": [
                    {
                      "data_source": "metrics",
                      "name": "query1",
                      "query": "sum:hugging_face_tgi.request.input_length.sum{$host}.as_count()"
                    }
                  ],
                  "response_format": "timeseries",
                  "style": {
                    "palette": "orange",
                    "order_reverse": false,
                    "color_order": "monotonic",
                    "line_type": "solid",
                    "line_width": "normal"
                  },
                  "display_type": "bars"
                }
              ],
              "markers": []
            },
            "layout": {
              "x": 0,
              "y": 1,
              "width": 5,
              "height": 4
            }
          },
          {
            "id": 17,
            "definition": {
              "title": "Total Generated",
              "title_size": "16",
              "title_align": "left",
              "show_legend": true,
              "legend_layout": "auto",
              "legend_columns": ["avg", "min", "max", "value", "sum"],
              "type": "timeseries",
              "requests": [
                {
                  "formulas": [
                    {
                      "alias": "Generated Tokens",
                      "style": {
                        "palette": "classic",
                        "palette_index": 4
                      },
                      "formula": "query1"
                    }
                  ],
                  "queries": [
                    {
                      "data_source": "metrics",
                      "name": "query1",
                      "query": "sum:hugging_face_tgi.request.generated_tokens.sum{$host}.as_count()"
                    }
                  ],
                  "response_format": "timeseries",
                  "style": {
                    "line_type": "solid",
                    "line_width": "normal"
                  },
                  "display_type": "bars"
                }
              ]
            },
            "layout": {
              "x": 5,
              "y": 1,
              "width": 5,
              "height": 4
            }
          },
          {
            "id": 2278476570708517,
            "definition": {
              "title": "Ingested",
              "title_size": "16",
              "title_align": "left",
              "time": {},
              "type": "query_value",
              "requests": [
                {
                  "formulas": [
                    {
                      "formula": "query1"
                    }
                  ],
                  "queries": [
                    {
                      "data_source": "metrics",
                      "name": "query1",
                      "query": "sum:hugging_face_tgi.request.input_length.sum{$host}.as_count()",
                      "aggregator": "sum"
                    }
                  ],
                  "response_format": "scalar"
                }
              ],
              "autoscale": true,
              "precision": 2,
              "timeseries_background": {
                "yaxis": {},
                "type": "bars"
              }
            },
            "layout": {
              "x": 10,
              "y": 1,
              "width": 2,
              "height": 2
            }
          },
          {
            "id": 1031719254760586,
            "definition": {
              "title": "Output",
              "title_size": "16",
              "title_align": "left",
              "time": {},
              "type": "query_value",
              "requests": [
                {
                  "formulas": [
                    {
                      "formula": "query1"
                    }
                  ],
                  "queries": [
                    {
                      "data_source": "metrics",
                      "name": "query1",
                      "query": "sum:hugging_face_tgi.request.generated_tokens.sum{$host}.as_count()",
                      "aggregator": "sum"
                    }
                  ],
                  "response_format": "scalar"
                }
              ],
              "autoscale": true,
              "precision": 2,
              "timeseries_background": {
                "type": "bars",
                "yaxis": {}
              }
            },
            "layout": {
              "x": 10,
              "y": 3,
              "width": 2,
              "height": 2
            }
          }
        ]
      },
      "layout": {
        "x": 0,
        "y": 14,
        "width": 12,
        "height": 6
      }
    },
    {
      "id": 19,
      "definition": {
        "title": "Batch Processing",
        "background_color": "vivid_yellow",
        "show_title": true,
        "type": "group",
        "layout_type": "ordered",
        "widgets": [
          {
            "id": 20,
            "definition": {
              "type": "note",
              "content": "Explore how TGI optimizes inference through intelligent batching. These metrics reveal batch composition strategies, processing pipeline efficiency, and help identify opportunities to improve throughput by understanding the various stages of batch execution.",
              "background_color": "yellow",
              "font_size": "16",
              "text_align": "center",
              "vertical_align": "top",
              "show_tick": false,
              "tick_pos": "50%",
              "tick_edge": "left",
              "has_padding": true
            },
            "layout": {
              "x": 0,
              "y": 0,
              "width": 12,
              "height": 1
            }
          },
          {
            "id": 3279775942383392,
            "definition": {
              "title": "Average prefill time",
              "title_size": "16",
              "title_align": "left",
              "show_legend": true,
              "legend_layout": "auto",
              "legend_columns": ["avg", "min", "max", "value", "sum"],
              "time": {},
              "type": "timeseries",
              "requests": [
                {
                  "formulas": [
                    {
                      "alias": "Concatenation",
                      "number_format": {
                        "unit": {
                          "type": "canonical_unit",
                          "unit_name": "second"
                        }
                      },
                      "formula": "query1 / query2"
                    },
                    {
                      "alias": "Filter",
                      "number_format": {
                        "unit": {
                          "type": "canonical_unit",
                          "unit_name": "second"
                        }
                      },
                      "formula": "query3 / query4"
                    },
                    {
                      "alias": "Forward",
                      "number_format": {
                        "unit": {
                          "type": "canonical_unit",
                          "unit_name": "second"
                        }
                      },
                      "formula": "query5 / query6"
                    },
                    {
                      "alias": "Inference - Time to First Token",
                      "number_format": {
                        "unit": {
                          "type": "canonical_unit",
                          "unit_name": "second"
                        }
                      },
                      "formula": "query7 / query8"
                    },
                    {
                      "alias": "Decode",
                      "number_format": {
                        "unit": {
                          "type": "canonical_unit",
                          "unit_name": "second"
                        }
                      },
                      "formula": "query9 / query10"
                    }
                  ],
                  "queries": [
                    {
                      "data_source": "metrics",
                      "name": "query1",
                      "query": "sum:hugging_face_tgi.batch.concat.duration.sum{$host,method:prefill}.as_count()"
                    },
                    {
                      "data_source": "metrics",
                      "name": "query2",
                      "query": "sum:hugging_face_tgi.batch.concat.duration.count{$host,method:prefill}.as_count()"
                    },
                    {
                      "data_source": "metrics",
                      "name": "query3",
                      "query": "sum:hugging_face_tgi.batch.filter.duration.sum{$host,method:prefill}.as_count()"
                    },
                    {
                      "data_source": "metrics",
                      "name": "query4",
                      "query": "sum:hugging_face_tgi.batch.filter.duration.count{$host,method:prefill}.as_count()"
                    },
                    {
                      "data_source": "metrics",
                      "name": "query5",
                      "query": "sum:hugging_face_tgi.batch.forward.duration.sum{$host,method:prefill}.as_count()"
                    },
                    {
                      "data_source": "metrics",
                      "name": "query6",
                      "query": "sum:hugging_face_tgi.batch.forward.duration.count{$host,method:prefill}.as_count()"
                    },
                    {
                      "data_source": "metrics",
                      "name": "query7",
                      "query": "sum:hugging_face_tgi.batch.inference.duration.sum{$host,method:prefill}.as_count()"
                    },
                    {
                      "data_source": "metrics",
                      "name": "query8",
                      "query": "sum:hugging_face_tgi.batch.inference.duration.count{$host,method:prefill}.as_count()"
                    },
                    {
                      "data_source": "metrics",
                      "name": "query9",
                      "query": "sum:hugging_face_tgi.batch.decode.duration.sum{$host,method:prefill}.as_count()"
                    },
                    {
                      "data_source": "metrics",
                      "name": "query10",
                      "query": "sum:hugging_face_tgi.batch.decode.duration.count{$host,method:prefill}.as_count()"
                    }
                  ],
                  "response_format": "timeseries",
                  "style": {
                    "palette": "dog_classic",
                    "order_by": "values",
                    "line_type": "solid",
                    "line_width": "normal"
                  },
                  "display_type": "line"
                }
              ]
            },
            "layout": {
              "x": 0,
              "y": 1,
              "width": 6,
              "height": 3
            }
          },
          {
            "id": 5373651868721697,
            "definition": {
              "title": "Average decode time",
              "title_size": "16",
              "title_align": "left",
              "show_legend": true,
              "legend_layout": "auto",
              "legend_columns": ["avg", "min", "max", "value", "sum"],
              "time": {},
              "type": "timeseries",
              "requests": [
                {
                  "formulas": [
                    {
                      "alias": "Concatenation",
                      "number_format": {
                        "unit": {
                          "type": "canonical_unit",
                          "unit_name": "second"
                        }
                      },
                      "formula": "query1 / query2"
                    },
                    {
                      "alias": "Filter",
                      "number_format": {
                        "unit": {
                          "type": "canonical_unit",
                          "unit_name": "second"
                        }
                      },
                      "formula": "query3 / query4"
                    },
                    {
                      "alias": "Forward",
                      "number_format": {
                        "unit": {
                          "type": "canonical_unit",
                          "unit_name": "second"
                        }
                      },
                      "formula": "query5 / query6"
                    },
                    {
                      "alias": "Inference - Time Per Token",
                      "number_format": {
                        "unit": {
                          "type": "canonical_unit",
                          "unit_name": "second"
                        }
                      },
                      "formula": "query7 / query8"
                    },
                    {
                      "alias": "Decode",
                      "number_format": {
                        "unit": {
                          "type": "canonical_unit",
                          "unit_name": "second"
                        }
                      },
                      "formula": "query9 / query10"
                    }
                  ],
                  "queries": [
                    {
                      "data_source": "metrics",
                      "name": "query1",
                      "query": "sum:hugging_face_tgi.batch.concat.duration.sum{$host,method:decode}.as_count()"
                    },
                    {
                      "data_source": "metrics",
                      "name": "query2",
                      "query": "sum:hugging_face_tgi.batch.concat.duration.count{$host,method:decode}.as_count()"
                    },
                    {
                      "data_source": "metrics",
                      "name": "query3",
                      "query": "sum:hugging_face_tgi.batch.filter.duration.sum{$host,method:decode}.as_count()"
                    },
                    {
                      "data_source": "metrics",
                      "name": "query4",
                      "query": "sum:hugging_face_tgi.batch.filter.duration.count{$host,method:decode}.as_count()"
                    },
                    {
                      "data_source": "metrics",
                      "name": "query5",
                      "query": "sum:hugging_face_tgi.batch.forward.duration.sum{$host,method:decode}.as_count()"
                    },
                    {
                      "data_source": "metrics",
                      "name": "query6",
                      "query": "sum:hugging_face_tgi.batch.forward.duration.count{$host,method:decode}.as_count()"
                    },
                    {
                      "data_source": "metrics",
                      "name": "query7",
                      "query": "sum:hugging_face_tgi.batch.inference.duration.sum{$host,method:decode}.as_count()"
                    },
                    {
                      "data_source": "metrics",
                      "name": "query8",
                      "query": "sum:hugging_face_tgi.batch.inference.duration.count{$host,method:decode}.as_count()"
                    },
                    {
                      "data_source": "metrics",
                      "name": "query9",
                      "query": "sum:hugging_face_tgi.batch.decode.duration.sum{$host,method:decode}.as_count()"
                    },
                    {
                      "data_source": "metrics",
                      "name": "query10",
                      "query": "sum:hugging_face_tgi.batch.decode.duration.count{$host,method:decode}.as_count()"
                    }
                  ],
                  "response_format": "timeseries",
                  "style": {
                    "palette": "dog_classic",
                    "line_type": "solid",
                    "line_width": "normal"
                  },
                  "display_type": "line"
                }
              ]
            },
            "layout": {
              "x": 6,
              "y": 1,
              "width": 6,
              "height": 3
            }
          },
          {
            "id": 21,
            "definition": {
              "title": "Batch size",
              "title_size": "16",
              "title_align": "left",
              "show_legend": true,
              "legend_layout": "auto",
              "legend_columns": ["avg", "min", "max", "value", "sum"],
              "type": "timeseries",
              "requests": [
                {
                  "formulas": [
                    {
                      "alias": "Current Batch Size",
                      "formula": "query1"
                    }
                  ],
                  "queries": [
                    {
                      "data_source": "metrics",
                      "name": "query1",
                      "query": "avg:hugging_face_tgi.batch.current.size{$host}"
                    }
                  ],
                  "response_format": "timeseries",
                  "style": {
                    "palette": "dog_classic",
                    "line_type": "solid",
                    "line_width": "normal"
                  },
                  "display_type": "line"
                }
              ]
            },
            "layout": {
              "x": 0,
              "y": 4,
              "width": 6,
              "height": 3
            }
          },
          {
            "id": 2400395466412779,
            "definition": {
              "title": "Batch count",
              "title_size": "16",
              "title_align": "left",
              "show_legend": true,
              "legend_layout": "auto",
              "legend_columns": ["avg", "min", "max", "value", "sum"],
              "type": "timeseries",
              "requests": [
                {
                  "formulas": [
                    {
                      "alias": "Next Batch Count",
                      "formula": "query2"
                    }
                  ],
                  "queries": [
                    {
                      "data_source": "metrics",
                      "name": "query2",
                      "query": "sum:hugging_face_tgi.batch.next.size.count{$host}.as_count()"
                    }
                  ],
                  "response_format": "timeseries",
                  "style": {
                    "palette": "dog_classic",
                    "line_type": "solid",
                    "line_width": "normal"
                  },
                  "display_type": "bars"
                }
              ]
            },
            "layout": {
              "x": 6,
              "y": 4,
              "width": 6,
              "height": 3
            }
          }
        ]
      },
      "layout": {
        "x": 0,
        "y": 0,
        "width": 12,
        "height": 8,
        "is_column_break": true
      }
    },
    {
      "id": 2702502207226428,
      "definition": {
        "title": "Logs",
        "background_color": "vivid_yellow",
        "show_title": true,
        "type": "group",
        "layout_type": "ordered",
        "widgets": [
          {
            "id": 4434208871632602,
            "definition": {
              "type": "note",
              "content": "Access comprehensive logging information from your TGI deployment. These logs provide detailed insights into system behavior, error patterns, and operational events that complement the performance metrics for thorough troubleshooting and monitoring.",
              "background_color": "yellow",
              "font_size": "16",
              "text_align": "center",
              "vertical_align": "top",
              "show_tick": false,
              "tick_pos": "50%",
              "tick_edge": "left",
              "has_padding": true
            },
            "layout": {
              "x": 0,
              "y": 0,
              "width": 12,
              "height": 1
            }
          },
          {
            "id": 7649784419120106,
            "definition": {
              "title": "Logs count by status",
              "title_size": "16",
              "title_align": "left",
              "show_legend": true,
              "legend_layout": "auto",
              "legend_columns": ["avg", "min", "max", "value", "sum"],
              "type": "timeseries",
              "requests": [
                {
                  "formulas": [
                    {
                      "formula": "query1"
                    }
                  ],
                  "queries": [
                    {
                      "name": "query1",
                      "data_source": "logs",
                      "search": {
                        "query": "service:text-generation-inference OR source:hugging_face_tgi"
                      },
                      "indexes": ["*"],
                      "group_by": [
                        {
                          "facet": "status",
                          "limit": 10,
                          "sort": {
                            "aggregation": "count",
                            "order": "desc",
                            "metric": "count"
                          },
                          "should_exclude_missing": true
                        }
                      ],
                      "compute": {
                        "aggregation": "count"
                      },
                      "storage": "hot"
                    }
                  ],
                  "response_format": "timeseries",
                  "style": {
                    "palette": "dog_classic",
                    "order_by": "values",
                    "line_type": "solid",
                    "line_width": "normal"
                  },
                  "display_type": "bars"
                }
              ]
            },
            "layout": {
              "x": 0,
              "y": 1,
              "width": 7,
              "height": 4
            }
          },
          {
            "id": 3743214108667418,
            "definition": {
              "title": "Error logs",
              "title_size": "16",
              "title_align": "left",
              "requests": [
                {
                  "response_format": "event_list",
                  "query": {
                    "data_source": "logs_stream",
                    "query_string": "(service:text-generation-inference OR source:hugging_face_tgi) AND status:error",
                    "indexes": [],
                    "storage": "hot"
                  },
                  "columns": [
                    {
                      "field": "status_line",
                      "width": "auto"
                    },
                    {
                      "field": "timestamp",
                      "width": "auto"
                    },
                    {
                      "field": "host",
                      "width": "auto"
                    },
                    {
                      "field": "service",
                      "width": "auto"
                    },
                    {
                      "field": "content",
                      "width": "compact"
                    }
                  ]
                }
              ],
              "type": "list_stream"
            },
            "layout": {
              "x": 7,
              "y": 1,
              "width": 5,
              "height": 4
            }
          }
        ]
      },
      "layout": {
        "x": 0,
        "y": 8,
        "width": 12,
        "height": 6
      }
    },
    {
      "id": 2258222563095315,
      "definition": {
        "title": "LLM Observability ",
        "background_color": "vivid_yellow",
        "show_title": true,
        "type": "group",
        "layout_type": "ordered",
        "widgets": [
          {
            "id": 467063193958253,
            "definition": {
              "type": "note",
              "content": "[Datadog LLM Observability](https://docs.datadoghq.com/llm_observability/quickstart/?tab=python) enables you to experiment, troubleshoot, monitor, and evaluate LLM agents or applications. Get real-time visibility into inputs and outputs, errors, latency, token usage, and more, along with in-depth quality and security checks at every stage, including data retrieval, tool calls, and agent interactions.\n\nLLM Observability SDK can [automatically trace](https://docs.datadoghq.com/llm_observability/instrumentation/auto_instrumentation?tab=python) your LLM operations. Datadog's LLM Observability views integrate with Hugging Face TGI metrics to provide visibility into your workflows.\n\nFor setup instructions and auto-instrumentation, check out the [LLM Observability Quickstart Guide](https://docs.datadoghq.com/llm_observability/quickstart/?tab=python).\n\nTo explore model-level usage, token attribution, cost analysis, and request tracing across teams and providers, visit the [LLM Observability dashboard](https://app.datadoghq.com/dash/integration/llm_operational_insights).",
              "background_color": "yellow",
              "font_size": "14",
              "text_align": "left",
              "vertical_align": "center",
              "show_tick": true,
              "tick_pos": "50%",
              "tick_edge": "left",
              "has_padding": true
            },
            "layout": {
              "x": 0,
              "y": 0,
              "width": 12,
              "height": 2
            }
          },
          {
            "id": 8256861655602834,
            "definition": {
              "title": "Total LLM Requests",
              "title_size": "16",
              "title_align": "left",
              "type": "query_value",
              "requests": [
                {
                  "formulas": [
                    {
                      "formula": "query1"
                    }
                  ],
                  "queries": [
                    {
                      "data_source": "llm_observability",
                      "name": "query1",
                      "indexes": ["*"],
                      "compute": {
                        "aggregation": "count"
                      },
                      "group_by": [],
                      "search": {
                        "query": "@event_type:span @meta.model_provider:* @meta.span.kind:llm $host"
                      }
                    }
                  ],
                  "response_format": "scalar"
                }
              ],
              "autoscale": true,
              "precision": 2,
              "timeseries_background": {
                "yaxis": {},
                "type": "bars"
              }
            },
            "layout": {
              "x": 0,
              "y": 2,
              "width": 4,
              "height": 3
            }
          },
          {
            "id": 7853879441273475,
            "definition": {
              "title": "LLM Call Response Time (p95)",
              "title_size": "16",
              "title_align": "left",
              "type": "query_value",
              "requests": [
                {
                  "formulas": [
                    {
                      "number_format": {
                        "unit": {
                          "type": "canonical_unit",
                          "unit_name": "second"
                        }
                      },
                      "formula": "query1"
                    }
                  ],
                  "queries": [
                    {
                      "aggregator": "percentile",
                      "data_source": "metrics",
                      "name": "query1",
                      "query": "p95:ml_obs.span.duration{span_kind:llm, $host}"
                    }
                  ],
                  "response_format": "scalar"
                }
              ],
              "autoscale": true,
              "precision": 2,
              "timeseries_background": {
                "type": "area"
              }
            },
            "layout": {
              "x": 4,
              "y": 2,
              "width": 4,
              "height": 3
            }
          },
          {
            "id": 3452479763987419,
            "definition": {
              "title": "LLM Call Response Time (p50)",
              "title_size": "16",
              "title_align": "left",
              "type": "query_value",
              "requests": [
                {
                  "formulas": [
                    {
                      "formula": "query1",
                      "number_format": {
                        "unit": {
                          "type": "canonical_unit",
                          "unit_name": "second"
                        }
                      }
                    }
                  ],
                  "queries": [
                    {
                      "aggregator": "percentile",
                      "data_source": "metrics",
                      "name": "query1",
                      "query": "p50:ml_obs.span.duration{span_kind:llm,$host}"
                    }
                  ],
                  "response_format": "scalar"
                }
              ],
              "autoscale": true,
              "precision": 2,
              "timeseries_background": {
                "type": "area"
              }
            },
            "layout": {
              "x": 8,
              "y": 2,
              "width": 4,
              "height": 3
            }
          },
          {
            "id": 8174429076143416,
            "definition": {
              "title": "Model Usage",
              "title_size": "16",
              "title_align": "left",
              "requests": [
                {
                  "queries": [
                    {
                      "compute": {
                        "aggregation": "count"
                      },
                      "data_source": "llm_observability",
                      "group_by": [
                        {
                          "facet": "@meta.model_provider",
                          "limit": 10,
                          "sort": {
                            "aggregation": "count",
                            "order": "desc"
                          }
                        },
                        {
                          "facet": "@meta.model_name",
                          "limit": 10,
                          "sort": {
                            "aggregation": "count",
                            "order": "desc"
                          }
                        }
                      ],
                      "indexes": ["*"],
                      "name": "query2",
                      "search": {
                        "query": "@event_type:span @meta.model_provider:* @meta.span.kind:llm $host"
                      }
                    }
                  ],
                  "response_format": "scalar",
                  "style": {
                    "palette": "datadog16"
                  },
                  "formulas": [
                    {
                      "formula": "query2"
                    }
                  ],
                  "sort": {
                    "count": 500,
                    "order_by": [
                      {
                        "index": 0,
                        "order": "desc",
                        "type": "formula"
                      }
                    ]
                  }
                }
              ],
              "type": "sunburst",
              "hide_total": false,
              "legend": {
                "type": "table"
              },
              "custom_links": [
                {
                  "label": "View related spans in LLM Observability",
                  "link": "/llm/traces?query=@meta.model_name%3A{{@meta.model_name.value}}%20@event_type%3Aspan%20@parent_id%3A*%20@{{$ml_app}}%20{{$version}}&start={{timestamp_widget_start}}&end={{timestamp_widget_end}}&paused=false"
                }
              ]
            },
            "layout": {
              "x": 0,
              "y": 5,
              "width": 12,
              "height": 5
            }
          }
        ]
      },
      "layout": {
        "x": 0,
        "y": 14,
        "width": 12,
        "height": 11
      }
    }
  ],
  "template_variables": [
    {
      "name": "host",
      "prefix": "host",
      "available_values": [],
      "default": "*"
    }
  ],
  "layout_type": "ordered",
  "notify_list": [],
  "reflow_type": "fixed"
}
