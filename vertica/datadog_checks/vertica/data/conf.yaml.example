## All options defined here are available to all instances.
#
init_config:

    ## @param global_custom_queries - list of mappings - optional
    ## See `custom_queries` defined below.
    ##
    ## Global custom queries can be applied to all instances using the
    ## `use_global_custom_queries` setting at the instance level.
    #
    # global_custom_queries:
    #   - metric_prefix: vertica
    #     query: <QUERY>
    #     columns: <COLUMNS>
    #     tags: <TAGS>

    ## @param service - string - optional
    ## Attach the tag `service:<SERVICE>` to every metric, event, and service check emitted by this integration.
    ##
    ## Additionally, this sets the default `service` for every log source.
    #
    # service: <SERVICE>

## Every instance is scheduled independent of the others.
#
instances:

  -
    ## @param db - string - optional
    ## The name of the database to establish a connection with, defaulting to the `username`.
    #
    # db: <DATABASE_NAME>

    ## @param server - string - optional - default: localhost
    ## The hostname used to connect to the database.
    #
    # server: localhost

    ## @param port - integer - optional - default: 5433
    ## The port used to connect to the database.
    #
    # port: 5433

    ## @param metric_groups - list of strings - optional
    ## Enable metric groups for metric collection. Metric groups are based on Vertica tables.
    ## By default all metric groups are collected.
    #
    # metric_groups:
    #   - licenses
    #   - license_audits
    #   - system
    #   - nodes
    #   - projections
    #   - projection_storage
    #   - storage_containers
    #   - host_resources
    #   - query_metrics
    #   - resource_pool_status
    #   - disk_storage
    #   - resource_usage

    ## @param username - string - optional
    ## The database user to authenticate as.
    #
    # username: <USERNAME>

    ## @param password - string - optional
    ## The password of `username`.
    #
    # password: <PASSWORD>

    ## @param backup_servers - list of mappings - optional
    ## A list of backup servers to try if the primary `server` is unreachable.
    ## If no port is specified, `port` will be used.
    #
    # backup_servers:
    #   - server: <SERVER_1>
    #     port: <PORT_1>
    #   - server: <SERVER_2>
    #     port: <PORT_2>

    ## @param connection_load_balance - boolean - optional - default: false
    ## Whether or not to enable connection load balancing. This helps automatically spread
    ## the overhead caused by client connections across clusters by having hosts redirect
    ## client connections to other hosts. If the server disables connection load balancing,
    ## load balancing requests is ignored.
    ##
    ## Setting this to `true` will force the creation of a new connection at every check run.
    #
    # connection_load_balance: false

    ## @param timeout - integer - optional - default: 10
    ## The timeout for connecting to `server` or `backup_servers`.
    #
    # timeout: 10

    ## @param use_tls - boolean - optional - default: false
    ## This instructs the Vertica check to connect using TLS.
    #
    # use_tls: false

    ## @param tls_verify - boolean - optional - default: true
    ## Instructs the check to validate the TLS certificate(s) of the service(s).
    #
    # tls_verify: true

    ## @param tls_ca_cert - string - optional
    ## The path to a file of concatenated CA certificates in PEM format or a directory
    ## containing several CA certificates in PEM format. If a directory, the directory
    ## must have been processed using the c_rehash utility supplied with OpenSSL. See:
    ## https://www.openssl.org/docs/manmaster/man3/SSL_CTX_load_verify_locations.html
    ##
    ## Setting this implicitly sets `tls_verify` to true.
    #
    # tls_ca_cert: <CA_CERT_PATH>

    ## @param tls_cert - string - optional
    ## The path to a single file in PEM format containing a certificate as well as any
    ## number of CA certificates needed to establish the certificate's authenticity for
    ## use when connecting to services. It may also contain an unencrypted private key to use.
    ##
    ## Setting this implicitly sets `tls_verify` to true.
    #
    # tls_cert: <CERT_PATH>

    ## @param tls_private_key - string - optional
    ## The unencrypted private key to use for `tls_cert` when connecting to services. This is
    ## required if `tls_cert` is set and it does not already contain a private key.
    ##
    ## Setting this implicitly sets `tls_verify` to true.
    #
    # tls_private_key: <PRIVATE_KEY_PATH>

    ## @param tls_private_key_password - string - optional
    ## Optional password to decrypt tls_private_key.
    ##
    ## Setting this implicitly sets `tls_verify` to true.
    #
    # tls_private_key_password: <PRIVATE_KEY_PASSWORD>

    ## @param tls_validate_hostname - boolean - optional - default: true
    ## Verifies that the server's cert hostname matches the one requested.
    #
    # tls_validate_hostname: true

    ## @param tags - list of strings - optional
    ## A list of tags to attach to every metric and service check emitted by this instance.
    ##
    ## Learn more about tagging at https://docs.datadoghq.com/tagging
    #
    # tags:
    #   - <KEY_1>:<VALUE_1>
    #   - <KEY_2>:<VALUE_2>

    ## @param service - string - optional
    ## Attach the tag `service:<SERVICE>` to every metric, event, and service check emitted by this integration.
    ##
    ## Overrides any `service` defined in the `init_config` section.
    #
    # service: <SERVICE>

    ## @param min_collection_interval - number - optional - default: 15
    ## This changes the collection interval of the check. For more information, see:
    ## https://docs.datadoghq.com/developers/write_agent_check/#collection-interval
    #
    # min_collection_interval: 15

    ## @param empty_default_hostname - boolean - optional - default: false
    ## This forces the check to send metrics with no hostname.
    ##
    ## This is useful for cluster-level checks.
    #
    # empty_default_hostname: false

    ## @param only_custom_queries - boolean - optional - default: false
    ## Set this parameter to `true` if you want to skip the integration's default metrics collection.
    ## Only metrics specified in `custom_queries` will be collected.
    #
    # only_custom_queries: false

    ## @param use_global_custom_queries - string - optional - default: true
    ## How `global_custom_queries` should be used for this instance. There are 3 options:
    ##
    ## 1. true - `global_custom_queries` override `custom_queries`.
    ## 2. false - `custom_queries` override `global_custom_queries`.
    ## 3. extend - `global_custom_queries` are used in addition to any `custom_queries`.
    #
    # use_global_custom_queries: 'true'

    ## @param custom_queries - list of mappings - optional
    ## Each query must have 2 fields, and can have a third optional field:
    ##
    ## 1. query - The SQL to execute. It can be a simple statement or a multi-line script.
    ##            Use the pipe `|` if you require a multi-line script.
    ## 2. columns - The list representing each column, ordered sequentially from left to right.
    ##              The number of columns must equal the number of columns returned in the query.
    ##              There are 2 required pieces of data:
    ##                a. name - The suffix to append to `<INTEGRATION>.` to form
    ##                          the full metric name. If `type` is `tag`, this column is
    ##                          considered a tag and applied to every
    ##                          metric collected by this particular query.
    ##                b. type - The submission method (gauge, monotonic_count, etc.).
    ##                          This can also be set to `tag` to tag each metric in the row
    ##                          with the name and value of the item in this column. You can
    ##                          use the `count` type to perform aggregation for queries that
    ##                          return multiple rows with the same or no tags.
    ##              Columns without a name are ignored. To skip a column, enter:
    ##                - {}
    ## 3. tags (optional) - A list of tags to apply to each metric.
    #
    # custom_queries:
    #   - query: SELECT force_outer, table_name FROM v_catalog.tables
    #     columns:
    #     - name: table.force_outer
    #       type: gauge
    #     - name: table_name
    #       type: tag
    #     tags:
    #     - test: vertica

    ## @param client_lib_log_level - string - optional
    ## Vertica library log level.
    ## This option exists because vertica-python logging is disabled by default
    ## and must be enabled explicitly.
    ## When this option is not set, library logging is disabled, or set to DEBUG
    ## when the Agent log level is DEBUG or lower (TRACE).
    ## Valid values: CRITICAL, FATAL, ERROR, WARN, WARNING, INFO, DEBUG
    #
    # client_lib_log_level: <CLIENT_LIB_LOG_LEVEL>

## Log Section
##
## type - required - Type of log input source (tcp / udp / file / windows_event)
## port / path / channel_path - required - Set port if type is tcp or udp.
##                                         Set path if type is file.
##                                         Set channel_path if type is windows_event.
## source  - required - Attribute that defines which integration sent the logs.
## encoding - optional - For file specifies the file encoding, default is utf-8, other
##                       possible values are utf-16-le and utf-16-be.
## service - optional - The name of the service that generates the log.
##                      Overrides any `service` defined in the `init_config` section.
## tags - optional - Add tags to the collected logs.
##
## Discover Datadog log collection: https://docs.datadoghq.com/logs/log_collection/
#
# logs:
#   - source: vertica
#     type: file
#     path: /<CATALOG_PATH>/<DATABASE_NAME>/<NODE_NAME>_catalog/vertica.log
