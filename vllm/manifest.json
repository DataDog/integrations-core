{
  "manifest_version": "2.0.0",
  "app_uuid": "355886f0-31ae-44a9-9638-6951ad0f3039",
  "app_id": "vllm",
  "display_on_public_website": false,
  "tile": {
    "overview": "README.md#Overview",
    "configuration": "README.md#Setup",
    "support": "README.md#Support",
    "changelog": "CHANGELOG.md",
    "description": "vLLM is a library for LLM inference and serving",
    "title": "vLLM",
    "media": [],
    "classifier_tags": [
      "Supported OS::Linux",
      "Supported OS::Windows",
      "Supported OS::macOS",
      "Category::Log Collection",
      "Category::AI/ML",
      "Submitted Data Type::Metrics",
      "Offering::Integration"
    ]
  },
  "assets": {
    "integration": {
      "auto_install": true,
      "source_type_id": 17652503,
      "source_type_name": "vLLM",
      "configuration": {
        "spec": "assets/configuration/spec.yaml"
      },
      "events": {
        "creates_events": false
      },
      "metrics": {
        "prefix": "vllm.",
        "check": "vllm.num_requests.running",
        "metadata_path": "metadata.csv"
      },
      "service_checks": {
        "metadata_path": "assets/service_checks.json"
      }
    },
    "monitors": {
      "token_throughput": "assets/monitors/token_throughput.json",
      "latency": "assets/monitors/latency.json"
    }
  },
  "author": {
    "support_email": "help@datadoghq.com",
    "name": "Datadog",
    "homepage": "https://www.datadoghq.com",
    "sales_email": "info@datadoghq.com"
  }
}