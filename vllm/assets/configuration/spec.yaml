name: vLLM
files:
- name: vllm.yaml
  options:
  - template: init_config
    options:
    - template: init_config/openmetrics
  - template: instances
    options:
    - template: instances/openmetrics
      overrides:
        openmetrics_endpoint.required: true
        openmetrics_endpoint.value.example: http://localhost:8000/metrics
        openmetrics_endpoint.description: |
          Endpoint exposing the vLLM's Prometheus metrics. For more information refer to:
          https://docs.vllm.ai/en/stable/serving/metrics.html
