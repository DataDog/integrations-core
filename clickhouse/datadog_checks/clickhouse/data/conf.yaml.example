init_config:
    ## @param global_custom_queries - list - optional
    ## See `custom_queries` defined below.
    ##
    ## Global custom queries can be applied to all instances using the
    ## `use_global_custom_queries` setting at the instance level.
    #
    # global_custom_queries:
    #   - metric_prefix: clickhouse
    #     query: <QUERY>
    #     columns: <COLUMNS>
    #     tags: <TAGS>

instances:

    ## @param server - string - required
    ## The hostname used to connect to the system.
    #
  - server: <SERVER>

    ## @param port - integer - optional - default: 9000
    ## The port used to connect to the system.
    #
    # port: 9000

    ## @param user - string - optional - default: default
    ## The database user to authenticate as.
    #
    # user: default

    ## @param password - string - optional
    ## The password of `username`.
    #
    # password: <PASSWORD>

    ## @param db - string - optional - default: default
    ## The database to connect to.
    #
    # db: default

    ## @param connect_timeout - integer - optional - default: 10
    ## The timeout for connecting to the `server`.
    #
    # connect_timeout: 10

    ## @param read_timeout - integer - optional - default: 10
    ## The timeout for reading from the `server`.
    #
    # read_timeout: 10

    ## @param compression - string - optional
    ## The compression algorithm to use. The default is no compression.
    ##
    ## Valid values are:
    ##
    ##   - lz4
    ##   - lz4hc
    #
    # compression: <COMPRESSION>

    ## @param tls_verify - boolean - optional - default: false
    ## Whether or not to connect securely using TLS. The server must also support this.
    #
    # tls_verify: false

    ## @param tags - list of strings following the pattern: "key:value" - optional
    ## List of tags to attach to every metric and service check emitted by this instance.
    ##
    ## Learn more about tagging at https://docs.datadoghq.com/tagging
    #
    # tags:
    #   - <KEY_1>:<VALUE_1>
    #   - <KEY_2>:<VALUE_2>

    ## @param use_global_custom_queries - string - optional - default: true
    ## How `global_custom_queries` should be used for this instance. There are 3 options:
    ##
    ## 1. true - `global_custom_queries` override `custom_queries`.
    ## 2. false - `custom_queries` override `global_custom_queries`.
    ## 2. extend - `global_custom_queries` are used in addition to any `custom_queries`.
    #
    # use_global_custom_queries: true

    ## @param custom_queries - list - optional
    ## Each query must have 2 fields:
    ##
    ## 1. query - The SQL to execute. It can be a simple statement or a multi-line script.
    ## 2. columns - The list representing each column, ordered sequentially from left to right.
    ##              The number of columns must equal the number of columns returned in the query.
    ##              There are 2 required pieces of data:
    ##                a. name - The suffix to append to `clickhouse.` to form
    ##                          the full metric name. If `type` is `tag`, this column is
    ##                          considered a tag and applied to every
    ##                          metric collected by this particular query.
    ##                b. type - The submission method (gauge, monotonic_count, etc.).
    ##                          This can also be set to `tag` to tag each metric in the row
    ##                          with the name and value of the item in this column. You can
    ##                          use the `count` type to perform aggregation for queries that
    ##                          return multiple rows with the same or no tags.
    ## 3. tags (optional) - A list of tags to apply to each metric.
    #
    # custom_queries:
    #   - query: |  # Use the pipe if you require a multi-line script.
    #       SELECT foo,
    #              COUNT(*)
    #       FROM table.events
    #       GROUP BY foo
    #     columns:
    #       # Columns without a name are ignored, use this for any column you wish to skip:
    #       # - {}
    #       - name: foo
    #         type: tag
    #       - name: event.total
    #         type: gauge
    #     tags:
    #       - test:clickhouse

## Log Section (Available for Agent >=6.0)
##
## type - mandatory - Type of log input source (tcp / udp / file / windows_event)
## port / path / channel_path - mandatory - Set port if the type is tcp or udp. Set path if the type is file. Set channel_path if the type is windows_event.
## service - mandatory - Name of the service that generated the log
## source  - mandatory - An attribute that defines which integration sent the logs.
## tags: - optional - Add tags to the collected logs
##
## Discover Datadog log collection: https://docs.datadoghq.com/logs/log_collection/
#
# logs:
#   - source: clickhouse
#     type: file
#     path: /var/log/clickhouse-server/clickhouse-server.log
#     service: <APPLICATION_NAME>
#     log_processing_rules:
#       - type: multi_line
#         name: log_start_with_date
#         pattern: \d{4}\.\d{2}\.\d{2}
#
#   - source: clickhouse
#     type: file
#     path: /var/log/clickhouse-server/clickhouse-server.err.log
#     service: <APPLICATION_NAME>
#     log_processing_rules:
#       - type: multi_line
#         name: log_start_with_date
#         pattern: \d{4}\.\d{2}\.\d{2}
