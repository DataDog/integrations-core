metric_name,metric_type,interval,unit_name,per_unit_name,description,orientation,integration,short_name
clickhouse.background_pool.processing.task.active,gauge,,task,,"The number of active tasks in BackgroundProcessingPool (merges, mutations, fetches, or replication queue bookkeeping)",-1,clickhouse,
clickhouse.background_pool.move.task.active,gauge,,task,,"The number of active tasks in BackgroundProcessingPool for moves",-1,clickhouse,
clickhouse.background_pool.schedule.task.active,gauge,,task,,"The number of active tasks in BackgroundSchedulePool. This pool is used for periodic ReplicatedMergeTree tasks, like cleaning old data parts, altering data parts, replica re-initialization, etc.",-1,clickhouse,
clickhouse.thread.lock.context.waiting,gauge,,thread,,The number of threads waiting for lock in Context. This is global lock.,-1,clickhouse,
clickhouse.query.insert.delayed,gauge,,query,,The number of INSERT queries that are throttled due to high number of active data parts for partition in a MergeTree table.,-1,clickhouse,
clickhouse.dictionary.request.cache,gauge,,request,,The number of requests in fly to data sources of dictionaries of cache type.,0,clickhouse,
clickhouse.merge.disk.reserved,gauge,,byte,,Disk space reserved for currently running background merges. It is slightly more than the total size of currently merging parts.,0,clickhouse,
clickhouse.table.distributed.file.insert.pending,gauge,,file,,The number of pending files to process for asynchronous insertion into Distributed tables. Number of files for every shard is summed.,0,clickhouse,
clickhouse.table.distributed.connection.inserted,gauge,,connection,,The number of connections to remote servers sending data that was INSERTed into Distributed tables. Both synchronous and asynchronous mode.,0,clickhouse,
clickhouse.zk.node.ephemeral,gauge,,node,,The number of ephemeral nodes hold in ZooKeeper.,0,clickhouse,
clickhouse.thread.global.total,gauge,,thread,,The number of threads in global thread pool.,0,clickhouse,
clickhouse.thread.global.active,gauge,,thread,,The number of threads in global thread pool running a task.,0,clickhouse,
clickhouse.connection.http,gauge,,connection,,The number of connections to HTTP server,0,clickhouse,
clickhouse.connection.interserver,gauge,,connection,,The number of connections from other replicas to fetch parts,0,clickhouse,
clickhouse.replica.leader.election,gauge,,shard,,The number of Replicas participating in leader election. Equals to total number of replicas in usual cases.,0,clickhouse,
clickhouse.table.replicated.leader,gauge,,table,,"The number of Replicated tables that are leaders. Leader replica is responsible for assigning merges, cleaning old blocks for deduplications and a few more bookkeeping tasks. There may be no more than one leader across all replicas at one moment of time. If there is no leader it will be elected soon or it indicate an issue.",0,clickhouse,
clickhouse.thread.local.total,gauge,,thread,,The number of threads in local thread pools. Should be similar to GlobalThreadActive.,0,clickhouse,
clickhouse.thread.local.active,gauge,,thread,,The number of threads in local thread pools running a task.,0,clickhouse,
clickhouse.query.memory,gauge,,byte,,Total amount of memory allocated in currently executing queries. Note that some memory allocations may not be accounted.,0,clickhouse,
clickhouse.merge.memory,gauge,,byte,,Total amount of memory allocated for background merges. Included in MemoryTrackingInBackgroundProcessingPool. Note that this value may include a drift when the memory was allocated in a context of background processing pool and freed in other context or vice-versa. This happens naturally due to caches for tables indexes and doesn't indicate memory leaks.,0,clickhouse,
clickhouse.background_pool.processing.memory,gauge,,byte,,"Total amount of memory allocated in background processing pool (that is dedicated for backround merges, mutations and fetches). Note that this value may include a drift when the memory was allocated in a context of background processing pool and freed in other context or vice-versa. This happens naturally due to caches for tables indexes and doesn't indicate memory leaks.",0,clickhouse,
clickhouse.background_pool.move.memory,gauge,,byte,,"Total amount of memory (bytes) allocated in background processing pool (that is dedicated for backround moves). Note that this value may include a drift when the memory was allocated in a context of background processing pool and freed in other context or vice-versa. This happens naturally due to caches for tables indexes and doesn't indicate memory leaks.",0,clickhouse,
clickhouse.background_pool.schedule.memory,gauge,,byte,,Total amount of memory allocated in background schedule pool (that is dedicated for bookkeeping tasks of Replicated tables).,0,clickhouse,
clickhouse.merge.active,gauge,,merge,,The number of executing background merges,0,clickhouse,
clickhouse.file.open.read,gauge,,file,,The number of files open for reading,0,clickhouse,
clickhouse.file.open.write,gauge,,file,,The number of files open for writing,0,clickhouse,
clickhouse.query.mutation,gauge,,query,,The number of mutations (ALTER DELETE/UPDATE),0,clickhouse,
clickhouse.query.active,gauge,,query,,The number of executing queries,0,clickhouse,
clickhouse.query.waiting,gauge,,query,,The number of queries that are stopped and waiting due to 'priority' setting.,0,clickhouse,
clickhouse.thread.query,gauge,,thread,,The number of query processing threads,0,clickhouse,
clickhouse.thread.lock.rw.active.read,gauge,,thread,,The number of threads holding read lock in a table RWLock.,0,clickhouse,
clickhouse.thread.lock.rw.active.write,gauge,,thread,,The number of threads holding write lock in a table RWLock.,0,clickhouse,
clickhouse.thread.lock.rw.waiting.read,gauge,,thread,,The number of threads waiting for read on a table RWLock.,0,clickhouse,
clickhouse.thread.lock.rw.waiting.write,gauge,,thread,,The number of threads waiting for write on a table RWLock.,0,clickhouse,
clickhouse.syscall.read,gauge,,read,,"The number of read (read, pread, io_getevents, etc.) syscalls in fly",0,clickhouse,
clickhouse.table.replicated.readonly,gauge,,table,,The number of Replicated tables that are currently in readonly state due to re-initialization after ZooKeeper session loss or due to startup without ZooKeeper configured.,0,clickhouse,
clickhouse.table.replicated.part.check,gauge,,item,,The number of data parts checking for consistency,0,clickhouse,
clickhouse.table.replicated.part.fetch,gauge,,item,,The number of data parts being fetched from replica,0,clickhouse,
clickhouse.table.replicated.part.send,gauge,,item,,The number of data parts being sent to replicas,0,clickhouse,
clickhouse.connection.send.external,gauge,,connection,,The number of connections that are sending data for external tables to remote servers. External tables are used to implement GLOBAL IN and GLOBAL JOIN operators with distributed subqueries.,0,clickhouse,
clickhouse.connection.send.scalar,gauge,,connection,,The number of connections that are sending data for scalars to remote servers.,0,clickhouse,
clickhouse.table.buffer.size,gauge,,byte,,Size of buffers of Buffer tables,0,clickhouse,
clickhouse.table.buffer.row,gauge,,row,,The number of rows in buffers of Buffer tables,0,clickhouse,
clickhouse.connection.mysql,gauge,,connection,,Number of client connections using MySQL protocol,0,clickhouse,
clickhouse.connection.tcp,gauge,,connection,,The number of connections to TCP server (clients with native interface),0,clickhouse,
clickhouse.syscall.write,gauge,,write,,"The number of write (write, pwrite, io_getevents, etc.) syscalls in fly",0,clickhouse,
clickhouse.zk.request,gauge,,request,,The number of requests to ZooKeeper in fly.,0,clickhouse,
clickhouse.zk.connection,gauge,,connection,,"The number of sessions (connections) to ZooKeeper. Should be no more than one, because using more than one connection to ZooKeeper may lead to bugs due to lack of linearizability (stale reads) that ZooKeeper consistency model allows.",0,clickhouse,
clickhouse.zk.watch,gauge,,event,,The number of watches (event subscriptions) in ZooKeeper.,0,clickhouse,
clickhouse.lock.context.acquisition.count,count,,event,,The number of times the lock of Context was acquired or tried to acquire during the last interval. This is global lock.,0,clickhouse,
clickhouse.lock.context.acquisition.total,gauge,,event,,The total number of times the lock of Context was acquired or tried to acquire. This is global lock.,0,clickhouse,
clickhouse.syscall.write.wait,gauge,,percent,,The percentage of time spent waiting for write syscall during the last interval. This include writes to page cache.,0,clickhouse,
clickhouse.file.open.count,count,,file,,The number of files opened during the last interval.,0,clickhouse,
clickhouse.file.open.total,gauge,,file,,The total number of files opened.,0,clickhouse,
clickhouse.query.count,count,,query,,"The number of queries to be interpreted and potentially executed during the last interval. Does not include queries that failed to parse or were rejected due to AST size limits, quota limits or limits on the number of simultaneously running queries. May include internal queries initiated by ClickHouse itself. Does not count subqueries.",0,clickhouse,
clickhouse.query.total,gauge,,query,,"The total number of queries to be interpreted and potentially executed. Does not include queries that failed to parse or were rejected due to AST size limits, quota limits or limits on the number of simultaneously running queries. May include internal queries initiated by ClickHouse itself. Does not count subqueries.",0,clickhouse,
clickhouse.file.read.count,count,,read,,The number of reads (read/pread) from a file descriptor during the last interval. Does not include sockets.,0,clickhouse,
clickhouse.file.read.total,gauge,,read,,The total number of reads (read/pread) from a file descriptor. Does not include sockets.,0,clickhouse,
clickhouse.thread.process_time,gauge,,percent,,The percentage of time spent processing (queries and other tasks) threads during the last interval.,0,clickhouse,
clickhouse.query.insert.count,count,,query,,"The number of INSERT queries to be interpreted and potentially executed during the last interval. Does not include queries that failed to parse or were rejected due to AST size limits, quota limits or limits on the number of simultaneously running queries. May include internal queries initiated by ClickHouse itself. Does not count subqueries.",0,clickhouse,
clickhouse.query.insert.total,gauge,,query,,"The total number of INSERT queries to be interpreted and potentially executed. Does not include queries that failed to parse or were rejected due to AST size limits, quota limits or limits on the number of simultaneously running queries. May include internal queries initiated by ClickHouse itself. Does not count subqueries.",0,clickhouse,
clickhouse.query.select.count,count,,query,,"The number of SELECT queries to be interpreted and potentially executed during the last interval. Does not include queries that failed to parse or were rejected due to AST size limits, quota limits or limits on the number of simultaneously running queries. May include internal queries initiated by ClickHouse itself. Does not count subqueries.",0,clickhouse,
clickhouse.query.select.total,gauge,,query,,"The total number of SELECT queries to be interpreted and potentially executed. Does not include queries that failed to parse or were rejected due to AST size limits, quota limits or limits on the number of simultaneously running queries. May include internal queries initiated by ClickHouse itself. Does not count subqueries.",0,clickhouse,
clickhouse.thread.system.process_time,gauge,,percent,,"The percentage of time spent processing (queries and other tasks) threads executing CPU instructions in OS kernel space during the last interval. This includes time CPU pipeline was stalled due to cache misses, branch mispredictions, hyper-threading, etc.",0,clickhouse,
clickhouse.thread.user.process_time,gauge,,percent,,"The percentage of time spent processing (queries and other tasks) threads executing CPU instructions in user space during the last interval. This includes time CPU pipeline was stalled due to cache misses, branch mispredictions, hyper-threading, etc.",0,clickhouse,
clickhouse.file.write.count,count,,write,,The number of writes (write/pwrite) to a file descriptor during the last interval. Does not include sockets.,0,clickhouse,
clickhouse.file.write.total,gauge,,write,,The total number of writes (write/pwrite) to a file descriptor. Does not include sockets.,0,clickhouse,
clickhouse.file.write.size.count,count,,byte,,"The number of bytes written to file descriptors during the last interval. If the file is compressed, this will show compressed data size.",0,clickhouse,
clickhouse.file.write.size.total,gauge,,byte,,"The total number of bytes written to file descriptors during the last interval. If the file is compressed, this will show compressed data size.",0,clickhouse,
clickhouse.node.remove.count,count,,error,,"The number of times an error happened while trying to remove ephemeral node during the last interval. This is usually not an issue, because ClickHouse's implementation of ZooKeeper library guarantees that the session will expire and the node will be removed.",0,clickhouse,
clickhouse.node.remove.total,gauge,,error,,"The total number of times an error happened while trying to remove ephemeral node. This is usually not an issue, because ClickHouse's implementation of ZooKeeper library guarantees that the session will expire and the node will be removed.",0,clickhouse,
clickhouse.buffer.write.discard.count,count,,error,,The number of stack traces dropped by query profiler or signal handler because pipe is full or cannot write to pipe during the last interval.,0,clickhouse,
clickhouse.buffer.write.discard.total,gauge,,error,,The total number of stack traces dropped by query profiler or signal handler because pipe is full or cannot write to pipe.,0,clickhouse,
clickhouse.compilation.attempt.count,count,,event,,The number of times a compilation of generated C++ code was initiated during the last interval.,0,clickhouse,
clickhouse.compilation.attempt.total,gauge,,event,,The total number of times a compilation of generated C++ code was initiated.,0,clickhouse,
clickhouse.compilation.size.count,count,,byte,,The number of bytes used for expressions compilation during the last interval.,0,clickhouse,
clickhouse.compilation.size.total,gauge,,byte,,The total number of bytes used for expressions compilation.,0,clickhouse,
clickhouse.compilation.time,gauge,,percent,,The percentage of time spent for compilation of expressions to LLVM code during the last interval.,0,clickhouse,
clickhouse.compilation.llvm.attempt.count,count,,event,,The number of times a compilation of generated LLVM code (to create fused function for complex expressions) was initiated during the last interval.,0,clickhouse,
clickhouse.compilation.llvm.attempt.total,gauge,,event,,The total number of times a compilation of generated LLVM code (to create fused function for complex expressions) was initiated.,0,clickhouse,
clickhouse.compilation.success.count,count,,event,,The number of times a compilation of generated C++ code was successful during the last interval.,0,clickhouse,
clickhouse.compilation.success.total,gauge,,event,,The total number of times a compilation of generated C++ code was successful.,0,clickhouse,
clickhouse.compilation.function.execute.count,count,,execution,,The number of times a compiled function was executed during the last interval.,0,clickhouse,
clickhouse.compilation.function.execute.total,gauge,,execution,,The total number of times a compiled function was executed.,0,clickhouse,
clickhouse.connection.http.create.count,count,,connection,,The number of created HTTP connections (closed or opened) during the last interval.,0,clickhouse,
clickhouse.connection.http.create.total,gauge,,connection,,The total number of created HTTP connections (closed or opened).,0,clickhouse,
clickhouse.table.mergetree.insert.delayed.count,count,,throttle,,The number of times the INSERT of a block to a MergeTree table was throttled due to high number of active data parts for partition during the last interval.,0,clickhouse,
clickhouse.table.mergetree.insert.delayed.total,gauge,,throttle,,The total number of times the INSERT of a block to a MergeTree table was throttled due to high number of active data parts for partition.,0,clickhouse,
clickhouse.table.mergetree.insert.delayed.time,gauge,,percent,,The percentage of time spent while the INSERT of a block to a MergeTree table was throttled due to high number of active data parts for partition during the last interval.,0,clickhouse,
clickhouse.syscall.read.wait,gauge,,percent,,The percentage of time spent waiting for read syscall during the last interval. This includes reads from page cache.,0,clickhouse,
clickhouse.table.mergetree.replicated.insert.deduplicate.count,count,,operation,,The number of times the INSERTed block to a ReplicatedMergeTree table was deduplicated during the last interval.,0,clickhouse,
clickhouse.table.mergetree.replicated.insert.deduplicate.total,gauge,,operation,,The total number of times the INSERTed block to a ReplicatedMergeTree table was deduplicated.,0,clickhouse,
clickhouse.table.insert.size.count,count,,byte,,The number of bytes (uncompressed; for columns as they stored in memory) INSERTed to all tables during the last interval.,0,clickhouse,
clickhouse.table.insert.size.total,gauge,,byte,,The total number of bytes (uncompressed; for columns as they stored in memory) INSERTed to all tables.,0,clickhouse,
clickhouse.table.insert.row.count,count,,row,,The number of rows INSERTed to all tables during the last interval.,0,clickhouse,
clickhouse.table.insert.row.total,gauge,,row,,The total number of rows INSERTed to all tables.,0,clickhouse,
clickhouse.table.mergetree.replicated.leader.elected.count,count,,event,,"The number of times a ReplicatedMergeTree table became a leader during the last interval. Leader replica is responsible for assigning merges, cleaning old blocks for deduplications and a few more bookkeeping tasks.",0,clickhouse,
clickhouse.table.mergetree.replicated.leader.elected.total,gauge,,event,,"The total number of times a ReplicatedMergeTree table became a leader. Leader replica is responsible for assigning merges, cleaning old blocks for deduplications and a few more bookkeeping tasks.",0,clickhouse,
clickhouse.merge.count,count,,merge,,The number of launched background merges during the last interval.,0,clickhouse,
clickhouse.merge.total,gauge,,merge,,The total number of launched background merges.,0,clickhouse,
clickhouse.table.mergetree.insert.block.count,count,,block,,The number of blocks INSERTed to MergeTree tables during the last interval. Each block forms a data part of level zero.,0,clickhouse,
clickhouse.table.mergetree.insert.block.total,gauge,,block,,The total number of blocks INSERTed to MergeTree tables. Each block forms a data part of level zero.,0,clickhouse,
clickhouse.table.mergetree.insert.block.already_sorted.count,count,,block,,The number of blocks INSERTed to MergeTree tables that appeared to be already sorted during the last interval.,0,clickhouse,
clickhouse.table.mergetree.insert.block.already_sorted.total,gauge,,block,,The total number of blocks INSERTed to MergeTree tables that appeared to be already sorted.,0,clickhouse,
clickhouse.table.mergetree.insert.write.size.compressed.count,count,,byte,,The number of bytes written to filesystem for data INSERTed to MergeTree tables during the last interval.,0,clickhouse,
clickhouse.table.mergetree.insert.write.size.compressed.total,gauge,,byte,,The total number of bytes written to filesystem for data INSERTed to MergeTree tables.,0,clickhouse,
clickhouse.table.mergetree.insert.row.count,count,,row,,The number of rows INSERTed to MergeTree tables during the last interval.,0,clickhouse,
clickhouse.table.mergetree.insert.row.total,gauge,,row,,The total number of rows INSERTed to MergeTree tables.,0,clickhouse,
clickhouse.table.mergetree.insert.write.size.uncompressed.count,count,,byte,,The number of uncompressed bytes (for columns as they are stored in memory) INSERTed to MergeTree tables during the last interval.,0,clickhouse,
clickhouse.table.mergetree.insert.write.size.uncompressed.total,gauge,,byte,,The total number of uncompressed bytes (for columns as they are stored in memory) INSERTed to MergeTree tables.,0,clickhouse,
clickhouse.merge.row.read.count,count,,row,,The number of rows read for background merges during the last interval. This is the number of rows before merge.,0,clickhouse,
clickhouse.merge.row.read.total,gauge,,row,,The total number of rows read for background merges. This is the number of rows before merge.,0,clickhouse,
clickhouse.merge.read.size.uncompressed.count,count,,byte,,The number of uncompressed bytes (for columns as they are stored in memory) that was read for background merges during the last interval. This is the number before merge.,0,clickhouse,
clickhouse.merge.read.size.uncompressed.total,gauge,,byte,,The total number of uncompressed bytes (for columns as they are stored in memory) that was read for background merges. This is the number before merge.,0,clickhouse,
clickhouse.merge.time,gauge,,percent,,The percentage of time spent for background merges during the last interval.,0,clickhouse,
clickhouse.cpu.time,gauge,,percent,,The percentage of CPU time spent seen by OS during the last interval. Does not include involuntary waits due to virtualization.,0,clickhouse,
clickhouse.thread.cpu.wait,gauge,,percent,,The percentage of time a thread was ready for execution but waiting to be scheduled by OS (from the OS point of view) during the last interval.,0,clickhouse,
clickhouse.thread.io.wait,gauge,,percent,,The percentage of time a thread spent waiting for a result of IO operation (from the OS point of view) during the last interval. This is real IO that doesn't include page cache.,0,clickhouse,
clickhouse.disk.read.size.count,count,,byte,,"The number of bytes read from disks or block devices during the last interval. Doesn't include bytes read from page cache. May include excessive data due to block size, readahead, etc.",0,clickhouse,
clickhouse.disk.read.size.total,gauge,,byte,,"The total number of bytes read from disks or block devices. Doesn't include bytes read from page cache. May include excessive data due to block size, readahead, etc.",0,clickhouse,
clickhouse.fs.read.size.count,count,,byte,,The number of bytes read from filesystem (including page cache) during the last interval.,0,clickhouse,
clickhouse.fs.read.size.total,gauge,,byte,,The total number of bytes read from filesystem (including page cache).,0,clickhouse,
clickhouse.disk.write.size.count,count,,byte,,The number of bytes written to disks or block devices during the last interval. Doesn't include bytes that are in page cache dirty pages. May not include data that was written by OS asynchronously.,0,clickhouse,
clickhouse.disk.write.size.total,gauge,,byte,,The total number of bytes written to disks or block devices. Doesn't include bytes that are in page cache dirty pages. May not include data that was written by OS asynchronously.,0,clickhouse,
clickhouse.fs.write.size.count,count,,byte,,The number of bytes written to filesystem (including page cache) during the last interval.,0,clickhouse,
clickhouse.fs.write.size.total,gauge,,byte,,The total number of bytes written to filesystem (including page cache).,0,clickhouse,
clickhouse.query.mask.match.count,count,,occurrence,,The number of times query masking rules were successfully matched during the last interval.,0,clickhouse,
clickhouse.query.mask.match.total,gauge,,occurrence,,The total number of times query masking rules were successfully matched.,0,clickhouse,
clickhouse.query.signal.dropped.count,count,,occurrence,,The number of times the processing of a signal was dropped due to overrun plus the number of signals that the OS has not delivered due to overrun during the last interval.,0,clickhouse,
clickhouse.query.signal.dropped.total,gauge,,occurrence,,The total number of times the processing of a signal was dropped due to overrun plus the number of signals that the OS has not delivered due to overrun.,0,clickhouse,
clickhouse.query.read.backoff.count,count,,occurrence,,The number of times the number of query processing threads was lowered due to slow reads during the last interval.,0,clickhouse,
clickhouse.query.read.backoff.total,gauge,,occurrence,,The total number of times the number of query processing threads was lowered due to slow reads.,0,clickhouse,
clickhouse.file.read.size.count,count,,byte,,"The number of bytes read from file descriptors during the last interval. If the file is compressed, this will show the compressed data size.",0,clickhouse,
clickhouse.file.read.size.total,gauge,,byte,,"The total number of bytes read from file descriptors. If the file is compressed, this will show the compressed data size.",0,clickhouse,
clickhouse.file.read.fail.count,count,,read,,The number of times the read (read/pread) from a file descriptor have failed during the last interval.,0,clickhouse,
clickhouse.file.read.fail.total,gauge,,read,,The total number of times the read (read/pread) from a file descriptor have failed.,0,clickhouse,
clickhouse.compilation.regex.count,count,,event,,The number of regular expressions compiled during the last interval. Identical regular expressions are compiled just once and cached forever.,0,clickhouse,
clickhouse.compilation.regex.total,gauge,,event,,The total number of regular expressions compiled. Identical regular expressions are compiled just once and cached forever.,0,clickhouse,
clickhouse.table.mergetree.insert.block.rejected.count,count,,block,,The number of times the INSERT of a block to a MergeTree table was rejected with `Too many parts` exception due to high number of active data parts for partition during the last interval.,0,clickhouse,
clickhouse.table.mergetree.insert.block.rejected.total,gauge,,block,,The total number of times the INSERT of a block to a MergeTree table was rejected with `Too many parts` exception due to high number of active data parts for partition.,0,clickhouse,
clickhouse.table.replicated.leader.yield.count,count,,event,,The number of times Replicated table yielded its leadership due to large replication lag relative to other replicas during the last interval.,0,clickhouse,
clickhouse.table.replicated.leader.yield.total,gauge,,event,,The total number of times Replicated table yielded its leadership due to large replication lag relative to other replicas.,0,clickhouse,
clickhouse.table.replicated.part.loss.count,count,,item,,"The number of times a data part we wanted doesn't exist on any replica (even on replicas that are offline right now) during the last interval. Those data parts are definitely lost. This is normal due to asynchronous replication (if quorum inserts were not enabled), when the replica on which the data part was written failed and when it became online after fail it doesn't contain that data part.",0,clickhouse,
clickhouse.table.replicated.part.loss.total,gauge,,item,,"The total number of times a data part that we wanted doesn't exist on any replica (even on replicas that are offline right now). That data parts are definitely lost. This is normal due to asynchronous replication (if quorum inserts were not enabled), when the replica on which the data part was written failed and when it became online after fail it doesn't contain that data part.",0,clickhouse,
clickhouse.table.mergetree.replicated.fetch.replica.count,count,,fetch,,The number of times a data part was downloaded from replica of a ReplicatedMergeTree table during the last interval.,0,clickhouse,
clickhouse.table.mergetree.replicated.fetch.replica.total,gauge,,fetch,,The total number of times a data part was downloaded from replica of a ReplicatedMergeTree table.,0,clickhouse,
clickhouse.table.mergetree.replicated.fetch.merged.count,count,,fetch,,The number of times ClickHouse prefers to download already merged part from replica of ReplicatedMergeTree table instead of performing a merge itself (usually it prefers doing a merge itself to save network traffic) during the last interval. This happens when ClickHouse does not have all source parts to perform a merge or when the data part is old enough.,0,clickhouse,
clickhouse.table.mergetree.replicated.fetch.merged.total,gauge,,fetch,,The total number of times ClickHouse prefers to download already merged part from replica of ReplicatedMergeTree table instead of performing a merge itself (usually it prefers doing a merge itself to save network traffic). This happens when ClickHouse does not have all source parts to perform a merge or when the data part is old enough.,0,clickhouse,
clickhouse.file.seek.count,count,,operation,,The number of times the `lseek` function was called during the last interval.,0,clickhouse,
clickhouse.file.seek.total,gauge,,operation,,The total number of times the `lseek` function was called.,0,clickhouse,
clickhouse.table.mergetree.mark.selected.count,count,,index,,The number of marks (index granules) selected to read from a MergeTree table during the last interval.,0,clickhouse,
clickhouse.table.mergetree.mark.selected.total,gauge,,index,,The total number of marks (index granules) selected to read from a MergeTree table.,0,clickhouse,
clickhouse.table.mergetree.part.selected.count,count,,item,,The number of data parts selected to read from a MergeTree table during the last interval.,0,clickhouse,
clickhouse.table.mergetree.part.selected.total,gauge,,item,,The total number of data parts selected to read from a MergeTree table.,0,clickhouse,
clickhouse.table.mergetree.range.selected.count,count,,item,,The number of non-adjacent ranges in all data parts selected to read from a MergeTree table during the last interval.,0,clickhouse,
clickhouse.table.mergetree.range.selected.total,gauge,,item,,The total number of non-adjacent ranges in all data parts selected to read from a MergeTree table.,0,clickhouse,
clickhouse.file.read.slow.count,count,,read,,The number of reads from a file that were slow during the last interval. This indicates system overload. Thresholds are controlled by read_backoff_* settings.,0,clickhouse,
clickhouse.file.read.slow.total,gauge,,read,,The total number of reads from a file that were slow. This indicates system overload. Thresholds are controlled by read_backoff_* settings.,0,clickhouse,
clickhouse.query.sleep.time,gauge,,percent,,The percentage of time a query was sleeping to conform to the `max_network_bandwidth` setting during the last interval.,0,clickhouse,
clickhouse.file.write.fail.count,count,,write,,The number of times the write (write/pwrite) to a file descriptor have failed during the last interval.,0,clickhouse,
clickhouse.file.write.fail.total,gauge,,write,,The total number of times the write (write/pwrite) to a file descriptor have failed.,0,clickhouse,
clickhouse.CompiledExpressionCacheCount,gauge,,item,,(EXPERIMENTAL) This metric will be renamed in a future minor release.,0,clickhouse,
clickhouse.table.mergetree.storage.mark.cache,gauge,,byte,,The size of the cache of `marks` for StorageMergeTree.,0,clickhouse,
clickhouse.MarkCacheFiles,gauge,,item,,(EXPERIMENTAL) This metric will be renamed in a future minor release.,0,clickhouse,
clickhouse.part.max,gauge,,item,,The maximum number of active parts in partitions.,0,clickhouse,
clickhouse.database.total,gauge,,instance,,The current number of databases.,0,clickhouse,
clickhouse.table.total,gauge,,table,,The current number of tables.,0,clickhouse,
clickhouse.replica.delay.absolute,gauge,,millisecond,,The maximum replica queue delay relative to current time.,0,clickhouse,
clickhouse.ReplicasMaxInsertsInQueue,gauge,,item,,(EXPERIMENTAL) This metric will be renamed in a future minor release.,0,clickhouse,
clickhouse.ReplicasMaxMergesInQueue,gauge,,item,,(EXPERIMENTAL) This metric will be renamed in a future minor release.,0,clickhouse,
clickhouse.ReplicasMaxQueueSize,gauge,,item,,(EXPERIMENTAL) This metric will be renamed in a future minor release.,0,clickhouse,
clickhouse.replica.delay.relative,gauge,,millisecond,,The maximum difference of absolute delay from any other replica.,0,clickhouse,
clickhouse.ReplicasSumInsertsInQueue,gauge,,item,,(EXPERIMENTAL) This metric will be renamed in a future minor release.,0,clickhouse,
clickhouse.ReplicasSumMergesInQueue,gauge,,item,,(EXPERIMENTAL) This metric will be renamed in a future minor release.,0,clickhouse,
clickhouse.replica.queue.size,gauge,,task,,The number of replication tasks in queue.,0,clickhouse,
clickhouse.UncompressedCacheBytes,gauge,,byte,,(EXPERIMENTAL) This metric will be renamed in a future minor release.,0,clickhouse,
clickhouse.UncompressedCacheCells,gauge,,item,,(EXPERIMENTAL) This metric will be renamed in a future minor release.,0,clickhouse,
clickhouse.uptime,gauge,,second,,The amount of time ClickHouse has been active.,0,clickhouse,
clickhouse.jemalloc.active,gauge,,byte,,(EXPERIMENTAL),0,clickhouse,
clickhouse.jemalloc.allocated,gauge,,byte,,The amount of memory allocated by ClickHouse.,0,clickhouse,
clickhouse.jemalloc.background_thread.num_runs,gauge,,byte,,(EXPERIMENTAL),0,clickhouse,
clickhouse.jemalloc.background_thread.num_threads,gauge,,thread,,(EXPERIMENTAL),0,clickhouse,
clickhouse.jemalloc.background_thread.run_interval,gauge,,byte,,(EXPERIMENTAL),0,clickhouse,
clickhouse.jemalloc.mapped,gauge,,byte,,The amount of memory in active extents mapped by the allocator.,0,clickhouse,
clickhouse.jemalloc.metadata,gauge,,byte,,"The amount of memory dedicated to metadata, which comprise base allocations used for bootstrap-sensitive allocator metadata structures and internal allocations.",0,clickhouse,
clickhouse.jemalloc.metadata_thp,gauge,,byte,,(EXPERIMENTAL),0,clickhouse,
clickhouse.jemalloc.resident,gauge,,byte,,"The amount of memory in physically resident data pages mapped by the allocator, comprising all pages dedicated to allocator metadata, pages backing active allocations, and unused dirty pages.",0,clickhouse,
clickhouse.jemalloc.retained,gauge,,byte,,The amount of memory in virtual memory mappings that were retained rather than being returned to the operating system.,0,clickhouse,
clickhouse.dictionary.memory.used,gauge,,byte,,The total amount of memory used by a dictionary.,0,clickhouse,
clickhouse.dictionary.item.current,gauge,,item,,The number of items stored in a dictionary.,0,clickhouse,
clickhouse.dictionary.load,gauge,,percent,,"The percentage filled in a dictionary (for a hashed dictionary, the percentage filled in the hash table).",0,clickhouse,
clickhouse.table.mergetree.size,gauge,,byte,,The total size of all data part files of a MergeTree table.,0,clickhouse,
clickhouse.table.mergetree.part.current,gauge,,object,,The total number of data parts of a MergeTree table.,0,clickhouse,
clickhouse.table.mergetree.row.current,gauge,,row,,The total number of rows in a MergeTree table.,0,clickhouse,
clickhouse.table.replicated.part.future,gauge,,item,,The number of data parts that will appear as the result of INSERTs or merges that haven't been done yet.,0,clickhouse,
clickhouse.table.replicated.part.suspect,gauge,,item,,The number of data parts in the queue for verification. A part is put in the verification queue if there is suspicion that it might be damaged.,0,clickhouse,
clickhouse.table.replicated.version,gauge,,operation,,"Version number of the table structure indicating how many times ALTER was performed. If replicas have different versions, it means some replicas haven't made all of the ALTERs yet.",0,clickhouse,
clickhouse.table.replicated.queue.size,gauge,,operation,,"Size of the queue for operations waiting to be performed. Operations include inserting blocks of data, merges, and certain other actions. It usually coincides with `clickhouse.table.replicated.part.future`.",0,clickhouse,
clickhouse.table.replicated.queue.insert,gauge,,operation,,"The number of inserts of blocks of data that need to be made. Insertions are usually replicated fairly quickly. If this number is large, it means something is wrong.",0,clickhouse,
clickhouse.table.replicated.queue.merge,gauge,,merge,,"The number of merges waiting to be made. Sometimes merges are lengthy, so this value may be greater than zero for a long time.",0,clickhouse,
clickhouse.table.replicated.log.max,gauge,,item,,Maximum entry number in the log of general activity.,0,clickhouse,
clickhouse.table.replicated.log.pointer,gauge,,item,,"Maximum entry number in the log of general activity that the replica copied to its execution queue, plus one. If this is much smaller than `clickhouse.table.replicated.log.max`, something is wrong.",0,clickhouse,
clickhouse.table.replicated.total,gauge,,table,,The total number of known replicas of this table.,0,clickhouse,
clickhouse.table.replicated.active,gauge,,table,,"The number of replicas of this table that have a session in ZooKeeper (i.e., the number of functioning replicas).",0,clickhouse,
