metric_name,metric_type,interval,unit_name,per_unit_name,description,orientation,integration,short_name,curated_metric
clickhouse.background_pool.processing.task.active,gauge,,task,,"The number of active tasks in BackgroundProcessingPool (merges, mutations, fetches, or replication queue bookkeeping)",-1,clickhouse,,
clickhouse.background_pool.move.task.active,gauge,,task,,"The number of active tasks in BackgroundProcessingPool for moves.",-1,clickhouse,,
clickhouse.background_pool.schedule.task.active,gauge,,task,,"The number of active tasks in BackgroundSchedulePool. This pool is used for periodic ReplicatedMergeTree tasks, like cleaning old data parts, altering data parts, replica re-initialization, etc.",-1,clickhouse,,
clickhouse.cache_dictionary.update_queue.batches,gauge,,,,"Number of 'batches' (a set of keys) in update queue in CacheDictionaries.",-1,clickhouse,,
clickhouse.cache_dictionary.update_queue.keys,gauge,,key,,"Exact number of keys in update queue in CacheDictionaries.",-1,clickhouse,,
clickhouse.thread.lock.context.waiting,gauge,,thread,,The number of threads waiting for lock in Context. This is global lock.,-1,clickhouse,,
clickhouse.query.insert.delayed,gauge,,query,,The number of INSERT queries that are throttled due to high number of active data parts for partition in a MergeTree table.,-1,clickhouse,,
clickhouse.dictionary.request.cache,gauge,,request,,The number of requests in fly to data sources of dictionaries of cache type.,0,clickhouse,,
clickhouse.merge.disk.reserved,gauge,,byte,,Disk space reserved for currently running background merges. It is slightly more than the total size of currently merging parts.,0,clickhouse,,
clickhouse.table.distributed.file.insert.pending,gauge,,file,,The number of pending files to process for asynchronous insertion into Distributed tables. Number of files for every shard is summed.,0,clickhouse,,
clickhouse.table.distributed.connection.inserted,gauge,,connection,,The number of connections to remote servers sending data that was INSERTed into Distributed tables. Both synchronous and asynchronous mode.,0,clickhouse,,
clickhouse.zk.node.ephemeral,gauge,,node,,The number of ephemeral nodes hold in ZooKeeper.,0,clickhouse,,
clickhouse.thread.global.total,gauge,,thread,,The number of threads in global thread pool.,0,clickhouse,,
clickhouse.thread.global.active,gauge,,thread,,The number of threads in global thread pool running a task.,0,clickhouse,,
clickhouse.connection.http,gauge,,connection,,The number of connections to HTTP server,0,clickhouse,,
clickhouse.connection.interserver,gauge,,connection,,The number of connections from other replicas to fetch parts,0,clickhouse,,
clickhouse.replica.leader.election,gauge,,shard,,The number of Replicas participating in leader election. Equals to total number of replicas in usual cases.,0,clickhouse,,
clickhouse.table.replicated.leader,gauge,,table,,"The number of Replicated tables that are leaders. Leader replica is responsible for assigning merges, cleaning old blocks for deduplications and a few more bookkeeping tasks. There may be no more than one leader across all replicas at one moment of time. If there is no leader it will be elected soon or it indicate an issue.",0,clickhouse,,
clickhouse.thread.local.total,gauge,,thread,,The number of threads in local thread pools. Should be similar to GlobalThreadActive.,0,clickhouse,,
clickhouse.thread.local.active,gauge,,thread,,The number of threads in local thread pools running a task.,0,clickhouse,,
clickhouse.query.memory,gauge,,byte,,Total amount of memory allocated in currently executing queries. Note that some memory allocations may not be accounted.,0,clickhouse,,
clickhouse.merge.memory,gauge,,byte,,Total amount of memory allocated for background merges. Included in MemoryTrackingInBackgroundProcessingPool. Note that this value may include a drift when the memory was allocated in a context of background processing pool and freed in other context or vice-versa. This happens naturally due to caches for tables indexes and doesn't indicate memory leaks.,0,clickhouse,,
clickhouse.background_pool.processing.memory,gauge,,byte,,"Total amount of memory allocated in background processing pool (that is dedicated for background merges, mutations and fetches). Note that this value may include a drift when the memory was allocated in a context of background processing pool and freed in other context or vice-versa. This happens naturally due to caches for tables indexes and doesn't indicate memory leaks.",0,clickhouse,,
clickhouse.background_pool.move.memory,gauge,,byte,,"Total amount of memory (bytes) allocated in background processing pool (that is dedicated for background moves). Note that this value may include a drift when the memory was allocated in a context of background processing pool and freed in other context or vice-versa. This happens naturally due to caches for tables indexes and doesn't indicate memory leaks.",0,clickhouse,,
clickhouse.background_pool.schedule.memory,gauge,,byte,,Total amount of memory allocated in background schedule pool (that is dedicated for bookkeeping tasks of Replicated tables).,0,clickhouse,,
clickhouse.merge.active,gauge,,merge,,The number of executing background merges,0,clickhouse,,
clickhouse.file.open.read,gauge,,file,,The number of files open for reading,0,clickhouse,,
clickhouse.file.open.write,gauge,,file,,The number of files open for writing,0,clickhouse,,
clickhouse.query.mutation,gauge,,query,,The number of mutations (ALTER DELETE/UPDATE),0,clickhouse,,
clickhouse.query.active,gauge,,query,,The number of executing queries,0,clickhouse,,
clickhouse.query.waiting,gauge,,query,,The number of queries that are stopped and waiting due to 'priority' setting.,0,clickhouse,,
clickhouse.thread.query,gauge,,thread,,The number of query processing threads,0,clickhouse,,
clickhouse.thread.lock.rw.active.read,gauge,,thread,,The number of threads holding read lock in a table RWLock.,0,clickhouse,,
clickhouse.thread.lock.rw.active.write,gauge,,thread,,The number of threads holding write lock in a table RWLock.,0,clickhouse,,
clickhouse.thread.lock.rw.waiting.read,gauge,,thread,,The number of threads waiting for read on a table RWLock.,0,clickhouse,,
clickhouse.thread.lock.rw.waiting.write,gauge,,thread,,The number of threads waiting for write on a table RWLock.,0,clickhouse,,
clickhouse.syscall.read,gauge,,read,,"The number of read (read, pread, io_getevents, etc.) syscalls in fly.",0,clickhouse,,
clickhouse.table.replicated.readonly,gauge,,table,,The number of Replicated tables that are currently in readonly state due to re-initialization after ZooKeeper session loss or due to startup without ZooKeeper configured.,0,clickhouse,,
clickhouse.table.replicated.part.check,gauge,,item,,The number of data parts checking for consistency,0,clickhouse,,
clickhouse.table.replicated.part.fetch,gauge,,item,,The number of data parts being fetched from replica,0,clickhouse,,
clickhouse.table.replicated.part.send,gauge,,item,,The number of data parts being sent to replicas,0,clickhouse,,
clickhouse.connection.send.external,gauge,,connection,,The number of connections that are sending data for external tables to remote servers. External tables are used to implement GLOBAL IN and GLOBAL JOIN operators with distributed subqueries.,0,clickhouse,,
clickhouse.connection.send.scalar,gauge,,connection,,The number of connections that are sending data for scalars to remote servers.,0,clickhouse,,
clickhouse.table.buffer.size,gauge,,byte,,Size of buffers of Buffer tables.,0,clickhouse,,
clickhouse.table.buffer.row,gauge,,row,,The number of rows in buffers of Buffer tables.,0,clickhouse,,
clickhouse.connection.mysql,gauge,,connection,,Number of client connections using MySQL protocol.,0,clickhouse,,
clickhouse.connection.tcp,gauge,,connection,,The number of connections to TCP server (clients with native interface).,0,clickhouse,,
clickhouse.syscall.write,gauge,,write,,"The number of write (write, pwrite, io_getevents, etc.) syscalls in fly.",0,clickhouse,,
clickhouse.zk.request,gauge,,request,,The number of requests to ZooKeeper in fly.,0,clickhouse,,
clickhouse.zk.connection,gauge,,connection,,"The number of sessions (connections) to ZooKeeper. Should be no more than one, because using more than one connection to ZooKeeper may lead to bugs due to lack of linearizability (stale reads) that ZooKeeper consistency model allows.",0,clickhouse,,
clickhouse.zk.watch,gauge,,event,,The number of watches (event subscriptions) in ZooKeeper.,0,clickhouse,,
clickhouse.lock.context.acquisition.count,count,,event,,The number of times the lock of Context was acquired or tried to acquire during the last interval. This is global lock.,0,clickhouse,,
clickhouse.lock.context.acquisition.total,gauge,,event,,The total number of times the lock of Context was acquired or tried to acquire. This is global lock.,0,clickhouse,,
clickhouse.syscall.write.wait,gauge,,percent,,The percentage of time spent waiting for write syscall during the last interval. This include writes to page cache.,0,clickhouse,,
clickhouse.file.open.count,count,,file,,The number of files opened during the last interval.,0,clickhouse,,
clickhouse.file.open.total,gauge,,file,,The total number of files opened.,0,clickhouse,,
clickhouse.query.count,count,,query,,"The number of queries to be interpreted and potentially executed during the last interval. Does not include queries that failed to parse or were rejected due to AST size limits, quota limits or limits on the number of simultaneously running queries. May include internal queries initiated by ClickHouse itself. Does not count subqueries.",0,clickhouse,,
clickhouse.query.total,gauge,,query,,"The total number of queries to be interpreted and potentially executed. Does not include queries that failed to parse or were rejected due to AST size limits, quota limits or limits on the number of simultaneously running queries. May include internal queries initiated by ClickHouse itself. Does not count subqueries.",0,clickhouse,,
clickhouse.file.read.count,count,,read,,The number of reads (read/pread) from a file descriptor during the last interval. Does not include sockets.,0,clickhouse,,
clickhouse.file.read.total,gauge,,read,,The total number of reads (read/pread) from a file descriptor. Does not include sockets.,0,clickhouse,,
clickhouse.thread.process_time,gauge,,percent,,The percentage of time spent processing (queries and other tasks) threads during the last interval.,0,clickhouse,,
clickhouse.query.insert.count,count,,query,,"The number of INSERT queries to be interpreted and potentially executed during the last interval. Does not include queries that failed to parse or were rejected due to AST size limits, quota limits or limits on the number of simultaneously running queries. May include internal queries initiated by ClickHouse itself. Does not count subqueries.",0,clickhouse,,
clickhouse.query.insert.total,gauge,,query,,"The total number of INSERT queries to be interpreted and potentially executed. Does not include queries that failed to parse or were rejected due to AST size limits, quota limits or limits on the number of simultaneously running queries. May include internal queries initiated by ClickHouse itself. Does not count subqueries.",0,clickhouse,,
clickhouse.query.select.count,count,,query,,"The number of SELECT queries to be interpreted and potentially executed during the last interval. Does not include queries that failed to parse or were rejected due to AST size limits, quota limits or limits on the number of simultaneously running queries. May include internal queries initiated by ClickHouse itself. Does not count subqueries.",0,clickhouse,,
clickhouse.query.select.total,gauge,,query,,"The total number of SELECT queries to be interpreted and potentially executed. Does not include queries that failed to parse or were rejected due to AST size limits, quota limits or limits on the number of simultaneously running queries. May include internal queries initiated by ClickHouse itself. Does not count subqueries.",0,clickhouse,,
clickhouse.thread.system.process_time,gauge,,percent,,"The percentage of time spent processing (queries and other tasks) threads executing CPU instructions in OS kernel space during the last interval. This includes time CPU pipeline was stalled due to cache misses, branch mispredictions, hyper-threading, etc.",0,clickhouse,,
clickhouse.thread.user.process_time,gauge,,percent,,"The percentage of time spent processing (queries and other tasks) threads executing CPU instructions in user space during the last interval. This includes time CPU pipeline was stalled due to cache misses, branch mispredictions, hyper-threading, etc.",0,clickhouse,,
clickhouse.file.write.count,count,,write,,The number of writes (write/pwrite) to a file descriptor during the last interval. Does not include sockets.,0,clickhouse,,
clickhouse.file.write.total,gauge,,write,,The total number of writes (write/pwrite) to a file descriptor. Does not include sockets.,0,clickhouse,,
clickhouse.file.write.size.count,count,,byte,,"The number of bytes written to file descriptors during the last interval. If the file is compressed, this will show compressed data size.",0,clickhouse,,
clickhouse.file.write.size.total,gauge,,byte,,"The total number of bytes written to file descriptors during the last interval. If the file is compressed, this will show compressed data size.",0,clickhouse,,
clickhouse.mmapped.file.current,gauge,,file,,"Total number of mmapped files.",0,clickhouse,,
clickhouse.mmapped.file.size,gauge,,byte,,"Sum size of mmapped file regions.",0,clickhouse,,
clickhouse.network.receive.elapsed.time,gauge,,microsecond,,"Total time spent waiting for data to receive or receiving data from the network.",0,clickhouse,,
clickhouse.network.receive.size.count,count,,byte,second,"The number of bytes received from network.",0,clickhouse,,
clickhouse.network.receive.size.total,gauge,,byte,second,"The total number of bytes received from network.",0,clickhouse,,
clickhouse.network.send.elapsed.time,gauge,,microsecond,,"Total time spent waiting for data to send to network or sending data to network.",0,clickhouse,,
clickhouse.network.send.size.count,count,,byte,,"The number of bytes sent to the network.",0,clickhouse,,
clickhouse.network.send.size.total,gauge,,byte,,"The total number of bytes sent to the network.",0,clickhouse,,
clickhouse.network.threads.receive,gauge,,thread,,"Number of threads receiving data from the network.",0,clickhouse,,
clickhouse.network.threads.send,gauge,,thread,,"Number of threads sending data to the network.",0,clickhouse,,
clickhouse.node.remove.count,count,,error,,"The number of times an error happened while trying to remove ephemeral node during the last interval. This is usually not an issue, because ClickHouse's implementation of ZooKeeper library guarantees that the session will expire and the node will be removed.",0,clickhouse,,
clickhouse.node.remove.total,gauge,,error,,"The total number of times an error happened while trying to remove ephemeral node. This is usually not an issue, because ClickHouse's implementation of ZooKeeper library guarantees that the session will expire and the node will be removed.",0,clickhouse,,
clickhouse.buffer.write.discard.count,count,,error,,The number of stack traces dropped by query profiler or signal handler because pipe is full or cannot write to pipe during the last interval.,0,clickhouse,,
clickhouse.buffer.write.discard.total,gauge,,error,,The total number of stack traces dropped by query profiler or signal handler because pipe is full or cannot write to pipe.,0,clickhouse,,
clickhouse.compilation.attempt.count,count,,event,,The number of times a compilation of generated C++ code was initiated during the last interval.,0,clickhouse,,
clickhouse.compilation.attempt.total,gauge,,event,,The total number of times a compilation of generated C++ code was initiated.,0,clickhouse,,
clickhouse.compilation.size.count,count,,byte,,The number of bytes used for expressions compilation during the last interval.,0,clickhouse,,
clickhouse.compilation.size.total,gauge,,byte,,The total number of bytes used for expressions compilation.,0,clickhouse,,
clickhouse.compilation.time,gauge,,percent,,The percentage of time spent for compilation of expressions to LLVM code during the last interval.,0,clickhouse,,
clickhouse.compilation.llvm.attempt.count,count,,event,,The number of times a compilation of generated LLVM code (to create fused function for complex expressions) was initiated during the last interval.,0,clickhouse,,
clickhouse.compilation.llvm.attempt.total,gauge,,event,,The total number of times a compilation of generated LLVM code (to create fused function for complex expressions) was initiated.,0,clickhouse,,
clickhouse.compilation.success.count,count,,event,,The number of times a compilation of generated C++ code was successful during the last interval.,0,clickhouse,,
clickhouse.compilation.success.total,gauge,,event,,The total number of times a compilation of generated C++ code was successful.,0,clickhouse,,
clickhouse.compilation.function.execute.count,count,,execution,,The number of times a compiled function was executed during the last interval.,0,clickhouse,,
clickhouse.compilation.function.execute.total,gauge,,execution,,The total number of times a compiled function was executed.,0,clickhouse,,
clickhouse.connection.http.create.count,count,,connection,,The number of created HTTP connections (closed or opened) during the last interval.,0,clickhouse,,
clickhouse.connection.http.create.total,gauge,,connection,,The total number of created HTTP connections (closed or opened).,0,clickhouse,,
clickhouse.table.mergetree.insert.delayed.count,count,,throttle,,The number of times the INSERT of a block to a MergeTree table was throttled due to high number of active data parts for partition during the last interval.,0,clickhouse,,
clickhouse.table.mergetree.insert.delayed.total,gauge,,throttle,,The total number of times the INSERT of a block to a MergeTree table was throttled due to high number of active data parts for partition.,0,clickhouse,,
clickhouse.table.mergetree.insert.delayed.time,gauge,,percent,,The percentage of time spent while the INSERT of a block to a MergeTree table was throttled due to high number of active data parts for partition during the last interval.,0,clickhouse,,
clickhouse.syscall.read.wait,gauge,,percent,,The percentage of time spent waiting for read syscall during the last interval. This includes reads from page cache.,0,clickhouse,,
clickhouse.table.mergetree.replicated.insert.deduplicate.count,count,,operation,,The number of times the INSERTed block to a ReplicatedMergeTree table was deduplicated during the last interval.,0,clickhouse,,
clickhouse.table.mergetree.replicated.insert.deduplicate.total,gauge,,operation,,The total number of times the INSERTed block to a ReplicatedMergeTree table was deduplicated.,0,clickhouse,,
clickhouse.table.insert.size.count,count,,byte,,The number of bytes (uncompressed; for columns as they stored in memory) INSERTed to all tables during the last interval.,0,clickhouse,,
clickhouse.table.insert.size.total,gauge,,byte,,The total number of bytes (uncompressed; for columns as they stored in memory) INSERTed to all tables.,0,clickhouse,,
clickhouse.table.insert.row.count,count,,row,,The number of rows INSERTed to all tables during the last interval.,0,clickhouse,,
clickhouse.table.insert.row.total,gauge,,row,,The total number of rows INSERTed to all tables.,0,clickhouse,,
clickhouse.table.mergetree.replicated.leader.elected.count,count,,event,,"The number of times a ReplicatedMergeTree table became a leader during the last interval. Leader replica is responsible for assigning merges, cleaning old blocks for deduplications and a few more bookkeeping tasks.",0,clickhouse,,
clickhouse.table.mergetree.replicated.leader.elected.total,gauge,,event,,"The total number of times a ReplicatedMergeTree table became a leader. Leader replica is responsible for assigning merges, cleaning old blocks for deduplications and a few more bookkeeping tasks.",0,clickhouse,,
clickhouse.merge.count,count,,merge,,The number of launched background merges during the last interval.,0,clickhouse,,
clickhouse.merge.total,gauge,,merge,,The total number of launched background merges.,0,clickhouse,,
clickhouse.table.mergetree.insert.block.count,count,,block,,The number of blocks INSERTed to MergeTree tables during the last interval. Each block forms a data part of level zero.,0,clickhouse,,
clickhouse.table.mergetree.insert.block.total,gauge,,block,,The total number of blocks INSERTed to MergeTree tables. Each block forms a data part of level zero.,0,clickhouse,,
clickhouse.table.mergetree.insert.block.already_sorted.count,count,,block,,The number of blocks INSERTed to MergeTree tables that appeared to be already sorted during the last interval.,0,clickhouse,,
clickhouse.table.mergetree.insert.block.already_sorted.total,gauge,,block,,The total number of blocks INSERTed to MergeTree tables that appeared to be already sorted.,0,clickhouse,,
clickhouse.table.mergetree.insert.write.size.compressed.count,count,,byte,,The number of bytes written to filesystem for data INSERTed to MergeTree tables during the last interval.,0,clickhouse,,
clickhouse.table.mergetree.insert.write.size.compressed.total,gauge,,byte,,The total number of bytes written to filesystem for data INSERTed to MergeTree tables.,0,clickhouse,,
clickhouse.table.mergetree.insert.row.count,count,,row,,The number of rows INSERTed to MergeTree tables during the last interval.,0,clickhouse,,
clickhouse.table.mergetree.insert.row.total,gauge,,row,,The total number of rows INSERTed to MergeTree tables.,0,clickhouse,,
clickhouse.table.mergetree.insert.write.size.uncompressed.count,count,,byte,,The number of uncompressed bytes (for columns as they are stored in memory) INSERTed to MergeTree tables during the last interval.,0,clickhouse,,
clickhouse.table.mergetree.insert.write.size.uncompressed.total,gauge,,byte,,The total number of uncompressed bytes (for columns as they are stored in memory) INSERTed to MergeTree tables.,0,clickhouse,,
clickhouse.merge.row.read.count,count,,row,,The number of rows read for background merges during the last interval. This is the number of rows before merge.,0,clickhouse,,
clickhouse.merge.row.read.total,gauge,,row,,The total number of rows read for background merges. This is the number of rows before merge.,0,clickhouse,,
clickhouse.merge.read.size.uncompressed.count,count,,byte,,The number of uncompressed bytes (for columns as they are stored in memory) that was read for background merges during the last interval. This is the number before merge.,0,clickhouse,,
clickhouse.merge.read.size.uncompressed.total,gauge,,byte,,The total number of uncompressed bytes (for columns as they are stored in memory) that was read for background merges. This is the number before merge.,0,clickhouse,,
clickhouse.merge.time,gauge,,percent,,The percentage of time spent for background merges during the last interval.,0,clickhouse,,
clickhouse.cpu.time,gauge,,percent,,The percentage of CPU time spent seen by OS during the last interval. Does not include involuntary waits due to virtualization.,0,clickhouse,,
clickhouse.thread.cpu.wait,gauge,,percent,,The percentage of time a thread was ready for execution but waiting to be scheduled by OS (from the OS point of view) during the last interval.,0,clickhouse,,
clickhouse.thread.io.wait,gauge,,percent,,The percentage of time a thread spent waiting for a result of IO operation (from the OS point of view) during the last interval. This is real IO that doesn't include page cache.,0,clickhouse,,
clickhouse.disk.read.size.count,count,,byte,,"The number of bytes read from disks or block devices during the last interval. Doesn't include bytes read from page cache. May include excessive data due to block size, readahead, etc.",0,clickhouse,,
clickhouse.disk.read.size.total,gauge,,byte,,"The total number of bytes read from disks or block devices. Doesn't include bytes read from page cache. May include excessive data due to block size, readahead, etc.",0,clickhouse,,
clickhouse.fs.read.size.count,count,,byte,,The number of bytes read from filesystem (including page cache) during the last interval.,0,clickhouse,,
clickhouse.fs.read.size.total,gauge,,byte,,The total number of bytes read from filesystem (including page cache).,0,clickhouse,,
clickhouse.disk.write.size.count,count,,byte,,The number of bytes written to disks or block devices during the last interval. Doesn't include bytes that are in page cache dirty pages. May not include data that was written by OS asynchronously.,0,clickhouse,,
clickhouse.disk.write.size.total,gauge,,byte,,The total number of bytes written to disks or block devices. Doesn't include bytes that are in page cache dirty pages. May not include data that was written by OS asynchronously.,0,clickhouse,,
clickhouse.fs.write.size.count,count,,byte,,The number of bytes written to filesystem (including page cache) during the last interval.,0,clickhouse,,
clickhouse.fs.write.size.total,gauge,,byte,,The total number of bytes written to filesystem (including page cache).,0,clickhouse,,
clickhouse.query.mask.match.count,count,,occurrence,,The number of times query masking rules were successfully matched during the last interval.,0,clickhouse,,
clickhouse.query.mask.match.total,gauge,,occurrence,,The total number of times query masking rules were successfully matched.,0,clickhouse,,
clickhouse.query.signal.dropped.count,count,,occurrence,,The number of times the processing of a signal was dropped due to overrun plus the number of signals that the OS has not delivered due to overrun during the last interval.,0,clickhouse,,
clickhouse.query.signal.dropped.total,gauge,,occurrence,,The total number of times the processing of a signal was dropped due to overrun plus the number of signals that the OS has not delivered due to overrun.,0,clickhouse,,
clickhouse.query.read.backoff.count,count,,occurrence,,The number of times the number of query processing threads was lowered due to slow reads during the last interval.,0,clickhouse,,
clickhouse.query.read.backoff.total,gauge,,occurrence,,The total number of times the number of query processing threads was lowered due to slow reads.,0,clickhouse,,
clickhouse.file.read.size.count,count,,byte,,"The number of bytes read from file descriptors during the last interval. If the file is compressed, this will show the compressed data size.",0,clickhouse,,
clickhouse.file.read.size.total,gauge,,byte,,"The total number of bytes read from file descriptors. If the file is compressed, this will show the compressed data size.",0,clickhouse,,
clickhouse.file.read.fail.count,count,,read,,The number of times the read (read/pread) from a file descriptor have failed during the last interval.,0,clickhouse,,
clickhouse.file.read.fail.total,gauge,,read,,The total number of times the read (read/pread) from a file descriptor have failed.,0,clickhouse,,
clickhouse.compilation.regex.count,count,,event,,The number of regular expressions compiled during the last interval. Identical regular expressions are compiled just once and cached forever.,0,clickhouse,,
clickhouse.compilation.regex.total,gauge,,event,,The total number of regular expressions compiled. Identical regular expressions are compiled just once and cached forever.,0,clickhouse,,
clickhouse.table.mergetree.insert.block.rejected.count,count,,block,,The number of times the INSERT of a block to a MergeTree table was rejected with `Too many parts` exception due to high number of active data parts for partition during the last interval.,0,clickhouse,,
clickhouse.table.mergetree.insert.block.rejected.total,gauge,,block,,The total number of times the INSERT of a block to a MergeTree table was rejected with `Too many parts` exception due to high number of active data parts for partition.,0,clickhouse,,
clickhouse.table.replicated.leader.yield.count,count,,event,,The number of times Replicated table yielded its leadership due to large replication lag relative to other replicas during the last interval.,0,clickhouse,,
clickhouse.table.replicated.leader.yield.total,gauge,,event,,The total number of times Replicated table yielded its leadership due to large replication lag relative to other replicas.,0,clickhouse,,
clickhouse.table.replicated.part.loss.count,count,,item,,"The number of times a data part we wanted doesn't exist on any replica (even on replicas that are offline right now) during the last interval. Those data parts are definitely lost. This is normal due to asynchronous replication (if quorum inserts were not enabled), when the replica on which the data part was written failed and when it became online after fail it doesn't contain that data part.",0,clickhouse,,
clickhouse.table.replicated.part.loss.total,gauge,,item,,"The total number of times a data part that we wanted doesn't exist on any replica (even on replicas that are offline right now). That data parts are definitely lost. This is normal due to asynchronous replication (if quorum inserts were not enabled), when the replica on which the data part was written failed and when it became online after fail it doesn't contain that data part.",0,clickhouse,,
clickhouse.table.mergetree.replicated.fetch.replica.count,count,,fetch,,The number of times a data part was downloaded from replica of a ReplicatedMergeTree table during the last interval.,0,clickhouse,,
clickhouse.table.mergetree.replicated.fetch.replica.total,gauge,,fetch,,The total number of times a data part was downloaded from replica of a ReplicatedMergeTree table.,0,clickhouse,,
clickhouse.table.mergetree.replicated.fetch.merged.count,count,,fetch,,The number of times ClickHouse prefers to download already merged part from replica of ReplicatedMergeTree table instead of performing a merge itself (usually it prefers doing a merge itself to save network traffic) during the last interval. This happens when ClickHouse does not have all source parts to perform a merge or when the data part is old enough.,0,clickhouse,,
clickhouse.table.mergetree.replicated.fetch.merged.total,gauge,,fetch,,The total number of times ClickHouse prefers to download already merged part from replica of ReplicatedMergeTree table instead of performing a merge itself (usually it prefers doing a merge itself to save network traffic). This happens when ClickHouse does not have all source parts to perform a merge or when the data part is old enough.,0,clickhouse,,
clickhouse.file.seek.count,count,,operation,,The number of times the `lseek` function was called during the last interval.,0,clickhouse,,
clickhouse.file.seek.total,gauge,,operation,,The total number of times the `lseek` function was called.,0,clickhouse,,
clickhouse.table.mergetree.mark.selected.count,count,,index,,The number of marks (index granules) selected to read from a MergeTree table during the last interval.,0,clickhouse,,
clickhouse.table.mergetree.mark.selected.total,gauge,,index,,The total number of marks (index granules) selected to read from a MergeTree table.,0,clickhouse,,
clickhouse.table.mergetree.part.selected.count,count,,item,,The number of data parts selected to read from a MergeTree table during the last interval.,0,clickhouse,,
clickhouse.table.mergetree.part.selected.total,gauge,,item,,The total number of data parts selected to read from a MergeTree table.,0,clickhouse,,
clickhouse.table.mergetree.range.selected.count,count,,item,,The number of non-adjacent ranges in all data parts selected to read from a MergeTree table during the last interval.,0,clickhouse,,
clickhouse.table.mergetree.range.selected.total,gauge,,item,,The total number of non-adjacent ranges in all data parts selected to read from a MergeTree table.,0,clickhouse,,
clickhouse.file.read.slow.count,count,,read,,The number of reads from a file that were slow during the last interval. This indicates system overload. Thresholds are controlled by read_backoff_* settings.,0,clickhouse,,
clickhouse.file.read.slow.total,gauge,,read,,The total number of reads from a file that were slow. This indicates system overload. Thresholds are controlled by read_backoff_* settings.,0,clickhouse,,
clickhouse.query.sleep.time,gauge,,percent,,The percentage of time a query was sleeping to conform to the `max_network_bandwidth` setting during the last interval.,0,clickhouse,,
clickhouse.file.write.fail.count,count,,write,,The number of times the write (write/pwrite) to a file descriptor have failed during the last interval.,0,clickhouse,,
clickhouse.file.write.fail.total,gauge,,write,,The total number of times the write (write/pwrite) to a file descriptor have failed.,0,clickhouse,,
clickhouse.CompiledExpressionCacheCount,gauge,,item,,Total entries in the cache of JIT-compiled code.,0,clickhouse,,
clickhouse.table.mergetree.storage.mark.cache,gauge,,byte,,The size of the cache of `marks` for StorageMergeTree.,0,clickhouse,,
clickhouse.MarkCacheFiles,gauge,,item,,The number of mark files cached in the mark cache.,0,clickhouse,,
clickhouse.part.max,gauge,,item,,The maximum number of active parts in partitions.,0,clickhouse,,
clickhouse.database.total,gauge,,instance,,The current number of databases.,0,clickhouse,,
clickhouse.table.total,gauge,,table,,The current number of tables.,0,clickhouse,,
clickhouse.replica.delay.absolute,gauge,,millisecond,,The maximum replica queue delay relative to current time.,0,clickhouse,,
clickhouse.ReplicasMaxInsertsInQueue,gauge,,item,,Maximum number of INSERT operations in the queue (still to be replicated) across Replicated tables.,0,clickhouse,,
clickhouse.ReplicasMaxMergesInQueue,gauge,,item,,Maximum number of merge operations in the queue (still to be applied) across Replicated tables.,0,clickhouse,,
clickhouse.ReplicasMaxQueueSize,gauge,,item,,"Maximum queue size (in the number of operations like get, merge) across Replicated tables.",0,clickhouse,,
clickhouse.replica.delay.relative,gauge,,millisecond,,The maximum difference of absolute delay from any other replica.,0,clickhouse,,
clickhouse.ReplicasSumInsertsInQueue,gauge,,item,,Sum of INSERT operations in the queue (still to be replicated) across Replicated tables.,0,clickhouse,,
clickhouse.ReplicasSumMergesInQueue,gauge,,item,,Sum of merge operations in the queue (still to be applied) across Replicated tables.,0,clickhouse,,
clickhouse.replica.queue.size,gauge,,task,,The number of replication tasks in queue.,0,clickhouse,,
clickhouse.UncompressedCacheBytes,gauge,,byte,,Total size of uncompressed cache in bytes. Uncompressed cache does not usually improve the performance and should be mostly avoided.,0,clickhouse,,
clickhouse.UncompressedCacheCells,gauge,,item,,Total number of entries in the uncompressed cache. Each entry represents a decompressed block of data. Uncompressed cache does not usually improve performance and should be mostly avoided.,0,clickhouse,,
clickhouse.uptime,gauge,,second,,The amount of time ClickHouse has been active.,0,clickhouse,,
clickhouse.jemalloc.active,gauge,,byte,,(EXPERIMENTAL),0,clickhouse,,
clickhouse.jemalloc.allocated,gauge,,byte,,The amount of memory allocated by ClickHouse.,0,clickhouse,,
clickhouse.jemalloc.background_thread.num_runs,gauge,,byte,,(EXPERIMENTAL),0,clickhouse,,
clickhouse.jemalloc.background_thread.num_threads,gauge,,thread,,(EXPERIMENTAL),0,clickhouse,,
clickhouse.jemalloc.background_thread.run_interval,gauge,,byte,,(EXPERIMENTAL),0,clickhouse,,
clickhouse.jemalloc.mapped,gauge,,byte,,The amount of memory in active extents mapped by the allocator.,0,clickhouse,,
clickhouse.jemalloc.metadata,gauge,,byte,,"The amount of memory dedicated to metadata, which comprise base allocations used for bootstrap-sensitive allocator metadata structures and internal allocations.",0,clickhouse,,
clickhouse.jemalloc.metadata_thp,gauge,,byte,,(EXPERIMENTAL),0,clickhouse,,
clickhouse.jemalloc.resident,gauge,,byte,,"The amount of memory in physically resident data pages mapped by the allocator, comprising all pages dedicated to allocator metadata, pages backing active allocations, and unused dirty pages.",0,clickhouse,,
clickhouse.jemalloc.retained,gauge,,byte,,The amount of memory in virtual memory mappings that were retained rather than being returned to the operating system.,0,clickhouse,,
clickhouse.dictionary.memory.used,gauge,,byte,,The total amount of memory used by a dictionary.,0,clickhouse,,
clickhouse.dictionary.item.current,gauge,,item,,The number of items stored in a dictionary.,0,clickhouse,,
clickhouse.dictionary.load,gauge,,percent,,"The percentage filled in a dictionary (for a hashed dictionary, the percentage filled in the hash table).",0,clickhouse,,
clickhouse.table.mergetree.size,gauge,,byte,,The total size of all data part files of a MergeTree table.,0,clickhouse,,
clickhouse.table.mergetree.part.current,gauge,,object,,The total number of data parts of a MergeTree table.,0,clickhouse,,
clickhouse.table.mergetree.row.current,gauge,,row,,The total number of rows in a MergeTree table.,0,clickhouse,,
clickhouse.table.replicated.part.future,gauge,,item,,The number of data parts that will appear as the result of INSERTs or merges that haven't been done yet.,0,clickhouse,,
clickhouse.table.replicated.part.suspect,gauge,,item,,The number of data parts in the queue for verification. A part is put in the verification queue if there is suspicion that it might be damaged.,0,clickhouse,,
clickhouse.table.replicated.version,gauge,,operation,,"Version number of the table structure indicating how many times ALTER was performed. If replicas have different versions, it means some replicas haven't made all of the ALTERs yet.",0,clickhouse,,
clickhouse.table.replicated.queue.size,gauge,,operation,,"Size of the queue for operations waiting to be performed. Operations include inserting blocks of data, merges, and certain other actions. It usually coincides with `clickhouse.table.replicated.part.future`.",0,clickhouse,,
clickhouse.table.replicated.queue.insert,gauge,,operation,,"The number of inserts of blocks of data that need to be made. Insertions are usually replicated fairly quickly. If this number is large, it means something is wrong.",0,clickhouse,,
clickhouse.table.replicated.queue.merge,gauge,,merge,,"The number of merges waiting to be made. Sometimes merges are lengthy, so this value may be greater than zero for a long time.",0,clickhouse,,
clickhouse.table.replicated.log.max,gauge,,item,,Maximum entry number in the log of general activity.,0,clickhouse,,
clickhouse.table.replicated.log.pointer,gauge,,item,,"Maximum entry number in the log of general activity that the replica copied to its execution queue, plus one. If this is much smaller than `clickhouse.table.replicated.log.max`, something is wrong.",0,clickhouse,,
clickhouse.table.replicated.total,gauge,,table,,The total number of known replicas of this table.,0,clickhouse,,
clickhouse.table.replicated.active,gauge,,table,,"The number of replicas of this table that have a session in ZooKeeper (i.e., the number of functioning replicas).",0,clickhouse,,
clickhouse.read.compressed.block.count,count,,block,,"The number of compressed blocks (the blocks of data that are compressed independent of each other) read from compressed sources (files, network) during the last interval.",0,clickhouse,,
clickhouse.read.compressed.block.total,gauge,,block,,"The total number of compressed blocks (the blocks of data that are compressed independent of each other) read from compressed sources (files, network).",0,clickhouse,,
clickhouse.read.compressed.raw.size.count,count,,byte,,"The number of uncompressed bytes (the number of bytes after decompression) read from compressed sources (files, network) during the last interval.",0,clickhouse,,
clickhouse.read.compressed.raw.size.total,gauge,,byte,,"The total number of uncompressed bytes (the number of bytes after decompression) read from compressed sources (files, network).",0,clickhouse,,
clickhouse.read.compressed.size.count,count,,byte,,"The number of bytes (the number of bytes before decompression) read from compressed sources (files, network) during the last interval.",0,clickhouse,,
clickhouse.read.compressed.size.total,gauge,,byte,,"The total number of bytes (the number of bytes before decompression) read from compressed sources (files, network).",0,clickhouse,,
clickhouse.table.mergetree.replicated.fetch.replica.fail.count,count,,byte,,The number of times a data part was failed to download from replica of a ReplicatedMergeTree table during the last interval.,0,clickhouse,,
clickhouse.table.mergetree.replicated.fetch.replica.fail.total,gauge,,byte,,The total number of times a data part was failed to download from replica of a ReplicatedMergeTree table.,0,clickhouse,,
clickhouse.table.mergetree.replicated.merge.count,count,,byte,,The number of times data parts of ReplicatedMergeTree tables were successfully merged during the last interval.,0,clickhouse,,
clickhouse.table.mergetree.replicated.merge.total,gauge,,byte,,The total number of times data parts of ReplicatedMergeTree tables were successfully merged.,0,clickhouse,,
clickhouse.background_pool.buffer_flush_schedule.task.active,gauge,,task,,Number of active tasks in BackgroundBufferFlushSchedulePool. This pool is used for periodic Buffer flushes,0,clickhouse,,
clickhouse.background_pool.distributed.task.active,gauge,,task,,Number of active tasks in BackgroundDistributedSchedulePool. This pool is used for distributed sends that is done in background.,0,clickhouse,,
clickhouse.background_pool.fetches.task.active,gauge,,task,,Number of active tasks in BackgroundFetchesPool,0,clickhouse,,
clickhouse.background_pool.message_broker.task.active,gauge,,task,,Number of active tasks in BackgroundProcessingPool for message streaming,0,clickhouse,,
clickhouse.ddl.max_processed,gauge,,,,Max processed DDL entry of DDLWorker.,0,clickhouse,,
clickhouse.parts.committed,gauge,,item,,"Active data part, used by current and upcoming SELECTs.",0,clickhouse,,
clickhouse.parts.compact,gauge,,item,,Compact parts.,0,clickhouse,,
clickhouse.parts.active,gauge,,item,,[Only versions >= 22.7.1] Active data part used by current and upcoming SELECTs.,0,clickhouse,,
clickhouse.parts.pre_active,gauge,,item,,[Only versions >= 22.7.1] The part is in data_parts but not used for SELECTs.,0,clickhouse,,
clickhouse.parts.delete_on_destroy,gauge,,item,,Part was moved to another disk and should be deleted in own destructor.,0,clickhouse,,
clickhouse.parts.deleting,gauge,,item,,"Not active data part with identity refcounter, it is deleting right now by a cleaner.",0,clickhouse,,
clickhouse.parts.inmemory,gauge,,item,,In-memory parts.,0,clickhouse,,
clickhouse.parts.outdated,gauge,,item,,"Not active data part, but could be used by only current SELECTs, could be deleted after SELECTs finishes.",0,clickhouse,,
clickhouse.parts.precommitted,gauge,,item,,"The part is in data_parts, but not used for SELECTs.",0,clickhouse,,
clickhouse.parts.temporary,gauge,,item,,"The part is generating now, it is not in data_parts list.",0,clickhouse,,
clickhouse.parts.wide,gauge,,item,,Wide parts.,0,clickhouse,,
clickhouse.postgresql.connection,gauge,,connection,,Number of client connections using PostgreSQL protocol,0,clickhouse,,
clickhouse.tables_to_drop.queue.total,gauge,,table,,"Number of dropped tables, that are waiting for background data removal.",0,clickhouse,,
clickhouse.log.entry.merge.created.total,gauge,,event,,Total successfully created log entryies to merge parts in ReplicatedMergeTree.,0,clickhouse,,
clickhouse.log.entry.merge.created.count,count,,event,,Successfully created log entry to merge parts in ReplicatedMergeTree.,0,clickhouse,,
clickhouse.log.entry.mutation.created.total,gauge,,event,,Total successfully created log entry to mutate parts in ReplicatedMergeTree.,0,clickhouse,,
clickhouse.log.entry.mutation.created.count,count,,event,,Successfully created log entry to mutate parts in ReplicatedMergeTree.,0,clickhouse,,
clickhouse.error.dns.total,gauge,,error,,Total count of errors in DNS resolution,0,clickhouse,,
clickhouse.error.dns.count,count,,error,, Number of errors in DNS resolution,0,clickhouse,,
clickhouse.distributed.connection.fail_at_all.total,gauge,,connection,,Total count when distributed connection fails after all retries finished,0,clickhouse,,
clickhouse.distributed.connection.fail_at_all.count,count,,connection,,Count when distributed connection fails after all retries finished,0,clickhouse,,
clickhouse.distributed.connection.fail_try.total,gauge,,connection,,Total count when distributed connection fails with retry,0,clickhouse,,
clickhouse.distributed.connection.fail_try.count,count,,connection,,Count when distributed connection fails with retry,0,clickhouse,,
clickhouse.distributed.inserts.delayed.total,gauge,,query,,Total number of times the INSERT of a block to a Distributed table was throttled due to high number of pending bytes.,0,clickhouse,,
clickhouse.distributed.inserts.delayed.count,count,,query,,Number of times the INSERT of a block to a Distributed table was throttled due to high number of pending bytes.,0,clickhouse,,
clickhouse.distributed.delayed.inserts.time,gauge,,microsecond,,Total number of milliseconds spent while the INSERT of a block to a Distributed table was throttled due to high number of pending bytes.,0,clickhouse,,
clickhouse.distributed.inserts.rejected.total,gauge,,query,,Total number of times the INSERT of a block to a Distributed table was rejected with 'Too many bytes' exception due to high number of pending bytes.,0,clickhouse,,
clickhouse.distributed.inserts.rejected.count,count,,query,,Number of times the INSERT of a block to a Distributed table was rejected with 'Too many bytes' exception due to high number of pending bytes.,0,clickhouse,,
clickhouse.query.insert.failed.total,gauge,,query,,"Same as FailedQuery, but only for INSERT queries.",0,clickhouse,,
clickhouse.query.insert.failed.count,count,,query,,"Same as FailedQuery, but only for INSERT queries.",0,clickhouse,,
clickhouse.query.failed.total,gauge,,query,,Total number of failed queries.,0,clickhouse,,
clickhouse.query.failed.count,count,,query,,Number of failed queries.,0,clickhouse,,
clickhouse.select.query.select.failed.total,gauge,,query,,"Same as FailedQuery, but only for SELECT queries.",0,clickhouse,,
clickhouse.select.query.select.failed.count,count,,query,,"Same as FailedQuery, but only for SELECT queries.",0,clickhouse,,
clickhouse.insert.query.time,gauge,,microsecond,,Total time of INSERT queries.,0,clickhouse,,
clickhouse.log.entry.merge.not_created.total,gauge,,event,,Total log entries to merge parts in ReplicatedMergeTree not created due to concurrent log update by another replica.,0,clickhouse,,
clickhouse.log.entry.merge.not_created.count,count,,event,,Log entry to merge parts in ReplicatedMergeTree is not created due to concurrent log update by another replica.,0,clickhouse,,
clickhouse.log.entry.mutation.not_created.total,gauge,,event,,Total log entries to mutate parts in ReplicatedMergeTree not created due to concurrent log update by another replica.,0,clickhouse,,
clickhouse.log.entry.mutation.not_created.count,count,,event,,Log entry to mutate parts in ReplicatedMergeTree is not created due to concurrent log update by another replica.,0,clickhouse,,
clickhouse.perf.alignment.faults.total,gauge,,event,,Total number of alignment faults. These happen when unaligned memory accesses happen; the kernel can handle these but it reduces performance. This happens only on some architectures (never on x86).,0,clickhouse,,
clickhouse.perf.alignment.faults.count,count,,event,,Number of alignment faults. These happen when unaligned memory accesses happen; the kernel can handle these but it reduces performance. This happens only on some architectures (never on x86).,0,clickhouse,,
clickhouse.perf.branch.instructions.total,gauge,,unit,,"Total retired branch instructions. Prior to Linux 2.6.35, this used the wrong event on AMD processors.",0,clickhouse,,
clickhouse.perf.branch.instructions.count,count,,unit,,"Retired branch instructions. Prior to Linux 2.6.35, this used the wrong event on AMD processors.",0,clickhouse,,
clickhouse.perf.branch.misses.total,gauge,,unit,,Total mispredicted branch instructions.,0,clickhouse,,
clickhouse.perf.branch.misses.count,count,,unit,,Mispredicted branch instructions.,0,clickhouse,,
clickhouse.perf.bus.cycles.total,gauge,,unit,,"Total bus cycles, which can be different from total cycles.",0,clickhouse,,
clickhouse.perf.bus.cycles.count,count,,unit,,"Bus cycles, which can be different from total cycles.",0,clickhouse,,
clickhouse.perf.cache.misses.total,gauge,,miss,,Cache misses. Usually this indicates total Last Level Cache misses; this is intended to be used in conjunction with the PERFCOUNTHWCACHEREFERENCES event to calculate cache miss rates.,0,clickhouse,,
clickhouse.perf.cache.misses.count,count,,miss,,Cache misses. Usually this indicates Last Level Cache misses; this is intended to be used in conjunction with the PERFCOUNTHWCACHEREFERENCES event to calculate cache miss rates.,0,clickhouse,,
clickhouse.perf.cache.references.total,gauge,,unit,,Cache accesses. Usually this indicates total Last Level Cache accesses but this may vary depending on your CPU. This may include prefetches and coherency messages; again this depends on the design of your CPU.,0,clickhouse,,
clickhouse.perf.cache.references.count,count,,unit,,Cache accesses. Usually this indicates Last Level Cache accesses but this may vary depending on your CPU. This may include prefetches and coherency messages; again this depends on the design of your CPU.,0,clickhouse,,
clickhouse.perf.context.switches.total,gauge,,,,Total number of context switches,0,clickhouse,,
clickhouse.perf.context.switches.count,count,,,,Number of context switches,0,clickhouse,,
clickhouse.perf.cpu.clock,gauge,,unit,,"The CPU clock, a high-resolution per-CPU timer.",0,clickhouse,,
clickhouse.perf.cpu.cycles.total,gauge,,unit,,Total CPU cycles. Be wary of what happens during CPU frequency scaling.,0,clickhouse,,
clickhouse.perf.cpu.cycles.count,count,,unit,,CPU cycles. Be wary of what happens during CPU frequency scaling.,0,clickhouse,,
clickhouse.perf.cpu.migrations.total,gauge,,unit,,Total number of times the process has migrated to a new CPU,0,clickhouse,,
clickhouse.perf.cpu.migrations.count,count,,unit,,Number of times the process has migrated to a new CPU,0,clickhouse,,
clickhouse.perf.data.tlb.misses.total,gauge,,miss,,Total data TLB misses,0,clickhouse,,
clickhouse.perf.data.tlb.misses.count,count,,miss,,Data TLB misses,0,clickhouse,,
clickhouse.perf.data.tlb.references.total,gauge,,unit,,Total data TLB references,0,clickhouse,,
clickhouse.perf.data.tlb.references.count,count,,unit,,Data TLB references,0,clickhouse,,
clickhouse.perf.emulation.faults.total,gauge,,fault,,Total number of emulation faults. The kernel sometimes traps on unimplemented instructions and emulates them for user space. This can negatively impact performance.,0,clickhouse,,
clickhouse.perf.emulation.faults.count,count,,fault,,Number of emulation faults. The kernel sometimes traps on unimplemented instructions and emulates them for user space. This can negatively impact performance.,0,clickhouse,,
clickhouse.perf.instruction.tlb.misses.total,gauge,,miss,,Total instruction TLB misses,0,clickhouse,,
clickhouse.perf.instruction.tlb.misses.count,count,,miss,,Instruction TLB misses,0,clickhouse,,
clickhouse.perf.instruction.tlb.references.total,gauge,,unit,,Total instruction TLB references,0,clickhouse,,
clickhouse.perf.instruction.tlb.references.count,count,,unit,,Instruction TLB references,0,clickhouse,,
clickhouse.perf.instructions.total,gauge,,unit,,"Total retired instructions. Be careful, these can be affected by various issues, most notably hardware interrupt counts.",0,clickhouse,,
clickhouse.perf.instructions.count,count,,unit,,"Retired instructions. Be careful, these can be affected by various issues, most notably hardware interrupt counts.",0,clickhouse,,
clickhouse.perf.local_memory.misses.total,gauge,,miss,,Total local NUMA node memory read misses,0,clickhouse,,
clickhouse.perf.local_memory.misses.count,count,,miss,,Local NUMA node memory read misses,0,clickhouse,,
clickhouse.perf.local_memory.references.total,gauge,,unit,,Total local NUMA node memory reads,0,clickhouse,,
clickhouse.perf.local_memory.references.count,count,,unit,,Local NUMA node memory reads,0,clickhouse,,
clickhouse.perf.min_enabled.running_time,gauge,,microsecond,,Running time for event with minimum enabled time. Used to track the amount of event multiplexing,0,clickhouse,,
clickhouse.perf.min_enabled.min_time,gauge,,microsecond,,"For all events, minimum time that an event was enabled. Used to track event multiplexing influence.",0,clickhouse,,
clickhouse.perf.cpu.ref_cycles.total,gauge,,unit,,Total cycles; not affected by CPU frequency scaling.,0,clickhouse,,
clickhouse.perf.cpu.ref_cycles.count,count,,unit,,CPU cycles; not affected by CPU frequency scaling.,0,clickhouse,,
clickhouse.perf.stalled_cycles.backend.total,gauge,,unit,,Total stalled cycles during retirement.,0,clickhouse,,
clickhouse.perf.stalled_cycles.backend.count,count,,unit,,Stalled cycles during retirement.,0,clickhouse,,
clickhouse.perf.stalled_cycles.frontend.total,gauge,,unit,,Total stalled cycles during issue.,0,clickhouse,,
clickhouse.perf.stalled_cycles.frontend.count,count,,unit,,Stalled cycles during issue.,0,clickhouse,,
clickhouse.perf.task.clock,gauge,,,,A clock count specific to the task that is running,0,clickhouse,,
clickhouse.query.memory.limit_exceeded.total,gauge,,,,Total number of times when memory limit exceeded for query.,0,clickhouse,,
clickhouse.query.memory.limit_exceeded.count,count,,,,Number of times when memory limit exceeded for query.,0,clickhouse,,
clickhouse.query.time,gauge,,microsecond,,Total time of all queries.,0,clickhouse,,
clickhouse.table.replica.partial.shutdown.total,gauge,,,,Total times Replicated table has to deinitialize its state due to session expiration in ZooKeeper. The state is reinitialized every time when ZooKeeper is available again.,0,clickhouse,,
clickhouse.table.replica.partial.shutdown.count,count,,,,How many times Replicated table has to deinitialize its state due to session expiration in ZooKeeper. The state is reinitialized every time when ZooKeeper is available again.,0,clickhouse,,
clickhouse.s3.read.bytes.total,gauge,,byte,,Total read bytes (incoming) in GET and HEAD requests to S3 storage.,0,clickhouse,,
clickhouse.s3.read.bytes.count,count,,byte,,Read bytes (incoming) in GET and HEAD requests to S3 storage.,0,clickhouse,,
clickhouse.s3.read.time,gauge,,microsecond,,Time of GET and HEAD requests to S3 storage.,0,clickhouse,,
clickhouse.s3.read.requests.total,gauge,,request,,Total number of GET and HEAD requests to S3 storage.,0,clickhouse,,
clickhouse.s3.read.requests.count,count,,request,,Number of GET and HEAD requests to S3 storage.,0,clickhouse,,
clickhouse.s3.read.requests.errors.total,gauge,,error,,Total number of non-throttling errors in GET and HEAD requests to S3 storage.,0,clickhouse,,
clickhouse.s3.read.requests.errors.count,count,,error,,Number of non-throttling errors in GET and HEAD requests to S3 storage.,0,clickhouse,,
clickhouse.s3.read.requests.redirects.total,gauge,,unit,,Total number of redirects in GET and HEAD requests to S3 storage.,0,clickhouse,,
clickhouse.s3.read.requests.redirects.count,count,,unit,,Number of redirects in GET and HEAD requests to S3 storage.,0,clickhouse,,
clickhouse.s3.read.requests.throttling.total,gauge,,error,,Total number of 429 and 503 errors in GET and HEAD requests to S3 storage.,0,clickhouse,,
clickhouse.s3.read.requests.throttling.count,count,,error,,Number of 429 and 503 errors in GET and HEAD requests to S3 storage.,0,clickhouse,,
clickhouse.s3.write.bytes.total,gauge,,byte,,"Total write bytes (outgoing) in POST, DELETE, PUT and PATCH requests to S3 storage.",0,clickhouse,,
clickhouse.s3.write.bytes.count,count,,byte,,"Write bytes (outgoing) in POST, DELETE, PUT and PATCH requests to S3 storage.",0,clickhouse,,
clickhouse.s3.write.time,gauge,,microsecond,,"Time of POST, DELETE, PUT and PATCH requests to S3 storage.",0,clickhouse,,
clickhouse.s3.write.requests.total,gauge,,request,,"Total number of POST, DELETE, PUT and PATCH requests to S3 storage.",0,clickhouse,,
clickhouse.s3.write.requests.count,count,,request,,"Number of POST, DELETE, PUT and PATCH requests to S3 storage.",0,clickhouse,,
clickhouse.s3.write.requests.errors.total,gauge,,request,,"Total number of non-throttling errors in POST, DELETE, PUT and PATCH requests to S3 storage.",0,clickhouse,,
clickhouse.s3.write.requests.errors.count,count,,request,,"Number of non-throttling errors in POST, DELETE, PUT and PATCH requests to S3 storage.",0,clickhouse,,
clickhouse.s3.write.requests.redirects.total,gauge,,request,,"Total number of redirects in POST, DELETE, PUT and PATCH requests to S3 storage.",0,clickhouse,,
clickhouse.s3.write.requests.redirects.count,count,,request,,"Number of redirects in POST, DELETE, PUT and PATCH requests to S3 storage.",0,clickhouse,,
clickhouse.s3.write.requests.throttling.total,gauge,,request,,"Total number of 429 and 503 errors in POST, DELETE, PUT and PATCH requests to S3 storage.",0,clickhouse,,
clickhouse.s3.write.requests.throttling.count,count,,request,,"Number of 429 and 503 errors in POST, DELETE, PUT and PATCH requests to S3 storage.",0,clickhouse,,
clickhouse.query.select.time,gauge,,microsecond,,Total time of SELECT queries.,0,clickhouse,,
clickhouse.selected.bytes.total,gauge,,byte,,Total number of bytes (uncompressed; for columns as they stored in memory) SELECTed from all tables.,0,clickhouse,,
clickhouse.selected.bytes.count,count,,byte,,Number of bytes (uncompressed; for columns as they stored in memory) SELECTed from all tables.,0,clickhouse,,
clickhouse.selected.rows.total,gauge,,row,,Number of rows SELECTed from all tables.,0,clickhouse,,
clickhouse.selected.rows.count,count,,row,,Total number of rows SELECTed from all tables.,0,clickhouse,,
clickhouse.aio.read.total,gauge,,read,,Total number of reads with Linux or FreeBSD AIO interface.,0,clickhouse,,
clickhouse.aio.read.count,count,,read,,Number of reads with Linux or FreeBSD AIO interface.,0,clickhouse,,
clickhouse.aio.read.size.total,gauge,,byte,,Total number of bytes read with Linux or FreeBSD AIO interface.,0,clickhouse,,
clickhouse.aio.read.size.count,count,,byte,,Number of bytes read with Linux or FreeBSD AIO interface.,0,clickhouse,,
clickhouse.aio.write.size.total,gauge,,byte,,Total number of bytes read with Linux or FreeBSD AIO interface.,0,clickhouse,,
clickhouse.aio.write.size.count,count,,byte,,Number of bytes read with Linux or FreeBSD AIO interface.,0,clickhouse,,
clickhouse.aio.write.total,gauge,,write,,Total number of writes with Linux or FreeBSD AIO interface.,0,clickhouse,,
clickhouse.aio.write.count,count,,write,,Number of writes with Linux or FreeBSD AIO interface.,0,clickhouse,,
clickhouse.drained_connections.async,gauge,,connection,,Number of connections drained asynchronously.,0,clickhouse,,
clickhouse.drained_connections.sync,gauge,,connection,,Number of connections drained synchronously.,0,clickhouse,,
clickhouse.drained_connections.async.active,gauge,,connection,,Number of active connections drained asynchronously.,0,clickhouse,,
clickhouse.drained_connections.sync.active,gauge,,connection,,Number of active connections drained synchronously.,0,clickhouse,,
clickhouse.table.distributed.file.insert.broken,gauge,,file,,Number of files for asynchronous insertion into Distributed tables that has been marked as broken. This metric will starts from 0 on start. Number of files for every shard is summed.,0,clickhouse,,
clickhouse.table.mergetree.insert.block.projection.total,gauge,,block,,Total number of blocks INSERTed to MergeTree tables projection. Each block forms a data part of level zero.,0,clickhouse,,
clickhouse.table.mergetree.insert.block.projection.count,count,,block,,Number of blocks INSERTed to MergeTree tables projection. Each block forms a data part of level zero.,0,clickhouse,,
clickhouse.table.mergetree.insert.block.already_sorted.projection.total,gauge,,block,,Total number of blocks INSERTed to MergeTree tables projection that appeared to be already sorted.,0,clickhouse,,
clickhouse.table.mergetree.insert.block.size.compressed.projection.count,count,,block,,Number of blocks INSERTed to MergeTree tables projection that appeared to be already sorted.,0,clickhouse,,
clickhouse.table.mergetree.insert.write.row.projection.total,gauge,,row,,Total number of rows INSERTed to MergeTree tables projection.,0,clickhouse,,
clickhouse.table.mergetree.insert.write.row.projection.count,count,,row,,Number of rows INSERTed to MergeTree tables projection.,0,clickhouse,,
clickhouse.table.mergetree.insert.write.size.uncompressed.projection.total,gauge,,byte,,Total uncompressed bytes (for columns as they stored in memory) INSERTed to MergeTree tables projection.,0,clickhouse,,
clickhouse.table.mergetree.insert.write.size.uncompressed.projection.count,count,,byte,,Uncompressed bytes (for columns as they stored in memory) INSERTed to MergeTree tables projection.,0,clickhouse,,
clickhouse.table.replica.change.hedged_requests.total,gauge,,timeout,,Total count when timeout for changing replica expired in hedged requests.,0,clickhouse,,
clickhouse.table.replica.change.hedged_requests.count,gauge,,timeout,,Count when timeout for changing replica expired in hedged requests.,0,clickhouse,,
