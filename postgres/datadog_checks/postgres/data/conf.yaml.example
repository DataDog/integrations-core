## All options defined here are available to all instances.
#
init_config:

    ## @param service - string - optional
    ## Attach the tag `service:<SERVICE>` to every metric, event, and service check emitted by this integration.
    ##
    ## Additionally, this sets the default `service` for every log source.
    #
    # service: <SERVICE>

## Every instance is scheduled independent of the others.
#
instances:

    ## @param host - string - required
    ## The hostname to connect to.
    ## NOTE: Even if the server name is `localhost`, the Agent connects to PostgreSQL using TCP/IP unless you also
    ## provide a value for the sock key.
    #
  - host: localhost

    ## @param port - integer - optional - default: 5432
    ## The port to use when connecting to PostgreSQL.
    #
    # port: 5432

    ## @param username - string - required
    ## The Datadog username created to connect to PostgreSQL.
    #
    username: datadog

    ## @param password - string - optional
    ## The password associated with the Datadog user.
    #
    # password: <PASSWORD>

    ## @param dbname - string - optional - default: postgres
    ## The name of the PostgresSQL database to monitor.
    ## Note: If omitted, the default system Postgres database is queried.
    #
    # dbname: <DBNAME>

    ## @param dbstrict - boolean - optional - default: false
    ## Whether to restrict the scope of the check to just the database in question.
    ## Set to `true` if you only want to gather metrics from the database provided in the dbname parameter.
    #
    # dbstrict: false

    ## @param ignore_databases - list of strings - optional
    ## A list of database to ignore. No metrics or statement samples will be collected for these databases.
    ## Each value can be a plain string or a Postgres pattern.
    ## For more information on how patterns work, see https://www.postgresql.org/docs/12/functions-matching.html
    #
    # ignore_databases:
    #   - template%
    #   - rdsadmin
    #   - azure_maintenance
    #   - postgres

    ## @param ssl - string - optional - default: false
    ## This option determines whether or not and with what priority a secure SSL TCP/IP connection
    ## is negotiated with the server. There are six modes:
    ## - `disable`: Only tries a non-SSL connection.
    ## - `allow`: First tries a non-SSL connection; if if fails, tries an SSL connection.
    ## - `prefer`: First tries an SSL connection; if it fails, tries a non-SSL connection.
    ## - `require`: Only tries an SSL connection. If a root CA file is present, verifies the certificate in
    ##              the same way as if verify-ca was specified.
    ## - `verify-ca`: Only tries an SSL connection, and verifies that the server certificate is issued by a
    ##                trusted certificate authority (CA).
    ## - `verify-full`: Only tries an SSL connection and verifies that the server certificate is issued by a
    ##                  trusted CA and that the requested server host name matches the one in the certificate.
    ##
    ## For a detailed description of how these options work see https://www.postgresql.org/docs/current/libpq-ssl.html
    ##
    ## Note: `true` is an alias for `require`, and `false` is an alias for `disable`.
    #
    # ssl: 'false'

    ## @param query_timeout - integer - optional - default: 5000
    ## Adds a statement_timeout https://www.postgresql.org/docs/current/runtime-config-client.html#GUC-STATEMENT-TIMEOUT
    ## to all metric collection queries. Aborts any statement that takes more than the specified number of milliseconds,
    ## starting from the time the command arrives at the server from the client. A value of zero turns this off.
    ## Cancelled queries won't log any metrics.
    #
    # query_timeout: 5000

    ## @param relations - (list of string or mapping) - optional
    ## The list of relations/tables must be specified here to track per-relation (table, index , view, etc.) metrics.
    ## If enabled, `dbname` should be specified to collect database-specific relations metrics.
    ## You can either specify a single relation by its exact name in 'relation_name' or use a regex to track metrics
    ## from all matching relations (useful in cases where relation names are dynamically generated, e.g. TimescaleDB).
    ## Each relation generates many metrics (10 + 10 per index).
    ##
    ## By default all schemas are included. To track relations from specific schemas only,
    ## you can specify the `schemas` attribute and provide a list of schemas to use for filtering.
    ##
    ## Size metrics are collected only for ordinary tables. Index metrics are collected only for user indexes. Lock
    ## metrics are are collected for all relation types (table, index , view, etc.). The rest of the metrics are
    ## collected only for user tables.
    ## To track lock metrics for relations of a specific kind only, specify the `relkind` attribute
    ## as a list of the options:
    ## * r = ordinary table
    ## * i = index
    ## * S = sequence
    ## * t = TOAST table
    ## * m = materialized view
    ## * c = composite type
    ## * f = foreign table
    ## * p = partitioned table
    ##
    ## Note: For compatibility reasons you can also use the following syntax to track relations metrics by specifying
    ## the list of table names. All schemas are included and regex are not supported.
    ## relations:
    #
    # relations:
    #   - relation_name: <TABLE_NAME>
    #     schemas:
    #     - <SCHEMA_NAME1>
    #   - relation_regex: <TABLE_PATTERN>
    #     relkind:
    #     - r
    #     - p

    ## @param max_relations - integer - optional - default: 300
    ## Determines the maximum number of relations to fetch.
    #
    # max_relations: 300

    ## @param collect_function_metrics - boolean - optional - default: false
    ## If set to true, collects metrics regarding PL/pgSQL functions from pg_stat_user_functions.
    #
    # collect_function_metrics: false

    ## @param collect_count_metrics - boolean - optional - default: true
    ## Collect count of user tables up to max_relations size from pg_stat_user_tables.
    #
    # collect_count_metrics: true

    ## @param collect_activity_metrics - boolean - optional - default: false
    ## Collect metrics regarding transactions from pg_stat_activity. Please make sure the user
    ## has sufficient privileges to read from pg_stat_activity before enabling this option.
    #
    # collect_activity_metrics: false

    ## @param collect_database_size_metrics - boolean - optional - default: true
    ## Collect database size metrics.
    #
    # collect_database_size_metrics: true

    ## @param collect_default_database - boolean - optional - default: false
    ## Include statistics from the default database 'postgres' in the check metrics.
    #
    # collect_default_database: false

    ## @param collect_wal_metrics - boolean - optional - default: false
    ## Collect metrics about WAL file age.
    ## NOTE: You must be running the check local to your database if you want to enable this option.
    #
    # collect_wal_metrics: false

    ## @param data_directory - string - optional - default: /usr/local/pgsql/data
    ## The data directory of your postgres installation
    ## Required when collecting WAL metrics.
    #
    # data_directory: /usr/local/pgsql/data

    ## @param tag_replication_role - boolean - optional - default: false
    ## Tag metrics and checks with `replication_role:<master|standby>`.
    #
    # tag_replication_role: false

    ## @param table_count_limit - integer - optional - default: 200
    ## The maximum number of tables to collect metrics from.
    #
    # table_count_limit: 200

    ## @param custom_queries - list of mappings - optional
    ## Define custom queries to collect custom metrics from your PostgreSQL
    ## See Datadog FAQ article for a guide on collecting custom metrics from PostgreSQL:
    ## https://docs.datadoghq.com/integrations/faq/postgres-custom-metric-collection-explained/
    #
    # custom_queries:
    #   - metric_prefix: postgresql
    #     query: <QUERY>
    #     columns:
    #     - name: <COLUNMS_1_NAME>
    #       type: <COLUMNS_1_TYPE>
    #     - name: <COLUNMS_2_NAME>
    #       type: <COLUMNS_2_TYPE>
    #     tags:
    #     - <TAG_KEY>:<TAG_VALUE>

    ## @param application_name - string - optional - default: datadog-agent
    ## The application_name can be any string of less than NAMEDATALEN characters (64 characters in a standard build).
    ## It is typically set by an application upon connection to the server.
    ## The name is displayed in the pg_stat_activity view and included in CSV log entries.
    #
    # application_name: datadog-agent

    ## @param dbm - boolean - optional - default: false
    ## Set to `true` to enable Database Monitoring.
    #
    # dbm: false

    ## @param pg_stat_statements_view - string - optional - default: show_pg_stat_statements()
    ## Set this value if you want to define a custom view or function to allow the datadog user to query the
    ## `pg_stat_statements` table, which is useful for restricting the permissions given to the datadog agent.
    ## Please note this is an ALPHA feature and is subject to change or deprecation without notice.
    #
    # pg_stat_statements_view: show_pg_stat_statements()

    ## Configure collection of query metrics
    #
    query_metrics:

        ## @param enabled - boolean - optional - default: true
        ## Enable collection of query metrics. Requires `dbm: true`.
        #
        # enabled: true

        ## @param collection_interval - number - optional - default: 10
        ## Set the query metric collection interval (in seconds). Each collection involves a single query to
        ## `pg_stat_statements`. If a non-default value is chosen then that exact same value must be used for *every*
        ## check instance. Running different instances with different collection intervals is not supported.
        #
        # collection_interval: 10

    ## Configure collection of query samples
    #
    query_samples:

        ## @param enabled - boolean - optional - default: true
        ## Enable collection of query samples. Requires `dbm: true`.
        #
        # enabled: true

        ## @param collection_interval - number - optional - default: 1
        ## Set the query sample collection interval (in seconds). Each collection involves a single query to
        ## `pg_stat_activity` followed by at most one `EXPLAIN` query per unique normalized query seen.
        #
        # collection_interval: 1

        ## @param explain_function - string - optional - default: datadog.explain_statement
        ## Override the default function used to collect execution plans for queries.
        #
        # explain_function: datadog.explain_statement

        ## @param explained_queries_per_hour_per_query - integer - optional - default: 60
        ## Set the rate limit for how many execution plans will be collected per hour per normalized query.
        #
        # explained_queries_per_hour_per_query: 60

        ## @param samples_per_hour_per_query - integer - optional - default: 15
        ## Set the rate limit for how many query sample events will be ingested per hour per normalized execution
        ## plan.
        #
        # samples_per_hour_per_query: 15

        ## @param explained_queries_cache_maxsize - integer - optional - default: 5000
        ## Set the max size of the cache used for the explained_queries_per_hour_per_query rate limit. This should
        ## be increased for databases with a very large number unique normalized queries which exceed the cache's
        ## limit.
        #
        # explained_queries_cache_maxsize: 5000

        ## @param seen_samples_cache_maxsize - integer - optional - default: 10000
        ## Set the max size of the cache used for the samples_per_hour_per_query rate limit. This should be increased
        ## for databases with a very large number of unique normalized execution plans which exceed the cache's limit.
        #
        # seen_samples_cache_maxsize: 10000

    ## Configure collection of query activity
    #
    query_activity:

        ## @param enabled - boolean - optional - default: true
        ## Enable collection of query activity. Requires `dbm: true`, and enabling query_samples.
        #
        # enabled: true

        ## @param collection_interval - number - optional - default: 10
        ## Set the query activity collection interval (in seconds). This number cannot be smaller than
        ## query_samples configured collection_interval.
        #
        # collection_interval: 10

    ## Configure how the SQL obfuscator behaves.
    #
    obfuscator_options:

        ## @param replace_digits - boolean - optional - default: false
        ## Set to `true` to replace digits in identifiers and table names with question marks in your SQL statements.
        ##
        ## Note that this option only applies when `dbm` is enabled.
        #
        # replace_digits: false

    ## @param tags - list of strings - optional
    ## A list of tags to attach to every metric and service check emitted by this instance.
    ##
    ## Learn more about tagging at https://docs.datadoghq.com/tagging
    #
    # tags:
    #   - <KEY_1>:<VALUE_1>
    #   - <KEY_2>:<VALUE_2>

    ## @param service - string - optional
    ## Attach the tag `service:<SERVICE>` to every metric, event, and service check emitted by this integration.
    ##
    ## Overrides any `service` defined in the `init_config` section.
    #
    # service: <SERVICE>

    ## @param min_collection_interval - number - optional - default: 15
    ## This changes the collection interval of the check. For more information, see:
    ## https://docs.datadoghq.com/developers/write_agent_check/#collection-interval
    #
    # min_collection_interval: 15

    ## @param empty_default_hostname - boolean - optional - default: false
    ## This forces the check to send metrics with no hostname.
    ##
    ## This is useful for cluster-level checks.
    #
    # empty_default_hostname: false

    ## @param disable_generic_tags - boolean - optional - default: false
    ## The integration will stop sending server tag as is reduntant with host tag
    #
    disable_generic_tags: true

## Log Section
##
## type - required - Type of log input source (tcp / udp / file / windows_event)
## port / path / channel_path - required - Set port if type is tcp or udp.
##                                         Set path if type is file.
##                                         Set channel_path if type is windows_event.
## source  - required - Attribute that defines which integration sent the logs.
## encoding - optional - For file specifies the file encoding, default is utf-8, other
##                       possible values are utf-16-le and utf-16-be.
## service - optional - The name of the service that generates the log.
##                      Overrides any `service` defined in the `init_config` section.
## tags - optional - Add tags to the collected logs.
##
## Discover Datadog log collection: https://docs.datadoghq.com/logs/log_collection/
#
# logs:
#   - type: file
#     path: /path/to/postgres.log
#     source: postgresql
#     service: <SERVICE>
#     log_processing_rules:
#     - type: multi_line
#       pattern: \d{4}\-(0?[1-9]|1[012])\-(0?[1-9]|[12][0-9]|3[01])
#       name: new_log_start_with_date
