## All options defined here are available to all instances.
#
init_config:

    ## @param service - string - optional
    ## Attach the tag `service:<SERVICE>` to every metric, event, and service check emitted by this integration.
    ##
    ## Additionally, this sets the default `service` for every log source.
    #
    # service: <SERVICE>

## Every instance is scheduled independent of the others.
#
instances:

    ## @param host - string - required
    ## The hostname to connect to.
    ## NOTE: Even if the server name is `localhost`, the Agent connects to PostgreSQL using TCP/IP unless you also
    ## provide a value for the sock key.
    #
  - host: localhost

    ## @param port - integer - optional - default: 5432
    ## The port to use when connecting to PostgreSQL.
    #
    # port: 5432

    ## @param username - string - required
    ## The Datadog username created to connect to PostgreSQL.
    #
    username: datadog

    ## @param password - string - optional
    ## The password associated with the Datadog user.
    #
    # password: <PASSWORD>

    ## @param dbname - string - optional - default: postgres
    ## The name of the PostgresSQL database to monitor.
    ## Note: If omitted, the default system Postgres database is queried.
    #
    # dbname: <DBNAME>

    ## @param ssl - string - optional - default: False
    ## This option determines whether or not and with what priority a secure SSL TCP/IP connection
    ## is negotiated with the server. There are six modes:
    ## - `disable`: Only tries a non-SSL connection.
    ## - `allow`: First tries a non-SSL connection; if if fails, tries an SSL connection.
    ## - `prefer`: First tries an SSL connection; if it fails, tries a non-SSL connection.
    ## - `require`: Only tries an SSL connection. If a root CA file is present, verifies the certificate in
    ##              the same way as if verify-ca was specified.
    ## - `verify-ca`: Only tries an SSL connection, and verifies that the server certificate is issued by a
    ##                trusted certificate authority (CA).
    ## - `verify-full`: Only tries an SSL connection and verifies that the server certificate is issued by a
    ##                  trusted CA and that the requested server host name matches the one in the certificate.
    ##
    ## For a detailed description of how these options work see https://www.postgresql.org/docs/current/libpq-ssl.html
    ##
    ## Note: `true` is an alias for `require`, and `false` is an alias for `disable`.
    #
    # ssl: 'false'

    ## @param query_timeout - integer - optional
    ## Adds a statement_timeout https://www.postgresql.org/docs/current/runtime-config-client.html#GUC-STATEMENT-TIMEOUT
    ## to all metric collection queries. Aborts any statement that takes more than the specified number of milliseconds,
    ## starting from the time the command arrives at the server from the client. A value of zero turns this off.
    ## Cancelled queries won't log any metrics.
    #
    # query_timeout: 1000

    ## @param relations - list of mappings - optional
    ## The list of relations/tables must be specified here to track per-relation (table) metrics.
    ## If enabled, `dbname` should be specified to collect database-specific relations metrics.
    ## You can either specify a single relation by its exact name in 'relation_name' or use a regex to track metrics
    ## from all matching relations (useful in cases where relation names are dynamically generated, e.g. TimescaleDB).
    ## Each relation generates many metrics (10 + 10 per index).
    ## By default all schemas are included. To track relations from specific schemas only,
    ## you can specify the `schemas` attribute and provide a list of schemas to use for filtering.
    ##
    ## Note: For compatibility reasons you can also use the following syntax to track relations metrics by specifying
    ## the list of table names. All schemas are included and regex are not supported.
    ## relations:
    ##   - <TABLE_NAME1>
    ##   - <TABLE_NAME2>
    #
    # relations:
    #   - relation_name: <TABLE_NAME>
    #     schemas:
    #     - <SCHEMA_NAME1>
    #   - relation_regex: <TABLE_PATTERN>

    ## @param max_relations - integer - optional - default: 300
    ## Determines the maximum number of relations to fetch.
    #
    # max_relations: 300

    ## @param collect_function_metrics - boolean - optional - default: false
    ## If set to true, collects metrics regarding PL/pgSQL functions from pg_stat_user_functions.
    #
    # collect_function_metrics: false

    ## @param collect_count_metrics - boolean - optional - default: true
    ## Collect count of user tables up to max_relations size from pg_stat_user_tables.
    #
    # collect_count_metrics: true

    ## @param collect_activity_metrics - boolean - optional - default: false
    ## Collect metrics regarding transactions from pg_stat_activity. Please make sure the user
    ## has sufficient privileges to read from pg_stat_activity before enabling this option.
    #
    # collect_activity_metrics: false

    ## @param collect_database_size_metrics - boolean - optional - default: true
    ## Collect database size metrics.
    #
    # collect_database_size_metrics: true

    ## @param collect_default_database - boolean - optional - default: false
    ## Include statistics from the default database 'postgres' in the check metrics.
    #
    # collect_default_database: false

    ## @param tag_replication_role - boolean - optional - default: false
    ## Tag metrics and checks with `replication_role:<master|standby>`.
    #
    # tag_replication_role: false

    ## @param table_count_limit - integer - optional - default: 200
    ## The maximum number of tables to collect metrics from.
    #
    # table_count_limit: 200

    ## @param custom_queries - list of mappings - optional
    ## Define custom queries to collect custom metrics from your PostgreSQL
    ## See Datadog FAQ article for a guide on collecting custom metrics from PostgreSQL:
    ## https://docs.datadoghq.com/integrations/faq/postgres-custom-metric-collection-explained/
    #
    # custom_queries:
    #   - metric_prefix: postgresql
    #     query: <QUERY>
    #     columns:
    #     - name: <COLUNMS_1_NAME>
    #       type: <COLUMNS_1_TYPE>
    #     - name: <COLUNMS_2_NAME>
    #       type: <COLUMNS_2_TYPE>
    #     tags:
    #     - <TAG_KEY>:<TAG_VALUE>

    ## @param tags - list of strings - optional
    ## A list of tags to attach to every metric and service check emitted by this instance.
    ##
    ## Learn more about tagging at https://docs.datadoghq.com/tagging
    #
    # tags:
    #   - <KEY_1>:<VALUE_1>
    #   - <KEY_2>:<VALUE_2>

    ## @param service - string - optional
    ## Attach the tag `service:<SERVICE>` to every metric, event, and service check emitted by this integration.
    ##
    ## Overrides any `service` defined in the `init_config` section.
    #
    # service: <SERVICE>

    ## @param min_collection_interval - number - optional - default: 15
    ## This changes the collection interval of the check. For more information, see:
    ## https://docs.datadoghq.com/developers/write_agent_check/#collection-interval
    #
    # min_collection_interval: 15

    ## @param empty_default_hostname - boolean - optional - default: false
    ## This forces the check to send metrics with no hostname.
    ##
    ## This is useful for cluster-level checks.
    #
    # empty_default_hostname: false

## Log Section
##
## type - required - Type of log input source (tcp / udp / file / windows_event)
## port / path / channel_path - required - Set port if type is tcp or udp.
##                                         Set path if type is file.
##                                         Set channel_path if type is windows_event.
## source  - required - Attribute that defines which Integration sent the logs.
## service - optional - The name of the service that generates the log.
##                      Overrides any `service` defined in the `init_config` section.
## tags - optional - Add tags to the collected logs.
##
## Discover Datadog log collection: https://docs.datadoghq.com/logs/log_collection/
#
# logs:
#   - type: file
#     path: /path/to/postgres.log
#     source: postgresql
#     service: <SERVICE>
#     log_processing_rules:
#     - type: multi_line
#       pattern: \d{4}\-(0?[1-9]|1[012])\-(0?[1-9]|[12][0-9]|3[01])
#       name: new_log_start_with_date
