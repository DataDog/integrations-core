# (C) Datadog, Inc. 2023-present
# All rights reserved
# Licensed under a 3-clause BSD style license (see LICENSE)
import pprint
import threading
import time
import uuid

import psycopg
import pytest

from datadog_checks.postgres import PostgreSql
from datadog_checks.postgres.connections import ConnectionPoolFullError, MultiDatabaseConnectionPool
from datadog_checks.postgres.util import DatabaseHealthCheckError

from .utils import POSTGRES_VERSION, _get_superconn


@pytest.mark.integration
@pytest.mark.usefixtures('dd_environment')
def test_conn_pool(pg_instance):
    """
    Test simple case of creating a connection pool
    and closing all connections.
    """
    check = PostgreSql('postgres', {}, [pg_instance])

    pool = MultiDatabaseConnectionPool(check._new_connection)
    db = pool._get_connection_raw('postgres', 100)
    assert pool._stats.connection_opened == 1
    assert len(pool._conns) == 1
    assert pool._stats.connection_closed == 0

    with db.cursor() as cursor:
        cursor.execute("select 1")
        rows = cursor.fetchall()
        assert len(rows) == 1 and rows[0][0] == 1

    # Sleep past the idle timeout and make sure we get a new connection
    time.sleep(2)

    db = pool._get_connection_raw('postgres', 999 * 1000)
    assert len(pool._conns) == 1
    # If we're on 14+ the connection should have idled out and we should have a new connection
    assert pool._stats.connection_opened == 1 if float(POSTGRES_VERSION) < 14.0 else 2
    success = pool.close_all_connections()
    assert success
    assert len(pool._conns) == 0
    assert pool._stats.connection_closed == 1
    assert pool._stats.connection_closed_failed == 0


@pytest.mark.integration
@pytest.mark.usefixtures('dd_environment')
def test_conn_pool_no_leaks_on_close(pg_instance):
    """
    Test a simple case of opening and closing many connections. There should be no leaked connections on the server.
    """
    unique_id = str(uuid.uuid4())  # Used to isolate this test from others on the DB

    check = PostgreSql('postgres', {}, [pg_instance])
    check._config.application_name = unique_id

    # # Used to make verification queries
    # pool2 = MultiDatabaseConnectionPool(
    #     lambda dbname: psycopg.connect(host=HOST, dbname=dbname, user=USER_ADMIN, password=PASSWORD_ADMIN)
    # )

    super_conn = _get_superconn(pg_instance)

    def get_activity():
        """
        Fetches all pg_stat_activity rows generated by this test and connection to a "dogs%" database
        """
        with super_conn.cursor() as cursor:
            # cursor = conn.cursor()
            cursor.execute(
                "SELECT pid, datname, usename, state, query_start, state_change, application_name"
                " FROM pg_stat_activity"
                " WHERE datname LIKE 'dogs%%' AND application_name = %s",
                (unique_id,),
            )
            return cursor.fetchall()

    # Iterate in the test many times to detect flakiness
    for _ in range(20):
        pool = MultiDatabaseConnectionPool(check._new_connection)

        conn_count = 100
        for i in range(0, conn_count):
            dbname = 'dogs_{}'.format(i)
            db = pool._get_connection_raw(dbname, 10 * 1000)
            with db.cursor() as cursor:
                cursor.execute("SET client_encoding TO 'UTF8'")
                cursor.execute("select current_database()")
                rows = cursor.fetchall()
                assert len(rows) == 1
                assert rows[0][0] == dbname

        assert pool._stats.connection_opened == conn_count
        assert len(get_activity()) == conn_count

        pool.close_all_connections()
        assert pool._stats.connection_closed == conn_count
        assert pool._stats.connection_closed_failed == 0

        # Ensure all the connections have been terminated on the server
        attempts = 10
        while True:
            attempts -= 1

            rows = get_activity()
            if len(rows) == 0:
                break

            assert attempts >= 0, "Connections leaked! Leaked rows found:\n{}".format(pprint.pformat(rows))
            time.sleep(1)


@pytest.mark.integration
@pytest.mark.usefixtures('dd_environment')
def test_conn_pool_single_context(pg_instance):
    """
    Test creating a single connection.
    """
    check = PostgreSql('postgres', {}, [pg_instance])

    pool = MultiDatabaseConnectionPool(check._new_connection)
    with pool.get_connection("dogs_0", 1000):
        pass

    assert pool._stats.connection_opened == 1

    expected_evicted = "dogs_0"
    evicted = pool.evict_lru()
    assert evicted == expected_evicted
    assert pool._stats.connection_closed == 1

    # ask for another connection again, error not raised
    with pool.get_connection("dogs_1", 1000):
        pass


@pytest.mark.integration
@pytest.mark.usefixtures('dd_environment')
def test_conn_pool_timeouts(pg_instance):
    """
    Test creating a single connection.
    """
    check = PostgreSql('postgres', {}, [pg_instance])

    pool = MultiDatabaseConnectionPool(check._new_connection)
    with pool.get_connection("dogs_0", 10) as conn:
        conn.cursor().execute("SELECT 1")

    assert pool._stats.connection_opened == 1

    time.sleep(2)  # Sleep past the idle timeout

    # ask for another connection again, error not raised
    with pool.get_connection("dogs_0", 10) as conn:
        conn.cursor().execute("SELECT 1")


@pytest.mark.integration
@pytest.mark.usefixtures('dd_environment')
def test_conn_pool_context_managed(pg_instance):
    """
    Test context manager API for connection grabbing.
    """

    def pretend_to_run_query(pool, dbname):
        with pool.get_connection(dbname, 10000):
            time.sleep(5)

    limit = 30
    check = PostgreSql('postgres', {}, [pg_instance])

    pool = MultiDatabaseConnectionPool(check._new_connection, limit)
    threadpool = []
    for i in range(limit):
        thread = threading.Thread(target=pretend_to_run_query, args=(pool, 'dogs_{}'.format(i)))
        threadpool.append(thread)
        thread.start()

    time.sleep(1)
    assert pool._stats.connection_opened == limit

    # ask for one more connection
    with pytest.raises(ConnectionPoolFullError):
        with pool.get_connection('dogs_{}'.format(limit + 1), 1, 1):
            pass

    # join threads
    for thread in threadpool:
        thread.join()

    # now can add a new connection, one will get kicked out of pool
    with pool.get_connection('dogs_{}'.format(limit + 1), 60000):
        pass

    assert pool._stats.connection_closed == 1

    # close the rest
    pool.close_all_connections()
    assert pool._stats.connection_closed == limit + 1


@pytest.mark.integration
@pytest.mark.usefixtures('dd_environment')
def test_conn_terminated_prematurely(pg_instance):
    """
    Test db connection terminated prematurely
    """

    def _terminate_connection(conn, dbname):
        # function to abruptly terminate a connection
        with conn.cursor() as cursor:
            cursor.execute(
                "SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE pid <> pg_backend_pid() AND datname = %s",
                (dbname,),
            )

    check = PostgreSql('postgres', {}, [pg_instance])
    conn = _get_superconn(pg_instance)

    check.check(pg_instance)
    assert check._db is not None
    assert not check._db.closed

    _terminate_connection(conn, pg_instance['dbname'])
    time.sleep(1)

    assert check._db is not None

    # the connection is terminated on the server, psycopg has no way of knowing
    # this check run will fail but the connection status should be updated
    with pytest.raises(DatabaseHealthCheckError):
        check.check(pg_instance)

    # connection status is updated to closed
    assert check._db is not None
    assert check._db.closed

    # new check run will re-open connection
    check.check(pg_instance)


@pytest.mark.integration
@pytest.mark.usefixtures('dd_environment')
def test_conn_statement_timeout(pg_instance):
    """
    Test db connection statement timeout is set at the session level
    """
    pg_instance["query_timeout"] = 500
    check = PostgreSql('postgres', {}, [pg_instance])
    check._connect()
    with pytest.raises(psycopg.errors.QueryCanceled):
        with check.db() as conn:
            with conn.cursor() as cursor:
                cursor.execute("SELECT pg_sleep(1)")
