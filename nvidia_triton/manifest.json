{
  "manifest_version": "2.0.0",
  "app_uuid": "72d17043-fa30-4f5c-95cb-939906d86fb7",
  "app_id": "nvidia-triton",
  "display_on_public_website": true,
  "tile": {
    "overview": "README.md#Overview",
    "configuration": "README.md#Setup",
    "support": "README.md#Support",
    "changelog": "CHANGELOG.md",
    "description": "NVIDIA Triton Inference Server is open source inference-serving software",
    "title": "Nvidia Triton",
    "media": [],
    "classifier_tags": [
      "Supported OS::Linux",
      "Supported OS::Windows",
      "Supported OS::macOS",
      "Category::Log Collection",
      "Category::AI/ML",
      "Submitted Data Type::Metrics"
    ]
  },
  "assets": {
    "integration": {
      "source_type_name": "Nvidia Triton",
      "source_type_id": 10416,
      "configuration": {
        "spec": "assets/configuration/spec.yaml"
      },
      "events": {
        "creates_events": false
      },
      "metrics": {
        "prefix": "nvidia_triton.",
        "check": "nvidia_triton.cpu.memory.total_bytes",
        "metadata_path": "metadata.csv"
      },
      "service_checks": {
        "metadata_path": "assets/service_checks.json"
      },
      "process_signatures": [
        "tritonserver"
      ],
      "auto_install": true
    },
    "dashboards": {
      "Nvidia Triton Overview": "assets/dashboards/nvidia_triton_overview.json"
    },
    "monitors": {
      "[Nvidia Triton] GPU utilization is high": "assets/monitors/gpu_utilization.json",
      "[Nvidia Triton] CPU Memory Usage is high": "assets/monitors/cpu_memory.json"
    },
    "logs": {
      "source": "nvidia_triton"
    }
  },
  "author": {
    "support_email": "help@datadoghq.com",
    "name": "Datadog",
    "homepage": "https://www.datadoghq.com",
    "sales_email": "info@datadoghq.com"
  }
}
