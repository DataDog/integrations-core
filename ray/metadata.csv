metric_name,metric_type,interval,unit_name,per_unit_name,description,orientation,integration,short_name,curated_metric
ray.actors,gauge,,,,Current number of actors currently in a particular state.,0,ray,,
ray.cluster.active_nodes,gauge,,node,,Active nodes on the cluster,0,ray,,
ray.cluster.failed_nodes,gauge,,node,,Failed nodes on the cluster,0,ray,,
ray.cluster.pending_nodes,gauge,,node,,Pending nodes on the cluster,0,ray,,
ray.component.cpu_percentage,gauge,,percent,,Total CPU usage of the components on a node.,0,ray,,
ray.component.mem_shared,gauge,,byte,,SHM usage of all components of the node. It is equivalent to the top command's SHR column.,0,ray,,
ray.component.rss,gauge,,megabyte,,RSS usage of all components on the node.,0,ray,,
ray.component.uss,gauge,,megabyte,,USS usage of all components on the node.,0,ray,,
ray.gcs.actors,gauge,,,,"Number of actors per state {Created, Destroyed, Unresolved, Pending}",0,ray,,
ray.gcs.placement_group,gauge,,,,"Number of placement groups broken down by state in {Registered, Pending, Infeasible}",0,ray,,
ray.gcs.storage_operation.count,count,,,,Number of operations invoked on Gcs storage,0,ray,,
ray.gcs.storage_operation.latency.bucket,count,,millisecond,,Time to invoke an operation on Gcs storage,0,ray,,
ray.gcs.storage_operation.latency.count,count,,,,Time to invoke an operation on Gcs storage,0,ray,,
ray.gcs.storage_operation.latency.sum,count,,millisecond,,Time to invoke an operation on Gcs storage,0,ray,,
ray.gcs.task_manager.task_events.dropped,gauge,,event,,"Number of task events dropped per type {PROFILE_EVENT, STATUS_EVENT}",0,ray,,
ray.gcs.task_manager.task_events.reported,gauge,,event,,Number of all task events reported to gcs.,0,ray,,
ray.gcs.task_manager.task_events.stored,gauge,,event,,Number of task events stored in GCS.,0,ray,,
ray.gcs.task_manager.task_events.stored_bytes,gauge,,byte,,Number of bytes of all task events stored in GCS.,0,ray,,
ray.grpc_server.req.finished.count,count,,request,,Finished request number in grpc server,0,ray,,
ray.grpc_server.req.handling.count,count,,request,,Request number are handling in grpc server,0,ray,,
ray.grpc_server.req.new.count,count,,request,,New request number in grpc server,0,ray,,
ray.grpc_server.req.process_time,gauge,,millisecond,,Request latency in grpc server,0,ray,,
ray.health_check.rpc_latency.bucket,count,,millisecond,,Latency of rpc request for health check.,0,ray,,
ray.health_check.rpc_latency.count,count,,,,Latency of rpc request for health check.,0,ray,,
ray.health_check.rpc_latency.sum,count,,millisecond,,Latency of rpc request for health check.,0,ray,,
ray.internal_num.infeasible_scheduling_classes,gauge,,,,The number of unique scheduling classes that are infeasible.,0,ray,,
ray.internal_num.processes.skipped.job_mismatch,gauge,,process,,The total number of cached workers skipped due to job mismatch.,0,ray,,
ray.internal_num.processes.skipped.runtime_environment_mismatch,gauge,,process,,The total number of cached workers skipped due to runtime environment mismatch.,0,ray,,
ray.internal_num.processes.started,gauge,,process,,The total number of worker processes the worker pool has created.,0,ray,,
ray.internal_num.processes.started.from_cache,gauge,,process,,The total number of workers started from a cached worker process.,0,ray,,
ray.internal_num.spilled_tasks,gauge,,request,,The cumulative number of lease requests that this raylet has spilled to other raylets.,0,ray,,
ray.memory_manager.worker_eviction,count,,,,The number of tasks and actors killed by the Ray Out of Memory killer broken down by types (whether it is tasks or actors) and names (name of tasks and actors).,0,ray,,
ray.node.cpu,gauge,,,,Total CPUs available on a ray node,0,ray,,
ray.node.cpu_utilization,gauge,,,,Total CPU usage on a ray node,0,ray,,
ray.node.disk.free,gauge,,byte,,Total disk free (bytes) on a ray node,0,ray,,
ray.node.disk.io.read,gauge,,,,Total read from disk,0,ray,,
ray.node.disk.io.read.count,gauge,,operation,,Total read ops from disk,0,ray,,
ray.node.disk.io.read.speed,gauge,,,,Disk read speed,0,ray,,
ray.node.disk.io.write,gauge,,,,Total written to disk,0,ray,,
ray.node.disk.io.write.count,gauge,,,,Total write ops to disk,0,ray,,
ray.node.disk.io.write.speed,gauge,,,,Disk write speed,0,ray,,
ray.node.disk.read.iops,gauge,,,,Disk read iops,0,ray,,
ray.node.disk.usage,gauge,,byte,,Total disk usage (bytes) on a ray node,0,ray,,
ray.node.disk.utilization,gauge,,percent,,Total disk utilization (percentage) on a ray node,0,ray,,
ray.node.disk.write.iops,gauge,,,,Disk write iops,0,ray,,
ray.node.gpus_utilization,gauge,,percent,,"The GPU utilization per GPU as a percentage quantity (0..NGPU*100). GpuDeviceName is a name of a GPU device (e.g., Nvidia A10G) and GpuIndex is the index of the GPU.",0,ray,,
ray.node.gram_used,gauge,,byte,,"The amount of GPU memory used per GPU, in bytes.",0,ray,,
ray.node.mem.available,gauge,,byte,,Memory available on a ray node,0,ray,,
ray.node.mem.shared,gauge,,byte,,Total shared memory usage on a ray node,0,ray,,
ray.node.mem.total,gauge,,byte,,Total memory on a ray node,0,ray,,
ray.node.mem.used,gauge,,byte,,Memory usage on a ray node,0,ray,,
ray.node.network.receive.speed,gauge,,,,Network receive speed,0,ray,,
ray.node.network.received,gauge,,,,Total network received,0,ray,,
ray.node.network.send.speed,gauge,,,,Network send speed,0,ray,,
ray.node.network.sent,gauge,,,,Total network sent,0,ray,,
ray.object_directory.added_locations,gauge,,,,"Number of object locations added per second., If this is high, a lot of objects have been added on this node.",0,ray,,
ray.object_directory.lookups,gauge,,,,"Number of object location lookups per second. If this is high, the raylet is waiting on a lot of objects.",0,ray,,
ray.object_directory.removed_locations,gauge,,,,"Number of object locations removed per second. If this is high, a lot of objects have been removed from this node.",0,ray,,
ray.object_directory.subscriptions,gauge,,,,"Number of object location subscriptions. If this is high, the raylet is attempting to pull a lot of objects.",0,ray,,
ray.object_directory.updates,gauge,,update,second,"Number of object location updates per second., If this is high, the raylet is attempting to pull a lot of objects and/or the locations for objects are frequently changing (e.g. due to many object copies or evictions).",0,ray,,
ray.object_manager.bytes,gauge,,byte,,"Number of bytes pushed or received by type {PushedFromLocalPlasma, PushedFromLocalDisk, Received}.",0,ray,,
ray.object_manager.num_pull_requests,gauge,,,,Number of active pull requests for objects.,0,ray,,
ray.object_manager.received_chunks,gauge,,,,"Number object chunks received broken per type {Total, FailedTotal, FailedCancelled, FailedPlasmaFull}.",0,ray,,
ray.object_store.available_memory,gauge,,byte,,Amount of memory currently available in the object store.,0,ray,,
ray.object_store.fallback_memory,gauge,,byte,,Amount of memory in fallback allocations in the filesystem.,0,ray,,
ray.object_store.memory,gauge,,byte,,Object store memory by various sub-kinds on this node,0,ray,,
ray.object_store.num_local_objects,gauge,,object,,Number of objects currently in the object store.,0,ray,,
ray.object_store.size.bucket,count,,byte,,The distribution of object size in bytes,0,ray,,
ray.object_store.size.count,count,,,,The distribution of object size in bytes,0,ray,,
ray.object_store.size.sum,count,,byte,,The distribution of object size in bytes,0,ray,,
ray.object_store.used_memory,gauge,,byte,,Amount of memory currently occupied in the object store.,0,ray,,
ray.placement_groups,gauge,,,,"Current number of placement groups by state. The State label (e.g., PENDING, CREATED, REMOVED) describes the state of the placement group.",0,ray,,
ray.process.cpu_seconds.count,count,,second,,Total user and system CPU time spent in seconds.,0,ray,,
ray.process.max_fds,gauge,,file,,Maximum number of open file descriptors.,0,ray,,
ray.process.open_fds,gauge,,file,,Number of open file descriptors.,0,ray,,
ray.process.resident_memory,gauge,,byte,,Resident memory size in bytes.,0,ray,,
ray.process.start_time,gauge,,second,,Start time of the process since unix epoch in seconds.,0,ray,,
ray.process.virtual_memory,gauge,,byte,,Virtual memory size in bytes.,0,ray,,
ray.pull_manager.active_bundles,gauge,,request,,Number of active bundle requests,0,ray,,
ray.pull_manager.num_object_pins,gauge,,attempt,,"Number of object pin attempts by the pull manager, can be {Success, Failure}.",0,ray,,
ray.pull_manager.object_request_time.bucket,count,,millisecond,,Time between initial object pull request and local pinning of the object.,0,ray,,
ray.pull_manager.object_request_time.count,count,,,,Time between initial object pull request and local pinning of the object.,0,ray,,
ray.pull_manager.object_request_time.sum,count,,millisecond,,Time between initial object pull request and local pinning of the object.,0,ray,,
ray.pull_manager.requested_bundles,gauge,,,,"Number of requested bundles broken per type {Get, Wait, TaskArgs}.",0,ray,,
ray.pull_manager.requests,gauge,,request,,"Number of pull requests broken per type {Queued, Active, Pinned}.",0,ray,,
ray.pull_manager.retries_total,gauge,,,,Number of cumulative pull retries.,0,ray,,
ray.pull_manager.usage,gauge,,byte,,"The total number of bytes usage broken per type {Available, BeingPulled, Pinned}",0,ray,,
ray.push_manager.chunks,gauge,,,,"Number of object chunks transfer broken per type {InFlight, Remaining}.",0,ray,,
ray.push_manager.in_flight_pushes,gauge,,request,,Number of in flight object push requests.,0,ray,,
ray.python.gc.collections.count,count,,,,Number of times this generation was collected,0,ray,,
ray.python.gc.objects_collected.count,count,,object,,Objects collected during gc,0,ray,,
ray.python.gc.objects_uncollectable.count,count,,object,,Uncollectable objects found during GC,0,ray,,
ray.resources,gauge,,resource,,"Logical Ray resources broken per state {AVAILABLE, USED}",0,ray,,
ray.scheduler.failed_worker_startup,gauge,,task,,"Number of tasks that fail to be scheduled because workers were not available. Labels are broken per reason {JobConfigMissing, RegistrationTimedOut, RateLimited}",0,ray,,
ray.scheduler.placement_time.bucket,count,,second,,"The time it takes for a workload (task, actor, placement group) to be placed. This is the time from when the tasks dependencies are resolved to when it actually reserves resources on a node to run.",0,ray,,
ray.scheduler.placement_time.count,count,,,,"The time it takes for a workload (task, actor, placement group) to be placed. This is the time from when the tasks dependencies are resolved to when it actually reserves resources on a node to run.",0,ray,,
ray.scheduler.placement_time.sum,count,,second,,"The time it takes for a workload (task, actor, placement group) to be placed. This is the time from when the tasks dependencies are resolved to when it actually reserves resources on a node to run.",0,ray,,
ray.scheduler.tasks,gauge,,task,,"Number of tasks waiting for scheduling broken per state {Cancelled, Executing, Waiting, Dispatched, Received}.",0,ray,,
ray.scheduler.unscheduleable_tasks,gauge,,task,,"Number of pending tasks (not scheduleable tasks) broken per reason {Infeasible, WaitingForResources, WaitingForPlasmaMemory, WaitingForRemoteResources, WaitingForWorkers}.",0,ray,,
ray.serve.deployment.error,gauge,,exception,,The number of exceptions that have occurred in this replica.,0,ray,,
ray.serve.deployment.processing_latency.bucket,count,,millisecond,,The latency for queries to be processed.,0,ray,,
ray.serve.deployment.processing_latency.count,count,,,,The latency for queries to be processed.,0,ray,,
ray.serve.deployment.processing_latency.sum,count,,millisecond,,The latency for queries to be processed.,0,ray,,
ray.serve.deployment.queued_queries,gauge,,query,,The current number of queries to this deployment waiting to be assigned to a replica.,0,ray,,
ray.serve.deployment.replica.healthy,gauge,,,,"Tracks whether this deployment replica is healthy. 1 means healthy, 0 means unhealthy.",0,ray,,
ray.serve.deployment.replica.starts,gauge,,,,The number of times this replica has been restarted due to failure.,0,ray,,
ray.serve.deployment.request.counter,gauge,,query,,The number of queries that have been processed in this replica.,0,ray,,
ray.serve.grpc_request_latency.bucket,count,,,,The end-to-end latency of GRPC requests (measured from the Serve GRPC proxy).,0,ray,,
ray.serve.grpc_request_latency.count,count,,,,The end-to-end latency of GRPC requests (measured from the Serve GRPC proxy).,0,ray,,
ray.serve.grpc_request_latency.sum,count,,,,The end-to-end latency of GRPC requests (measured from the Serve GRPC proxy).,0,ray,,
ray.serve.handle_request,gauge,,request,,The number of handle.remote() calls that have been made on this handle.,0,ray,,
ray.serve.http_request_latency.bucket,count,,millisecond,,The end-to-end latency of HTTP requests (measured from the Serve HTTP proxy).,0,ray,,
ray.serve.http_request_latency.count,count,,,,The end-to-end latency of HTTP requests (measured from the Serve HTTP proxy).,0,ray,,
ray.serve.http_request_latency.sum,count,,millisecond,,The end-to-end latency of HTTP requests (measured from the Serve HTTP proxy).,0,ray,,
ray.serve.multiplexed_get_model_requests.count,count,,,,The counter for get model requests on the current replica.,0,ray,,
ray.serve.multiplexed_model_load_latency.bucket,count,,millisecond,,The time it takes to load a model.,0,ray,,
ray.serve.multiplexed_model_load_latency.count,count,,,,The time it takes to load a model.,0,ray,,
ray.serve.multiplexed_model_load_latency.sum,count,,millisecond,,The time it takes to load a model.,0,ray,,
ray.serve.multiplexed_model_unload_latency.bucket,count,,millisecond,,The time it takes to unload a model.,0,ray,,
ray.serve.multiplexed_model_unload_latency.count,count,,,,The time it takes to unload a model.,0,ray,,
ray.serve.multiplexed_model_unload_latency.sum,count,,millisecond,,The time it takes to unload a model.,0,ray,,
ray.serve.multiplexed_models_load.count,count,,,,The counter for loaded models on the current replica.,0,ray,,
ray.serve.multiplexed_models_unload.count,count,,,,The counter for unloaded models on the current replica.,0,ray,,
ray.serve.num_deployment_grpc_error_requests,gauge,,,,The number of errored GRPC responses returned by each deployment.,0,ray,,
ray.serve.num_deployment_http_error_requests,gauge,,response,,The number of non-200 HTTP responses returned by each deployment.,0,ray,,
ray.serve.num_grpc_error_requests,gauge,,,,The number of errored GRPC responses.,0,ray,,
ray.serve.num_grpc_requests,gauge,,,,The number of GRPC responses.,0,ray,,
ray.serve.num_http_error_requests,gauge,,response,,The number of non-200 HTTP responses.,0,ray,,
ray.serve.num_http_requests,gauge,,request,,The number of HTTP requests processed.,0,ray,,
ray.serve.num_multiplexed_models,gauge,,,,The number of models loaded on the current replica.,0,ray,,
ray.serve.num_router_requests,gauge,,request,,The number of requests processed by the router.,0,ray,,
ray.serve.registered_multiplexed_model_id,gauge,,,,The model id registered on the current replica.,0,ray,,
ray.serve.replica.pending_queries,gauge,,query,,The current number of pending queries.,0,ray,,
ray.serve.replica.processing_queries,gauge,,query,,The current number of queries being processed.,0,ray,,
ray.server.num_ongoing_grpc_requests,gauge,,,,The number of ongoing requests in this GRPC proxy.,0,ray,,
ray.server.num_ongoing_http_requests,gauge,,,,The number of ongoing requests in this HTTP proxy.,0,ray,,
ray.server.num_scheduling_tasks,gauge,,,,The number of request scheduling tasks in the router.,0,ray,,
ray.server.num_scheduling_tasks_in_backoff,gauge,,,,The number of request scheduling tasks in the router that are undergoing backoff.,0,ray,,
ray.spill_manager.objects,gauge,,object,,"Number of local objects broken per state {Pinned, PendingRestore, PendingSpill}.",0,ray,,
ray.spill_manager.objects_size,gauge,,byte,,"Byte size of local objects broken per state {Pinned, PendingSpill}.",0,ray,,
ray.spill_manager.request_total,gauge,,request,,"Number of {spill, restore} requests.",0,ray,,
ray.tasks,gauge,,task,,Current number of tasks currently in a particular state.,0,ray,,
ray.unintentional_worker_failures.count,count,,error,,"Number of worker failures that are not intentional. For example, worker failures due to system related errors.",0,ray,,
ray.worker.register_time.bucket,count,,millisecond,,End to end latency of register a worker process.,0,ray,,
ray.worker.register_time.count,count,,,,End to end latency of register a worker process.,0,ray,,
ray.worker.register_time.sum,count,,millisecond,,End to end latency of register a worker process.,0,ray,,
