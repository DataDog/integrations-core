## All options defined here are available to all instances.
#
init_config:

    ## @param global_custom_queries - list of mappings - optional
    ## See `custom_queries` defined below.
    ##
    ## Global custom queries can be applied to all instances using the
    ## `use_global_custom_queries` setting at the instance level.
    #
    # global_custom_queries:
    #   - query: <QUERY>
    #     columns: <COLUMNS>
    #     tags: <TAGS>

    ## @param proxy_host - string - optional
    ## The host of your proxy server.
    #
    # proxy_host: <PROXY_HOST>

    ## @param proxy_port - integer - optional
    ## The port of your proxy server.
    #
    # proxy_port: <PROXY_PORT>

    ## @param proxy_user - string - optional
    ## The username to authenticate your proxy server.
    #
    # proxy_user: <PROXY_USER>

    ## @param proxy_password - string - optional
    ## The password to authenticate your proxy server.
    #
    # proxy_password: <PROXY_PASSWORD>

    ## @param service - string - optional
    ## Attach the tag `service:<SERVICE>` to every metric, event, and service check emitted by this integration.
    ##
    ## Additionally, this sets the default `service` for every log source.
    #
    # service: <SERVICE>

## Every instance is scheduled independently of the others.
#
instances:

    ## @param account - string - required
    ## Name of your account (provided by Snowflake), including the platform and region if applicable.
    ## For more information on Snowflake account names,
    ## see https://docs.snowflake.com/en/user-guide/connecting.html#your-snowflake-account-name
    ##
    ## If you are using private connectivity with Snowflake, your account name should be in the following format:
    ##   account: <ACCOUNT>.<REGION_ID>.privatelink
    #
  - account: <ORG_NAME>-<ACCOUNT_NAME>

    ## @param username - string - required
    ## Login name for the user.
    #
    username: <USER>

    ## @param password - string - optional
    ## Password for the user
    #
    # password: <PASSWORD>

    ## @param role - string - required
    ## Name of the role to use.
    ##
    ## By default, the SNOWFLAKE database is only accessible by the ACCOUNTADMIN role. Snowflake recommends
    ## configuring a role specific for monitoring:
    ## https://docs.snowflake.com/en/sql-reference/account-usage.html#enabling-account-usage-for-other-roles
    #
    role: <ROLE>

    ## @param database - string - optional - default: SNOWFLAKE
    ## Name of the default database to use.
    #
    # database: SNOWFLAKE

    ## @param schema - string - optional - default: ACCOUNT_USAGE
    ## Name of the default schema to use for the database.
    ##
    ## To collect organization level metrics, set this to ORGANIZATION_USAGE.
    #
    # schema: ACCOUNT_USAGE

    ## @param warehouse - string - optional
    ## Name of the default warehouse to use.
    #
    # warehouse: <WAREHOUSE>

    ## @param client_prefetch_threads - integer - optional - default: 4
    ## The number of threads used to download the results sets. Increasing the value improves fetch
    ## performance but requires more memory.
    #
    # client_prefetch_threads: 4

    ## @param login_timeout - integer - optional - default: 60
    ## Timeout in seconds for login. The login request gives up after the timeout length if the HTTP response succeeds.
    #
    # login_timeout: 60

    ## @param ocsp_response_cache_filename - string - optional
    ## Path for the OCSP response cache file. By default, the file is created in the cache directory:
    ##   Linux   - ~/.cache/snowflake/ocsp_response_cache
    ##   macOS   - ~/Library/Caches/Snowflake/ocsp_response_cache
    ##   Windows - %USERPROFILE%\AppData\Local\Snowflake\Caches\ocsp_response_cache
    #
    # ocsp_response_cache_filename: <OCSP_RESPONSE_CACHE_FILENAME>

    ## @param authenticator - string - optional - default: snowflake
    ## Authenticator for Snowflake. Supported methods are:
    ## * `snowflake`, the default value, uses the internal Snowflake authenticator. It needs `password` or 
    ##   `private_key_path` option.
    ## * `snowflake_jwt`, uses key pair authentication. It needs `private_key_path` option.
    ## * `oauth`, to authenticate with OAuth method. It needs `token` or `token_path` option.
    #
    # authenticator: <AUTHENTICATOR>

    ## @param token - string - optional
    ## Token used for OAuth connection to Snowflake. You cannot use this alongside `token_path`.
    #
    # token: <TOKEN>

    ## @param token_path - string - optional - default: /path/to/token
    ## Path to the file that contains the token used for OAuth connection to Snowflake.
    ## You cannot use this alongside `token`.
    ## The token is re-read at every check run.
    #
    # token_path: /path/to/token

    ## @param private_key_path - string - optional
    ## The path to the file that contains the private key used to connect to Snowflake.
    ## The key is re-read at every check run.
    #
    # private_key_path: /path/to/private_key

    ## @param private_key_password - string - optional
    ## The password protecting the private key file in the `private_key_path` option.
    #
    # private_key_password: <PRIVATE_KEY_PASSWORD>

    ## @param client_session_keep_alive - boolean - optional - default: false
    ## If set to true, Snowflake keeps the session active indefinitely as long as the connection is active,
    ## even if there is no activity from the user.
    ##
    ## By default, the connection will need to be renewed after four hours of inactivity.
    #
    # client_session_keep_alive: false

    ## @param metric_groups - list of strings - optional
    ## List of Snowflake metric groups to collect. Metric groups are determined by the metric prefixes.
    ##
    ## When querying the ACCOUNT_USAGE schema, the available metric groups are:
    ##
    ##   - snowflake.query (enabled by default)
    ##   - snowflake.billing (enabled by default)
    ##   - snowflake.storage (enabled by default)
    ##   - snowflake.storage.database
    ##   - snowflake.storage.table
    ##   - snowflake.logins (enabled by default)
    ##   - snowflake.data_transfer
    ##   - snowflake.auto_recluster
    ##   - snowflake.pipe
    ##   - snowflake.replication
    ##
    ## When querying the ORGANIZATION_USAGE schema, the available metric groups are:
    ##   - snowflake.organization.warehouse (enabled by default)
    ##   - snowflake.organization.currency (enabled by default)
    ##   - snowflake.organization.credit
    ##   - snowflake.organization.storage (enabled by default)
    ##   - snowflake.organization.contracts
    ##   - snowflake.organization.balance
    ##   - snowflake.organization.rate
    ##   - snowflake.organization.data_transfer
    #
    # metric_groups:
    #   - snowflake.query
    #   - snowflake.billing
    #   - snowflake.storage
    #   - snowflake.logins

    ## @param aggregate_last_24_hours - boolean - optional - default: false
    ## Set to `true` to aggregate table entries on the last 24 hours instead of
    ## aggregating entries of the current day.
    #
    # aggregate_last_24_hours: true

    ## @param only_custom_queries - boolean - optional - default: false
    ## Set this parameter to `true` if you want to skip the integration's default metrics collection.
    ## Only metrics specified in `custom_queries` will be collected.
    #
    # only_custom_queries: false

    ## @param use_global_custom_queries - string - optional - default: true
    ## How `global_custom_queries` should be used for this instance. There are 3 options:
    ##
    ## 1. true - `global_custom_queries` override `custom_queries`.
    ## 2. false - `custom_queries` override `global_custom_queries`.
    ## 3. extend - `global_custom_queries` are used in addition to any `custom_queries`.
    #
    # use_global_custom_queries: 'true'

    ## @param custom_queries - list of mappings - optional
    ## Each query must have 2 fields, and can have a third optional field:
    ##
    ## 1. query - The SQL to execute. It can be a simple statement or a multi-line script.
    ##            Use the pipe `|` if you require a multi-line script.
    ## 2. columns - The list representing each column, ordered sequentially from left to right.
    ##              The number of columns must equal the number of columns returned in the query.
    ##              There are 2 required pieces of data:
    ##                a. name - The suffix to append to `<INTEGRATION>.` to form
    ##                          the full metric name. If `type` is a `tag` type, this column is
    ##                          considered a tag and applied to every
    ##                          metric collected by this particular query.
    ##                b. type - The submission method (gauge, monotonic_count, etc.).
    ##                          This can also be set to the following `tag` types to
    ##                          tag each metric in the row with the name and value
    ##                          of the item in this column:
    ##                           i. tag           - This is the default tag type
    ##                           ii. tag_list     - This allows multiple values to be attached
    ##                                             to the tag name. For example: 
    ##
    ##                                             query = {
    ##                                               "name": "example",
    ##                                               "query": "...",
    ##                                               "columns": [
    ##                                                 {"name": "server_tag", "type": "tag_list"},
    ##                                                 {"name": "foo", "type": "gauge"},
    ##                                               ]
    ##                                             }
    ##
    ##                                             May result in:
    ##                                             gauge("foo", tags=[
    ##                                                                 "server_tag:us",
    ##                                                                 "server_tag:primary",
    ##                                                                 "server_tag:default"
    ##                                                               ])
    ##                                             gauge("foo", tags=["server_tag:eu"])
    ##                                             gauge("foo", tags=["server_tag:eu", "server_tag:primary"])
    ##                           iii. tag_not_null - This only sets tags in the metric if the value is not null
    ##                          You can use the `count` type to perform aggregation
    ##                          for queries that return multiple rows with the same or no tags.
    ##              Columns without a name are ignored. To skip a column, enter:
    ##                - {}
    ## 3. tags (optional) - A list of tags to apply to each metric.
    #
    # custom_queries:
    #   - query: SELECT foo, COUNT(*) FROM table.events GROUP BY foo
    #     columns:
    #     - name: foo
    #       type: tag
    #     - name: event.total
    #       type: gauge
    #     tags:
    #     - test:snowflake

    ## @param tags - list of strings - optional
    ## A list of tags to attach to every metric and service check emitted by this instance.
    ##
    ## Learn more about tagging at https://docs.datadoghq.com/tagging
    #
    # tags:
    #   - <KEY_1>:<VALUE_1>
    #   - <KEY_2>:<VALUE_2>

    ## @param service - string - optional
    ## Attach the tag `service:<SERVICE>` to every metric, event, and service check emitted by this integration.
    ##
    ## Overrides any `service` defined in the `init_config` section.
    #
    # service: <SERVICE>

    ## @param min_collection_interval - number - optional - default: 15
    ## This changes the collection interval of the check. For more information, see:
    ## https://docs.datadoghq.com/developers/write_agent_check/#collection-interval
    ##
    ## NOTE: Most Snowflake ACCOUNT_USAGE views are populated on an hourly basis,
    ## so to minimize unnecessary queries, set the `min_collection_interval` to 1 hour.
    ##
    ## Most metrics are aggregated by day, you can increase the interval to reduce the number of queries.
    #
    min_collection_interval: 3600

    ## @param empty_default_hostname - boolean - optional - default: false
    ## This forces the check to send metrics with no hostname.
    ##
    ## This is useful for cluster-level checks.
    #
    # empty_default_hostname: false

    ## @param disable_generic_tags - boolean - optional - default: false
    ## Generic tags such as `cluster` will be replaced by <integration_name>_cluster to avoid
    ## getting mixed with other integration tags.
    #
    disable_generic_tags: true

    ## @param metric_patterns - mapping - optional
    ## A mapping of metrics to include or exclude, with each entry being a regular expression.
    ##
    ## Metrics defined in `exclude` will take precedence in case of overlap.
    #
    # metric_patterns:
    #   include:
    #   - <INCLUDE_REGEX>
    #   exclude:
    #   - <EXCLUDE_REGEX>
