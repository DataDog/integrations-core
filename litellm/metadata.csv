metric_name,metric_type,interval,unit_name,per_unit_name,description,orientation,integration,short_name,curated_metric,sample_tags
litellm.api.key.budget.remaining_hours.metric,gauge,,hour,,Remaining hours for api key budget to be reset,0,litellm,,,
litellm.api.key.max_budget.metric,gauge,,,,Maximum budget set for api key,0,litellm,,,
litellm.auth.failed_requests.count,count,,error,,Number of failed requests for auth service in the time period,0,litellm,,,
litellm.auth.latency.bucket,count,,,,Number of observations that fall into each upper_bound latency bucket for auth service,0,litellm,,,
litellm.auth.latency.count,count,,,,Number of latency observations for auth service in the time period,0,litellm,,,
litellm.auth.latency.sum,count,,millisecond,,Latency for auth service,0,litellm,,,
litellm.auth.total_requests.count,count,,request,,Number of requests for auth service in the time period,0,litellm,,,
litellm.batch_write_to_db.failed_requests.count,count,,error,,Number of failed requests for batch_write_to_db service in the time period,0,litellm,,,
litellm.batch_write_to_db.latency.bucket,count,,,,Number of observations that fall into each upper_bound latency bucket for batch_write_to_db service,0,litellm,,,
litellm.batch_write_to_db.latency.count,count,,,,Number of latency observations for batch_write_to_db service in the time period,0,litellm,,,
litellm.batch_write_to_db.latency.sum,count,,millisecond,,Latency for batch_write_to_db service,0,litellm,,,
litellm.batch_write_to_db.total_requests.count,count,,request,,Number of requests for batch_write_to_db service in the time period,0,litellm,,,
litellm.deployment.cooled_down.count,count,,event,,Number of times a deployment has been cooled down by LiteLLM load balancing logic in the time period. exception_status is the status of the exception that caused the deployment to be cooled down,0,litellm,,,
litellm.deployment.failed_fallbacks.count,count,,error,,Number of failed fallback requests from primary model -> fallback model in the time period,0,litellm,,,
litellm.deployment.failure_by_tag_responses.count,count,,error,,Number of failed LLM API calls for a specific LLM deployment by custom metadata tags in the time period,0,litellm,,,
litellm.deployment.failure_responses.count,count,,error,,Number of failed LLM API calls for a specific LLM deployment in the time period. exception_status is the status of the exception from the LLM API,0,litellm,,,
litellm.deployment.latency_per_output_token.bucket,count,,,,Number of observations that fall into each upper_bound latency per output token bucket for deployment,0,litellm,,,
litellm.deployment.latency_per_output_token.count,count,,,,Number of latency per output token observations for deployment in the time period,0,litellm,,,
litellm.deployment.latency_per_output_token.sum,count,,millisecond,,Latency per output token,0,litellm,,,
litellm.deployment.state,gauge,,unit,,"The state of the deployment: 0 = healthy,1 = partial outage,2 = complete outage",0,litellm,,,
litellm.deployment.success_responses.count,count,,response,,Number of successful LLM API calls via litellm in the time period,0,litellm,,,
litellm.deployment.successful_fallbacks.count,count,,response,,Number of successful fallback requests from primary model -> fallback model in the time period,0,litellm,,,
litellm.deployment.total_requests.count,count,,request,,Number of LLM API calls via litellm in the time period - success + failure,0,litellm,,,
litellm.in_memory.daily_spend_update_queue.size,gauge,,item,,Gauge for in_memory_daily_spend_update_queue service,0,litellm,,,
litellm.in_memory.spend_update_queue.size,gauge,,item,,Gauge for in_memory_spend_update_queue service,0,litellm,,,
litellm.input.tokens.count,count,,token,,Number of input tokens from LLM requests in the time period,0,litellm,,,
litellm.llm.api.failed_requests.metric.count,count,,error,,Deprecated - use litellm.proxy.failed_requests.metric. Number of failed responses from proxy in the time period - the client did not get a success response from litellm proxy,0,litellm,,,
litellm.llm.api.latency.metric.bucket,count,,,,Number of observations that fall into each upper_bound latency bucket (seconds) for a model's LLM API call,0,litellm,,,
litellm.llm.api.latency.metric.count,count,,,,Number of latency observations (seconds) for a model's LLM API call in the time period,0,litellm,,,
litellm.llm.api.latency.metric.sum,count,,second,,Total latency (seconds) for a model's LLM API call,0,litellm,,,
litellm.llm.api.time_to_first_token.metric.bucket,count,,,,Number of observations that fall into each upper_bound time to first token bucket for a model's LLM API call,0,litellm,,,
litellm.llm.api.time_to_first_token.metric.count,count,,,,Number of time to first token observations for a model's LLM API call in the time period,0,litellm,,,
litellm.llm.api.time_to_first_token.metric.sum,count,,second,,Time to first token for a model's LLM API call,0,litellm,,,
litellm.output.tokens.count,count,,token,,Number of output tokens from LLM requests in the time period,0,litellm,,,
litellm.overhead_latency.metric.bucket,count,,,,Number of observations that fall into each upper_bound overhead latency bucket (milliseconds) added by LiteLLM processing,0,litellm,,,
litellm.overhead_latency.metric.count,count,,,,Number of overhead latency observations (milliseconds) added by LiteLLM processing in the time period,0,litellm,,,
litellm.overhead_latency.metric.sum,count,,millisecond,,Latency overhead (milliseconds) added by LiteLLM processing,0,litellm,,,
litellm.pod_lock_manager.size,gauge,,item,,Gauge for pod_lock_manager service,0,litellm,,,
litellm.postgres.failed_requests.count,count,,error,,Number of failed requests for Postgres service in the time period,0,litellm,,,
litellm.postgres.latency.bucket,count,,,,Number of observations that fall into each upper_bound latency bucket for Postgres service,0,litellm,,,
litellm.postgres.latency.count,count,,,,Number of latency observations for Postgres service in the time period,0,litellm,,,
litellm.postgres.latency.sum,count,,millisecond,,Latency for Postgres service,0,litellm,,,
litellm.postgres.total_requests.count,count,,request,,Number of requests for Postgres service in the time period,0,litellm,,,
litellm.process.uptime.seconds,gauge,,second,,Start time of the process since unix epoch in seconds.,0,litellm,,,
litellm.provider.remaining_budget.metric,gauge,,,,Remaining budget for provider - used when you set provider budget limits,0,litellm,,,
litellm.proxy.failed_requests.metric.count,count,,error,,Number of failed responses from proxy in the time period - the client did not get a success response from litellm proxy,0,litellm,,,
litellm.proxy.pre_call.failed_requests.count,count,,error,,Number of failed requests for proxy_pre_call service in the time period,0,litellm,,,
litellm.proxy.pre_call.latency.bucket,count,,,,Number of observations that fall into each upper_bound latency bucket for proxy_pre_call service,0,litellm,,,
litellm.proxy.pre_call.latency.count,count,,,,Number of latency observations for proxy_pre_call service in the time period,0,litellm,,,
litellm.proxy.pre_call.latency.sum,count,,millisecond,,Latency for proxy_pre_call service,0,litellm,,,
litellm.proxy.pre_call.total_requests.count,count,,request,,Number of requests for proxy_pre_call service in the time period,0,litellm,,,
litellm.proxy.total_requests.metric.count,count,,request,,Number of requests made to the proxy server in the time period - track number of client side requests,0,litellm,,,
litellm.redis.daily_spend_update_queue.size,gauge,,item,,Gauge for redis_daily_spend_update_queue service,0,litellm,,,
litellm.redis.daily_tag_spend_update_queue.failed_requests.count,count,,error,,Number of failed requests for redis_daily_tag_spend_update_queue service in the time period,0,litellm,,,
litellm.redis.daily_tag_spend_update_queue.latency.bucket,count,,,,Number of observations that fall into each upper_bound latency bucket for redis_daily_tag_spend_update_queue service,0,litellm,,,
litellm.redis.daily_tag_spend_update_queue.latency.count,count,,,,Number of latency observations for redis_daily_tag_spend_update_queue service in the time period,0,litellm,,,
litellm.redis.daily_tag_spend_update_queue.latency.sum,count,,millisecond,,Latency for redis_daily_tag_spend_update_queue service,0,litellm,,,
litellm.redis.daily_tag_spend_update_queue.total_requests.count,count,,request,,Number of requests for redis_daily_tag_spend_update_queue service in the time period,0,litellm,,,
litellm.redis.daily_team_spend_update_queue.failed_requests.count,count,,error,,Number of failed requests for redis_daily_team_spend_update_queue service in the time period,0,litellm,,,
litellm.redis.daily_team_spend_update_queue.latency.bucket,count,,,,Number of observations that fall into each upper_bound latency bucket for redis_daily_team_spend_update_queue service,0,litellm,,,
litellm.redis.daily_team_spend_update_queue.latency.count,count,,,,Number of latency observations for redis_daily_team_spend_update_queue service in the time period,0,litellm,,,
litellm.redis.daily_team_spend_update_queue.latency.sum,count,,millisecond,,Latency for redis_daily_team_spend_update_queue service,0,litellm,,,
litellm.redis.daily_team_spend_update_queue.total_requests.count,count,,request,,Number of requests for redis_daily_team_spend_update_queue service in the time period,0,litellm,,,
litellm.redis.failed_requests.count,count,,error,,Number of failed requests for Redis service in the time period,0,litellm,,,
litellm.redis.latency.bucket,count,,,,Number of observations that fall into each upper_bound latency bucket for Redis service,0,litellm,,,
litellm.redis.latency.count,count,,,,Number of latency observations for Redis service in the time period,0,litellm,,,
litellm.redis.latency.sum,count,,millisecond,,Total latency (milliseconds) for Redis service,0,litellm,,,
litellm.redis.spend_update_queue.size,gauge,,item,,Gauge for redis_spend_update_queue service,0,litellm,,,
litellm.redis.total_requests.count,count,,request,,Number of requests for Redis service in the time period,0,litellm,,,
litellm.remaining.api_key.budget.metric,gauge,,,,Remaining budget for api key,0,litellm,,,
litellm.remaining.api_key.requests_for_model,gauge,,request,,Remaining requests API Key can make for model (model based rpm limit on key),0,litellm,,,
litellm.remaining.api_key.tokens_for_model,gauge,,token,,Remaining tokens API Key can make for model (model based tpm limit on key),0,litellm,,,
litellm.remaining.requests,gauge,,request,,"Remaining requests for model, returned from LLM API Provider",0,litellm,,,
litellm.remaining.team_budget.metric,gauge,,,,Remaining budget for team,0,litellm,,,
litellm.remaining_requests.metric,gauge,,request,,Track x-ratelimit-remaining-requests returned from LLM API Deployment,0,litellm,,,
litellm.remaining_tokens,gauge,,token,,"Remaining tokens for model, returned from LLM API Provider",0,litellm,,,
litellm.request.total_latency.metric.bucket,count,,,,Number of observations that fall into each upper_bound total latency bucket (seconds) for a request to LiteLLM,0,litellm,,,
litellm.request.total_latency.metric.count,count,,,,Number of total latency observations (seconds) for a request to LiteLLM in the time period,0,litellm,,,
litellm.request.total_latency.metric.sum,count,,second,,Total latency (seconds) for a request to LiteLLM,0,litellm,,,
litellm.requests.metric.count,count,,request,,"Deprecated - use litellm.proxy.total_requests.metric.count. Number of LLM calls to litellm in the time period - track total per API Key, team, user",0,litellm,,,
litellm.reset_budget_job.failed_requests.count,count,,error,,Number of failed requests for reset_budget_job service in the time period,0,litellm,,,
litellm.reset_budget_job.latency.bucket,count,,,,Latency for reset_budget_job service,0,litellm,,,
litellm.reset_budget_job.total_requests.count,count,,request,,Number of requests for reset_budget_job service in the time period,0,litellm,,,
litellm.router.failed_requests.count,count,,error,,Number of failed requests for router service in the time period,0,litellm,,,
litellm.router.latency.bucket,count,,,,Number of observations that fall into each upper_bound latency bucket for router service,0,litellm,,,
litellm.router.latency.count,count,,,,Number of latency observations for router service in the time period,0,litellm,,,
litellm.router.latency.sum,count,,millisecond,,Latency for router service,0,litellm,,,
litellm.router.total_requests.count,count,,request,,Number of requests for router service in the time period,0,litellm,,,
litellm.self.failed_requests.count,count,,error,,Number of failed requests for self service in the time period,0,litellm,,,
litellm.self.latency.bucket,count,,,,Number of observations that fall into each upper_bound latency bucket for self service,0,litellm,,,
litellm.self.latency.count,count,,,,Number of latency observations for self service in the time period,0,litellm,,,
litellm.self.latency.sum,count,,millisecond,,Latency for self service,0,litellm,,,
litellm.self.total_requests.count,count,,request,,Number of requests for self service in the time period,0,litellm,,,
litellm.spend.metric.count,count,,,,Spend on LLM requests in the time period,0,litellm,,,
litellm.team.budget.remaining_hours.metric,gauge,,hour,,Remaining hours for team budget to be reset,0,litellm,,,
litellm.team.max_budget.metric,gauge,,,,Maximum budget set for team,0,litellm,,,
litellm.total.tokens.count,count,,token,,Number of input + output tokens from LLM requests in the time period,0,litellm,,,
