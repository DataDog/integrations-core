# HELP python_gc_objects_collected_total Objects collected during gc
# TYPE python_gc_objects_collected_total counter
python_gc_objects_collected_total{generation="0"} 4.313161e+06
python_gc_objects_collected_total{generation="1"} 565116.0
python_gc_objects_collected_total{generation="2"} 19342.0
# HELP python_gc_objects_uncollectable_total Uncollectable objects found during GC
# TYPE python_gc_objects_uncollectable_total counter
python_gc_objects_uncollectable_total{generation="0"} 0.0
python_gc_objects_uncollectable_total{generation="1"} 0.0
python_gc_objects_uncollectable_total{generation="2"} 0.0
# HELP python_gc_collections_total Number of times this generation was collected
# TYPE python_gc_collections_total counter
python_gc_collections_total{generation="0"} 5458.0
python_gc_collections_total{generation="1"} 496.0
python_gc_collections_total{generation="2"} 9.0
# HELP python_info Python platform information
# TYPE python_info gauge
python_info{implementation="CPython",major="3",minor="13",patchlevel="3",version="3.13.3"} 1.0
# HELP process_virtual_memory_bytes Virtual memory size in bytes.
# TYPE process_virtual_memory_bytes gauge
process_virtual_memory_bytes 8.34048e+08
# HELP process_resident_memory_bytes Resident memory size in bytes.
# TYPE process_resident_memory_bytes gauge
process_resident_memory_bytes 4.32541696e+08
# HELP process_start_time_seconds Start time of the process since unix epoch in seconds.
# TYPE process_start_time_seconds gauge
process_start_time_seconds 1.74906289901e+09
# HELP process_cpu_seconds_total Total user and system CPU time spent in seconds.
# TYPE process_cpu_seconds_total counter
process_cpu_seconds_total 562.71
# HELP process_open_fds Number of open file descriptors.
# TYPE process_open_fds gauge
process_open_fds 22.0
# HELP process_max_fds Maximum number of open file descriptors.
# TYPE process_max_fds gauge
process_max_fds 1.048576e+06
# HELP litellm_redis_latency Latency for redis service
# TYPE litellm_redis_latency histogram
# HELP litellm_redis_failed_requests_total Total failed_requests for redis service
# TYPE litellm_redis_failed_requests_total counter
# HELP litellm_redis_total_requests_total Total total_requests for redis service
# TYPE litellm_redis_total_requests_total counter
# HELP litellm_postgres_latency Latency for postgres service
# TYPE litellm_postgres_latency histogram
litellm_postgres_latency_bucket{le="0.005",postgres="postgres"} 43160.0
litellm_postgres_latency_bucket{le="0.00625",postgres="postgres"} 45050.0
litellm_postgres_latency_bucket{le="0.0125",postgres="postgres"} 45842.0
litellm_postgres_latency_bucket{le="0.025",postgres="postgres"} 46054.0
litellm_postgres_latency_bucket{le="0.05",postgres="postgres"} 46121.0
litellm_postgres_latency_bucket{le="0.1",postgres="postgres"} 46131.0
litellm_postgres_latency_bucket{le="0.5",postgres="postgres"} 46132.0
litellm_postgres_latency_bucket{le="1.0",postgres="postgres"} 46132.0
litellm_postgres_latency_bucket{le="1.5",postgres="postgres"} 46132.0
litellm_postgres_latency_bucket{le="2.0",postgres="postgres"} 46132.0
litellm_postgres_latency_bucket{le="2.5",postgres="postgres"} 46132.0
litellm_postgres_latency_bucket{le="3.0",postgres="postgres"} 46132.0
litellm_postgres_latency_bucket{le="3.5",postgres="postgres"} 46132.0
litellm_postgres_latency_bucket{le="4.0",postgres="postgres"} 46132.0
litellm_postgres_latency_bucket{le="4.5",postgres="postgres"} 46132.0
litellm_postgres_latency_bucket{le="5.0",postgres="postgres"} 46132.0
litellm_postgres_latency_bucket{le="5.5",postgres="postgres"} 46132.0
litellm_postgres_latency_bucket{le="6.0",postgres="postgres"} 46132.0
litellm_postgres_latency_bucket{le="6.5",postgres="postgres"} 46132.0
litellm_postgres_latency_bucket{le="7.0",postgres="postgres"} 46132.0
litellm_postgres_latency_bucket{le="7.5",postgres="postgres"} 46132.0
litellm_postgres_latency_bucket{le="8.0",postgres="postgres"} 46132.0
litellm_postgres_latency_bucket{le="8.5",postgres="postgres"} 46132.0
litellm_postgres_latency_bucket{le="9.0",postgres="postgres"} 46132.0
litellm_postgres_latency_bucket{le="9.5",postgres="postgres"} 46132.0
litellm_postgres_latency_bucket{le="10.0",postgres="postgres"} 46132.0
litellm_postgres_latency_bucket{le="15.0",postgres="postgres"} 46132.0
litellm_postgres_latency_bucket{le="20.0",postgres="postgres"} 46132.0
litellm_postgres_latency_bucket{le="25.0",postgres="postgres"} 46132.0
litellm_postgres_latency_bucket{le="30.0",postgres="postgres"} 46132.0
litellm_postgres_latency_bucket{le="60.0",postgres="postgres"} 46132.0
litellm_postgres_latency_bucket{le="120.0",postgres="postgres"} 46132.0
litellm_postgres_latency_bucket{le="180.0",postgres="postgres"} 46132.0
litellm_postgres_latency_bucket{le="240.0",postgres="postgres"} 46132.0
litellm_postgres_latency_bucket{le="300.0",postgres="postgres"} 46132.0
litellm_postgres_latency_bucket{le="+Inf",postgres="postgres"} 46132.0
litellm_postgres_latency_count{postgres="postgres"} 46132.0
litellm_postgres_latency_sum{postgres="postgres"} 141.5365270000006
# HELP litellm_postgres_latency_created Latency for postgres service
# TYPE litellm_postgres_latency_created gauge
litellm_postgres_latency_created{postgres="postgres"} 1.7490629065396974e+09
# HELP litellm_postgres_failed_requests_total Total failed_requests for postgres service
# TYPE litellm_postgres_failed_requests_total counter
# HELP litellm_postgres_total_requests_total Total total_requests for postgres service
# TYPE litellm_postgres_total_requests_total counter
litellm_postgres_total_requests_total{postgres="postgres"} 46132.0
# HELP litellm_postgres_total_requests_created Total total_requests for postgres service
# TYPE litellm_postgres_total_requests_created gauge
litellm_postgres_total_requests_created{postgres="postgres"} 1.7490629065397623e+09
# HELP litellm_batch_write_to_db_latency Latency for batch_write_to_db service
# TYPE litellm_batch_write_to_db_latency histogram
# HELP litellm_batch_write_to_db_failed_requests_total Total failed_requests for batch_write_to_db service
# TYPE litellm_batch_write_to_db_failed_requests_total counter
# HELP litellm_batch_write_to_db_total_requests_total Total total_requests for batch_write_to_db service
# TYPE litellm_batch_write_to_db_total_requests_total counter
# HELP litellm_reset_budget_job_latency Latency for reset_budget_job service
# TYPE litellm_reset_budget_job_latency histogram
litellm_reset_budget_job_latency_bucket{le="0.005",reset_budget_job="reset_budget_job"} 2030.0
litellm_reset_budget_job_latency_bucket{le="0.00625",reset_budget_job="reset_budget_job"} 2158.0
litellm_reset_budget_job_latency_bucket{le="0.0125",reset_budget_job="reset_budget_job"} 2555.0
litellm_reset_budget_job_latency_bucket{le="0.025",reset_budget_job="reset_budget_job"} 2632.0
litellm_reset_budget_job_latency_bucket{le="0.05",reset_budget_job="reset_budget_job"} 2663.0
litellm_reset_budget_job_latency_bucket{le="0.1",reset_budget_job="reset_budget_job"} 2664.0
litellm_reset_budget_job_latency_bucket{le="0.5",reset_budget_job="reset_budget_job"} 2664.0
litellm_reset_budget_job_latency_bucket{le="1.0",reset_budget_job="reset_budget_job"} 2664.0
litellm_reset_budget_job_latency_bucket{le="1.5",reset_budget_job="reset_budget_job"} 2664.0
litellm_reset_budget_job_latency_bucket{le="2.0",reset_budget_job="reset_budget_job"} 2664.0
litellm_reset_budget_job_latency_bucket{le="2.5",reset_budget_job="reset_budget_job"} 2664.0
litellm_reset_budget_job_latency_bucket{le="3.0",reset_budget_job="reset_budget_job"} 2664.0
litellm_reset_budget_job_latency_bucket{le="3.5",reset_budget_job="reset_budget_job"} 2664.0
litellm_reset_budget_job_latency_bucket{le="4.0",reset_budget_job="reset_budget_job"} 2664.0
litellm_reset_budget_job_latency_bucket{le="4.5",reset_budget_job="reset_budget_job"} 2664.0
litellm_reset_budget_job_latency_bucket{le="5.0",reset_budget_job="reset_budget_job"} 2664.0
litellm_reset_budget_job_latency_bucket{le="5.5",reset_budget_job="reset_budget_job"} 2664.0
litellm_reset_budget_job_latency_bucket{le="6.0",reset_budget_job="reset_budget_job"} 2664.0
litellm_reset_budget_job_latency_bucket{le="6.5",reset_budget_job="reset_budget_job"} 2664.0
litellm_reset_budget_job_latency_bucket{le="7.0",reset_budget_job="reset_budget_job"} 2664.0
litellm_reset_budget_job_latency_bucket{le="7.5",reset_budget_job="reset_budget_job"} 2664.0
litellm_reset_budget_job_latency_bucket{le="8.0",reset_budget_job="reset_budget_job"} 2664.0
litellm_reset_budget_job_latency_bucket{le="8.5",reset_budget_job="reset_budget_job"} 2664.0
litellm_reset_budget_job_latency_bucket{le="9.0",reset_budget_job="reset_budget_job"} 2664.0
litellm_reset_budget_job_latency_bucket{le="9.5",reset_budget_job="reset_budget_job"} 2664.0
litellm_reset_budget_job_latency_bucket{le="10.0",reset_budget_job="reset_budget_job"} 2664.0
litellm_reset_budget_job_latency_bucket{le="15.0",reset_budget_job="reset_budget_job"} 2664.0
litellm_reset_budget_job_latency_bucket{le="20.0",reset_budget_job="reset_budget_job"} 2664.0
litellm_reset_budget_job_latency_bucket{le="25.0",reset_budget_job="reset_budget_job"} 2664.0
litellm_reset_budget_job_latency_bucket{le="30.0",reset_budget_job="reset_budget_job"} 2664.0
litellm_reset_budget_job_latency_bucket{le="60.0",reset_budget_job="reset_budget_job"} 2664.0
litellm_reset_budget_job_latency_bucket{le="120.0",reset_budget_job="reset_budget_job"} 2664.0
litellm_reset_budget_job_latency_bucket{le="180.0",reset_budget_job="reset_budget_job"} 2664.0
litellm_reset_budget_job_latency_bucket{le="240.0",reset_budget_job="reset_budget_job"} 2664.0
litellm_reset_budget_job_latency_bucket{le="300.0",reset_budget_job="reset_budget_job"} 2664.0
litellm_reset_budget_job_latency_bucket{le="+Inf",reset_budget_job="reset_budget_job"} 2664.0
litellm_reset_budget_job_latency_count{reset_budget_job="reset_budget_job"} 2664.0
litellm_reset_budget_job_latency_sum{reset_budget_job="reset_budget_job"} 11.089456558227539
# HELP litellm_reset_budget_job_latency_created Latency for reset_budget_job service
# TYPE litellm_reset_budget_job_latency_created gauge
litellm_reset_budget_job_latency_created{reset_budget_job="reset_budget_job"} 1.7490629675290077e+09
# HELP litellm_reset_budget_job_failed_requests_total Total failed_requests for reset_budget_job service
# TYPE litellm_reset_budget_job_failed_requests_total counter
# HELP litellm_reset_budget_job_total_requests_total Total total_requests for reset_budget_job service
# TYPE litellm_reset_budget_job_total_requests_total counter
litellm_reset_budget_job_total_requests_total{reset_budget_job="reset_budget_job"} 2664.0
# HELP litellm_reset_budget_job_total_requests_created Total total_requests for reset_budget_job service
# TYPE litellm_reset_budget_job_total_requests_created gauge
litellm_reset_budget_job_total_requests_created{reset_budget_job="reset_budget_job"} 1.749062967529171e+09
# HELP litellm_self_latency Latency for self service
# TYPE litellm_self_latency histogram
# HELP litellm_self_failed_requests_total Total failed_requests for self service
# TYPE litellm_self_failed_requests_total counter
# HELP litellm_self_total_requests_total Total total_requests for self service
# TYPE litellm_self_total_requests_total counter
# HELP litellm_router_latency Latency for router service
# TYPE litellm_router_latency histogram
# HELP litellm_router_failed_requests_total Total failed_requests for router service
# TYPE litellm_router_failed_requests_total counter
# HELP litellm_router_total_requests_total Total total_requests for router service
# TYPE litellm_router_total_requests_total counter
# HELP litellm_auth_latency Latency for auth service
# TYPE litellm_auth_latency histogram
litellm_auth_latency_bucket{auth="auth",le="0.005"} 4.0
litellm_auth_latency_bucket{auth="auth",le="0.00625"} 4.0
litellm_auth_latency_bucket{auth="auth",le="0.0125"} 4.0
litellm_auth_latency_bucket{auth="auth",le="0.025"} 4.0
litellm_auth_latency_bucket{auth="auth",le="0.05"} 4.0
litellm_auth_latency_bucket{auth="auth",le="0.1"} 4.0
litellm_auth_latency_bucket{auth="auth",le="0.5"} 4.0
litellm_auth_latency_bucket{auth="auth",le="1.0"} 4.0
litellm_auth_latency_bucket{auth="auth",le="1.5"} 4.0
litellm_auth_latency_bucket{auth="auth",le="2.0"} 4.0
litellm_auth_latency_bucket{auth="auth",le="2.5"} 4.0
litellm_auth_latency_bucket{auth="auth",le="3.0"} 4.0
litellm_auth_latency_bucket{auth="auth",le="3.5"} 4.0
litellm_auth_latency_bucket{auth="auth",le="4.0"} 4.0
litellm_auth_latency_bucket{auth="auth",le="4.5"} 4.0
litellm_auth_latency_bucket{auth="auth",le="5.0"} 4.0
litellm_auth_latency_bucket{auth="auth",le="5.5"} 4.0
litellm_auth_latency_bucket{auth="auth",le="6.0"} 4.0
litellm_auth_latency_bucket{auth="auth",le="6.5"} 4.0
litellm_auth_latency_bucket{auth="auth",le="7.0"} 4.0
litellm_auth_latency_bucket{auth="auth",le="7.5"} 4.0
litellm_auth_latency_bucket{auth="auth",le="8.0"} 4.0
litellm_auth_latency_bucket{auth="auth",le="8.5"} 4.0
litellm_auth_latency_bucket{auth="auth",le="9.0"} 4.0
litellm_auth_latency_bucket{auth="auth",le="9.5"} 4.0
litellm_auth_latency_bucket{auth="auth",le="10.0"} 4.0
litellm_auth_latency_bucket{auth="auth",le="15.0"} 4.0
litellm_auth_latency_bucket{auth="auth",le="20.0"} 4.0
litellm_auth_latency_bucket{auth="auth",le="25.0"} 4.0
litellm_auth_latency_bucket{auth="auth",le="30.0"} 4.0
litellm_auth_latency_bucket{auth="auth",le="60.0"} 4.0
litellm_auth_latency_bucket{auth="auth",le="120.0"} 4.0
litellm_auth_latency_bucket{auth="auth",le="180.0"} 4.0
litellm_auth_latency_bucket{auth="auth",le="240.0"} 4.0
litellm_auth_latency_bucket{auth="auth",le="300.0"} 4.0
litellm_auth_latency_bucket{auth="auth",le="+Inf"} 4.0
litellm_auth_latency_count{auth="auth"} 4.0
litellm_auth_latency_sum{auth="auth"} 0.0009918212890625
# HELP litellm_auth_latency_created Latency for auth service
# TYPE litellm_auth_latency_created gauge
litellm_auth_latency_created{auth="auth"} 1.7490630796924577e+09
# HELP litellm_auth_failed_requests_total Total failed_requests for auth service
# TYPE litellm_auth_failed_requests_total counter
# HELP litellm_auth_total_requests_total Total total_requests for auth service
# TYPE litellm_auth_total_requests_total counter
litellm_auth_total_requests_total{auth="auth"} 4.0
# HELP litellm_auth_total_requests_created Total total_requests for auth service
# TYPE litellm_auth_total_requests_created gauge
litellm_auth_total_requests_created{auth="auth"} 1.7490630796924982e+09
# HELP litellm_proxy_pre_call_latency Latency for proxy_pre_call service
# TYPE litellm_proxy_pre_call_latency histogram
# HELP litellm_proxy_pre_call_failed_requests_total Total failed_requests for proxy_pre_call service
# TYPE litellm_proxy_pre_call_failed_requests_total counter
# HELP litellm_proxy_pre_call_total_requests_total Total total_requests for proxy_pre_call service
# TYPE litellm_proxy_pre_call_total_requests_total counter
# HELP litellm_pod_lock_manager_size Gauge for pod_lock_manager service
# TYPE litellm_pod_lock_manager_size gauge
# HELP litellm_in_memory_daily_spend_update_queue_size Gauge for in_memory_daily_spend_update_queue service
# TYPE litellm_in_memory_daily_spend_update_queue_size gauge
# HELP litellm_redis_daily_spend_update_queue_size Gauge for redis_daily_spend_update_queue service
# TYPE litellm_redis_daily_spend_update_queue_size gauge
# HELP litellm_redis_daily_team_spend_update_queue_latency Latency for redis_daily_team_spend_update_queue service
# TYPE litellm_redis_daily_team_spend_update_queue_latency histogram
# HELP litellm_redis_daily_team_spend_update_queue_failed_requests_total Total failed_requests for redis_daily_team_spend_update_queue service
# TYPE litellm_redis_daily_team_spend_update_queue_failed_requests_total counter
# HELP litellm_redis_daily_team_spend_update_queue_total_requests_total Total total_requests for redis_daily_team_spend_update_queue service
# TYPE litellm_redis_daily_team_spend_update_queue_total_requests_total counter
# HELP litellm_redis_daily_tag_spend_update_queue_latency Latency for redis_daily_tag_spend_update_queue service
# TYPE litellm_redis_daily_tag_spend_update_queue_latency histogram
# HELP litellm_redis_daily_tag_spend_update_queue_failed_requests_total Total failed_requests for redis_daily_tag_spend_update_queue service
# TYPE litellm_redis_daily_tag_spend_update_queue_failed_requests_total counter
# HELP litellm_redis_daily_tag_spend_update_queue_total_requests_total Total total_requests for redis_daily_tag_spend_update_queue service
# TYPE litellm_redis_daily_tag_spend_update_queue_total_requests_total counter
# HELP litellm_in_memory_spend_update_queue_size Gauge for in_memory_spend_update_queue service
# TYPE litellm_in_memory_spend_update_queue_size gauge
# HELP litellm_redis_spend_update_queue_size Gauge for redis_spend_update_queue service
# TYPE litellm_redis_spend_update_queue_size gauge
# HELP litellm_proxy_failed_requests_metric_total Total number of failed responses from proxy - the client did not get a success response from litellm proxy
# TYPE litellm_proxy_failed_requests_metric_total counter
litellm_proxy_failed_requests_metric_total{api_key_alias="None",end_user="None",exception_class="Exception",exception_status="None",hashed_api_key="",requested_model="",route="/metrics/",team="None",team_alias="None",user="None"} 6850.0
# HELP litellm_proxy_failed_requests_metric_created Total number of failed responses from proxy - the client did not get a success response from litellm proxy
# TYPE litellm_proxy_failed_requests_metric_created gauge
litellm_proxy_failed_requests_metric_created{api_key_alias="None",end_user="None",exception_class="Exception",exception_status="None",hashed_api_key="",requested_model="",route="/metrics/",team="None",team_alias="None",user="None"} 1.7490629142629414e+09
# HELP litellm_proxy_total_requests_metric_total Total number of requests made to the proxy server - track number of client side requests
# TYPE litellm_proxy_total_requests_metric_total counter
litellm_proxy_total_requests_metric_total{api_key_alias="None",end_user="None",hashed_api_key="",requested_model="",route="/metrics/",status_code="None",team="None",team_alias="None",user="None",user_email="None"} 6850.0
# HELP litellm_proxy_total_requests_metric_created Total number of requests made to the proxy server - track number of client side requests
# TYPE litellm_proxy_total_requests_metric_created gauge
litellm_proxy_total_requests_metric_created{api_key_alias="None",end_user="None",hashed_api_key="",requested_model="",route="/metrics/",status_code="None",team="None",team_alias="None",user="None",user_email="None"} 1.7490629142629857e+09
# HELP litellm_request_total_latency_metric Total latency (seconds) for a request to LiteLLM
# TYPE litellm_request_total_latency_metric histogram
# HELP litellm_llm_api_latency_metric Total latency (seconds) for a models LLM API call
# TYPE litellm_llm_api_latency_metric histogram
# HELP litellm_llm_api_time_to_first_token_metric Time to first token for a models LLM API call
# TYPE litellm_llm_api_time_to_first_token_metric histogram
# HELP litellm_spend_metric_total Total spend on LLM requests
# TYPE litellm_spend_metric_total counter
# HELP litellm_total_tokens_total Total number of input + output tokens from LLM requests
# TYPE litellm_total_tokens_total counter
# HELP litellm_input_tokens_total Total number of input tokens from LLM requests
# TYPE litellm_input_tokens_total counter
# HELP litellm_output_tokens_total Total number of output tokens from LLM requests
# TYPE litellm_output_tokens_total counter
# HELP litellm_remaining_team_budget_metric Remaining budget for team
# TYPE litellm_remaining_team_budget_metric gauge
# HELP litellm_team_max_budget_metric Maximum budget set for team
# TYPE litellm_team_max_budget_metric gauge
# HELP litellm_team_budget_remaining_hours_metric Remaining days for team budget to be reset
# TYPE litellm_team_budget_remaining_hours_metric gauge
# HELP litellm_remaining_api_key_budget_metric Remaining budget for api key
# TYPE litellm_remaining_api_key_budget_metric gauge
# HELP litellm_api_key_max_budget_metric Maximum budget set for api key
# TYPE litellm_api_key_max_budget_metric gauge
# HELP litellm_api_key_budget_remaining_hours_metric Remaining hours for api key budget to be reset
# TYPE litellm_api_key_budget_remaining_hours_metric gauge
# HELP litellm_remaining_api_key_requests_for_model Remaining Requests API Key can make for model (model based rpm limit on key)
# TYPE litellm_remaining_api_key_requests_for_model gauge
# HELP litellm_remaining_api_key_tokens_for_model Remaining Tokens API Key can make for model (model based tpm limit on key)
# TYPE litellm_remaining_api_key_tokens_for_model gauge
# HELP litellm_remaining_requests LLM Deployment Analytics - remaining requests for model, returned from LLM API Provider
# TYPE litellm_remaining_requests gauge
# HELP litellm_remaining_tokens remaining tokens for model, returned from LLM API Provider
# TYPE litellm_remaining_tokens gauge
# HELP litellm_overhead_latency_metric Latency overhead (milliseconds) added by LiteLLM processing
# TYPE litellm_overhead_latency_metric histogram
# HELP litellm_provider_remaining_budget_metric Remaining budget for provider - used when you set provider budget limits
# TYPE litellm_provider_remaining_budget_metric gauge
# HELP litellm_deployment_state LLM Deployment Analytics - The state of the deployment: 0 = healthy, 1 = partial outage, 2 = complete outage
# TYPE litellm_deployment_state gauge
litellm_deployment_state{api_base="",api_provider="None",litellm_model_name="",model_id=""} 1.0
# HELP litellm_deployment_cooled_down_total LLM Deployment Analytics - Number of times a deployment has been cooled down by LiteLLM load balancing logic. exception_status is the status of the exception that caused the deployment to be cooled down
# TYPE litellm_deployment_cooled_down_total counter
# HELP litellm_deployment_success_responses_total LLM Deployment Analytics - Total number of successful LLM API calls via litellm
# TYPE litellm_deployment_success_responses_total counter
# HELP litellm_deployment_failure_responses_total LLM Deployment Analytics - Total number of failed LLM API calls for a specific LLM deploymeny. exception_status is the status of the exception from the llm api
# TYPE litellm_deployment_failure_responses_total counter
litellm_deployment_failure_responses_total{api_base="",api_key_alias="None",api_provider="None",exception_class="Exception",exception_status="None",hashed_api_key="",litellm_model_name="",model_id="",requested_model="",team="None",team_alias="None"} 6850.0
# HELP litellm_deployment_failure_responses_created LLM Deployment Analytics - Total number of failed LLM API calls for a specific LLM deploymeny. exception_status is the status of the exception from the llm api
# TYPE litellm_deployment_failure_responses_created gauge
litellm_deployment_failure_responses_created{api_base="",api_key_alias="None",api_provider="None",exception_class="Exception",exception_status="None",hashed_api_key="",litellm_model_name="",model_id="",requested_model="",team="None",team_alias="None"} 1.749062914261377e+09
# HELP litellm_deployment_failure_by_tag_responses_total Total number of failed LLM API calls for a specific LLM deploymeny by custom metadata tags
# TYPE litellm_deployment_failure_by_tag_responses_total counter
# HELP litellm_deployment_total_requests_total LLM Deployment Analytics - Total number of LLM API calls via litellm - success + failure
# TYPE litellm_deployment_total_requests_total counter
litellm_deployment_total_requests_total{api_base="",api_key_alias="None",api_provider="None",hashed_api_key="",litellm_model_name="",model_id="",requested_model="",team="None",team_alias="None"} 6850.0
# HELP litellm_deployment_total_requests_created LLM Deployment Analytics - Total number of LLM API calls via litellm - success + failure
# TYPE litellm_deployment_total_requests_created gauge
litellm_deployment_total_requests_created{api_base="",api_key_alias="None",api_provider="None",hashed_api_key="",litellm_model_name="",model_id="",requested_model="",team="None",team_alias="None"} 1.7490629142613935e+09
# HELP litellm_deployment_latency_per_output_token LLM Deployment Analytics - Latency per output token
# TYPE litellm_deployment_latency_per_output_token histogram
# HELP litellm_deployment_successful_fallbacks_total LLM Deployment Analytics - Number of successful fallback requests from primary model -> fallback model
# TYPE litellm_deployment_successful_fallbacks_total counter
# HELP litellm_deployment_failed_fallbacks_total LLM Deployment Analytics - Number of failed fallback requests from primary model -> fallback model
# TYPE litellm_deployment_failed_fallbacks_total counter
# HELP litellm_llm_api_failed_requests_metric_total deprecated - use litellm_proxy_failed_requests_metric
# TYPE litellm_llm_api_failed_requests_metric_total counter
litellm_llm_api_failed_requests_metric_total{api_key_alias="None",end_user="None",hashed_api_key="",model="",team="None",team_alias="None",user="None"} 6850.0
# HELP litellm_llm_api_failed_requests_metric_created deprecated - use litellm_proxy_failed_requests_metric
# TYPE litellm_llm_api_failed_requests_metric_created gauge
litellm_llm_api_failed_requests_metric_created{api_key_alias="None",end_user="None",hashed_api_key="",model="",team="None",team_alias="None",user="None"} 1.7490629142612934e+09
# HELP litellm_requests_metric_total deprecated - use litellm_proxy_total_requests_metric. Total number of LLM calls to litellm - track total per API Key, team, user
# TYPE litellm_requests_metric_total counter