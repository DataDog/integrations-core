## Every instance is scheduled independent of the others.
#
instances:

    ## @param gitlab_url - string - required
    ## The master URL to probe for service health status
    ## If you are using gitlab CE and not EE, use this URL with
    ## the authorization token: http://localhost/?token=<TOKEN>
    #
  - gitlab_url: <GITLAB_URL>

    ## @param api_token - string - optional
    ## The Gitlab API token for this instance
    ## used to collect the Gitlab version.
    #
    # api_token: <API_TOKEN>

    ## @param prometheus_url - string - required
    ## The URL where your application metrics are exposed by Prometheus.
    #
    prometheus_url: http://<GITLAB_URL>/-/metrics

    ## @param prometheus_metrics_prefix - string - optional
    ## <PREFIX> for exposed Prometheus metrics.
    #
    # prometheus_metrics_prefix: <PREFIX>_

    ## @param health_service_check - boolean - optional - default: true
    ## Send a service check reporting about the health of the Prometheus endpoint.
    ## The service check is named <NAMESPACE>.prometheus.health
    #
    # health_service_check: true

    ## @param label_to_hostname - string - optional
    ## Override the hostname with the value of one label.
    #
    # label_to_hostname: <LABEL>

    ## @param label_joins - mapping - optional
    ## The label join allows to target a metric and retrieve it's label with a 1:1 mapping.
    #
    # label_joins:
    #   target_metric:
    #     label_to_match: <MATCHED_LABEL>
    #     labels_to_get:
    #     - <EXTRA_LABEL_1>
    #     - <EXTRA_LABEL_2>

    ## @param labels_mapper - mapping - optional
    ## The label mapper allows you to rename labels.
    ## Format is <LABEL_TO_RENAME>: <NEW_LABEL_NAME>
    #
    # labels_mapper:
    #   flavor: origin

    ## @param type_overrides - mapping - optional
    ## Override a type in the Prometheus payload or type an untyped metric (they're ignored by default).
    ## Supported <METRIC_TYPE> are `gauge`, `counter`, `histogram`, and `summary`.
    ## The "*" wildcard can be used to match multiple metric names.
    #
    # type_overrides:
    #   <METRIC_NAME>: <METRIC_TYPE>

    ## @param send_histograms_buckets - boolean - optional - default: true
    ## Set send_histograms_buckets to true to send the histograms bucket.
    #
    # send_histograms_buckets: true

    ## @param send_distribution_buckets - boolean - optional - default: false
    ## Set `send_distribution_buckets` to `true` to send histograms as Datadog distribution metrics.
    ##
    ## Learn more about distribution metrics: https://docs.datadoghq.com/developers/metrics/distributions/
    #
    # send_distribution_buckets: false

    ## @param send_monotonic_counter - boolean - optional - default: true
    ## Set send_monotonic_counter to true to send counters as monotonic counter.
    #
    send_monotonic_counter: true

    ## @param send_distribution_counts_as_monotonic - boolean - optional - default: true
    ## Set send_distribution_counts_as_monotonic to true to send histograms and summary
    ## counters as monotonic counters (instead of gauges).
    #
    send_distribution_counts_as_monotonic: true

    ## @param send_distribution_sums_as_monotonic - boolean - optional - default: false
    ## Set send_distribution_sums_as_monotonic to true to send histograms and summary
    ## sum as monotonic counters (instead of gauges).
    #
    # send_distribution_sums_as_monotonic: false

    ## @param exclude_labels - list of strings - optional
    ## List of labels to be excluded
    #
    # exclude_labels:
    #   - timestamp

    ## @param bearer_token_auth - boolean - optional - default: false
    ## Set bearer_token_auth to true to add bearer token authentication header.
    ## Note: if bearer_token_path is not set, the default path is /var/run/secrets/kubernetes.io/serviceaccount/token.
    #
    # bearer_token_auth: false

    ## @param bearer_token_path - string - optional
    ## The path to a Kubernetes service account bearer token file. Make sure the file exists and is mounted correctly.
    ## Note: bearer_token_auth should be set to true to enable adding the token to HTTP headers for authentication.
    #
    # bearer_token_path: <TOKEN_PATH>

    ## @param ignore_metrics - list of strings - optional
    ## List of metrics to be ignored, the "*" wildcard can be used to match multiple metric names.
    #
    # ignore_metrics:
    #   - <IGNORED_METRIC_NAME>
    #   - <PREFIX_*>
    #   - <*_SUFFIX>
    #   - <PREFIX_*_SUFFIX>
    #   - <*_SUBSTRING_*>

    ## @param proxy - mapping - optional
    ## This overrides the `proxy` setting in `init_config`.
    ##
    ## Set HTTP or HTTPS proxies for all instances. Use the `no_proxy` list
    ## to specify hosts that must bypass proxies.
    ##
    ## The SOCKS protocol is also supported, for example:
    ##
    ##   socks5://user:pass@host:port
    ##
    ## Using the scheme `socks5` causes the DNS resolution to happen on the
    ## client, rather than on the proxy server. This is in line with `curl`,
    ## which uses the scheme to decide whether to do the DNS resolution on
    ## the client or proxy. If you want to resolve the domains on the proxy
    ## server, use `socks5h` as the scheme.
    #
    # proxy:
    #   http: http://<PROXY_SERVER_FOR_HTTP>:<PORT>
    #   https: https://<PROXY_SERVER_FOR_HTTPS>:<PORT>
    #   no_proxy:
    #   - <HOSTNAME_1>
    #   - <HOSTNAME_2>

    ## @param skip_proxy - boolean - optional - default: false
    ## This overrides the `skip_proxy` setting in `init_config`.
    ##
    ## If set to `true`, this makes the check bypass any proxy
    ## settings enabled and attempt to reach services directly.
    #
    # skip_proxy: false

    ## @param auth_type - string - optional - default: basic
    ## The type of authentication to use. The available types (and related options) are:
    ##
    ##   - basic
    ##     |__ username
    ##     |__ password
    ##   - digest
    ##     |__ username
    ##     |__ password
    ##   - ntlm
    ##     |__ ntlm_domain
    ##     |__ password
    ##   - kerberos
    ##     |__ kerberos_auth
    ##     |__ kerberos_cache
    ##     |__ kerberos_delegate
    ##     |__ kerberos_force_initiate
    ##     |__ kerberos_hostname
    ##     |__ kerberos_keytab
    ##     |__ kerberos_principal
    ##   - aws
    ##     |__ aws_region
    ##     |__ aws_host
    ##     |__ aws_service
    ##
    ## The `aws` auth type relies on boto3 to automatically gather AWS credentials (e.g. from `.aws/credentials`).
    ## Details: https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html#configuring-credentials
    #
    # auth_type: basic

    ## @param username - string - optional
    ## The username to use if services are behind basic or digest auth.
    #
    # username: <USERNAME>

    ## @param password - string - optional
    ## The password to use if services are behind basic or NTLM auth.
    #
    # password: <PASSWORD>

    ## @param ntlm_domain - string - optional
    ## If your services use NTLM authentication, you can specify
    ## a domain that is used in the check. For NTLM Auth, append
    ## the username to domain, not as the `username` parameter.
    #
    # ntlm_domain: <NTLM_DOMAIN>\<USERNAME>

    ## @param kerberos_auth - string - optional - default: disabled
    ## If your services use Kerberos authentication, you can specify the Kerberos
    ## strategy to use between:
    ##
    ##   - required
    ##   - optional
    ##   - disabled
    ##
    ## See https://github.com/requests/requests-kerberos#mutual-authentication
    #
    # kerberos_auth: disabled

    ## @param kerberos_cache - string - optional
    ## Sets the KRB5CCNAME environment variable.
    ## It should point to a credential cache with a valid TGT.
    #
    # kerberos_cache: <KERBEROS_CACHE>

    ## @param kerberos_delegate - boolean - optional - default: false
    ## Set to `true` to enable Kerberos delegation of credentials to a server that requests delegation.
    ##
    ## See https://github.com/requests/requests-kerberos#delegation
    #
    # kerberos_delegate: false

    ## @param kerberos_force_initiate - boolean - optional - default: false
    ## Set to `true` to preemptively initiate the Kerberos GSS exchange and
    ## present a Kerberos ticket on the initial request (and all subsequent).
    ##
    ## See https://github.com/requests/requests-kerberos#preemptive-authentication
    #
    # kerberos_force_initiate: false

    ## @param kerberos_hostname - string - optional
    ## Override the hostname used for the Kerberos GSS exchange if its DNS name doesn't
    ## match its Kerberos hostname (e.g. behind a content switch or load balancer).
    ##
    ## See https://github.com/requests/requests-kerberos#hostname-override
    #
    # kerberos_hostname: <KERBEROS_HOSTNAME>

    ## @param kerberos_principal - string - optional
    ## Set an explicit principal, to force Kerberos to look for a
    ## matching credential cache for the named user.
    ##
    ## See https://github.com/requests/requests-kerberos#explicit-principal
    #
    # kerberos_principal: <KERBEROS_PRINCIPAL>

    ## @param kerberos_keytab - string - optional
    ## Set the path to your Kerberos key tab file.
    #
    # kerberos_keytab: <KEYTAB_FILE_PATH>

    ## @param aws_region - string - optional
    ## If your services require AWS Signature Version 4 signing, set the region.
    ##
    ## See https://docs.aws.amazon.com/general/latest/gr/signature-version-4.html
    #
    # aws_region: <AWS_REGION>

    ## @param aws_host - string - optional
    ## If your services require AWS Signature Version 4 signing, set the host.
    ##
    ## Note: This setting is not necessary for official integrations.
    ##
    ## See https://docs.aws.amazon.com/general/latest/gr/signature-version-4.html
    #
    # aws_host: <AWS_HOST>

    ## @param aws_service - string - optional
    ## If your services require AWS Signature Version 4 signing, set the service code. For a list
    ## of available service codes, see https://docs.aws.amazon.com/general/latest/gr/rande.html
    ##
    ## Note: This setting is not necessary for official integrations.
    ##
    ## See https://docs.aws.amazon.com/general/latest/gr/signature-version-4.html
    #
    # aws_service: <AWS_SERVICE>

    ## @param tls_verify - boolean - optional - default: true
    ## Instructs the check to validate the TLS certificate of services.
    #
    # tls_verify: true

    ## @param tls_use_host_header - boolean - optional - default: false
    ## If a `Host` header is set, this enables its use for SNI (matching against the TLS certificate CN or SAN).
    #
    # tls_use_host_header: false

    ## @param tls_ignore_warning - boolean - optional - default: false
    ## If `tls_verify` is disabled, security warnings are logged by the check.
    ## Disable those by setting `tls_ignore_warning` to true.
    ##
    ## Note: `tls_ignore_warning` set to true is currently only reliable if used by one instance of one integration.
    ## If enabled for multiple instances, spurious warnings might still appear even if `tls_ignore_warning` is set
    ## to true.
    #
    # tls_ignore_warning: false

    ## @param tls_cert - string - optional
    ## The path to a single file in PEM format containing a certificate as well as any
    ## number of CA certificates needed to establish the certificate's authenticity for
    ## use when connecting to services. It may also contain an unencrypted private key to use.
    #
    # tls_cert: <CERT_PATH>

    ## @param tls_private_key - string - optional
    ## The unencrypted private key to use for `tls_cert` when connecting to services. This is
    ## required if `tls_cert` is set and it does not already contain a private key.
    #
    # tls_private_key: <PRIVATE_KEY_PATH>

    ## @param tls_ca_cert - string - optional
    ## The path to a file of concatenated CA certificates in PEM format or a directory
    ## containing several CA certificates in PEM format. If a directory, the directory
    ## must have been processed using the c_rehash utility supplied with OpenSSL. See:
    ## https://www.openssl.org/docs/manmaster/man3/SSL_CTX_load_verify_locations.html
    #
    # tls_ca_cert: <CA_CERT_PATH>

    ## @param headers - mapping - optional
    ## The headers parameter allows you to send specific headers with every request.
    ## You can use it for explicitly specifying the host header or adding headers for
    ## authorization purposes.
    ##
    ## This overrides any default headers.
    #
    # headers:
    #   Host: <ALTERNATIVE_HOSTNAME>
    #   X-Auth-Token: <AUTH_TOKEN>

    ## @param extra_headers - mapping - optional
    ## Additional headers to send with every request.
    #
    # extra_headers:
    #   Host: <ALTERNATIVE_HOSTNAME>
    #   X-Auth-Token: <AUTH_TOKEN>

    ## @param timeout - number - optional - default: 10
    ## The timeout for accessing services.
    ##
    ## This overrides the `timeout` setting in `init_config`.
    #
    # timeout: 10

    ## @param connect_timeout - number - optional
    ## The connect timeout for accessing services. Defaults to `timeout`.
    #
    # connect_timeout: <CONNECT_TIMEOUT>

    ## @param read_timeout - number - optional
    ## The read timeout for accessing services. Defaults to `timeout`.
    #
    # read_timeout: <READ_TIMEOUT>

    ## @param log_requests - boolean - optional - default: false
    ## Whether or not to debug log the HTTP(S) requests made, including the method and URL.
    #
    # log_requests: false

    ## @param persist_connections - boolean - optional - default: false
    ## Whether or not to persist cookies and use connection pooling for increased performance.
    #
    # persist_connections: false

    ## @param tags - list of strings - optional
    ## A list of tags to attach to every metric and service check emitted by this instance.
    ##
    ## Learn more about tagging at https://docs.datadoghq.com/tagging
    #
    # tags:
    #   - <KEY_1>:<VALUE_1>
    #   - <KEY_2>:<VALUE_2>

    ## @param service - string - optional
    ## Attach the tag `service:<SERVICE>` to every metric, event, and service check emitted by this integration.
    ##
    ## Overrides any `service` defined in the `init_config` section.
    #
    # service: <SERVICE>

    ## @param min_collection_interval - number - optional - default: 15
    ## This changes the collection interval of the check. For more information, see:
    ## https://docs.datadoghq.com/developers/write_agent_check/#collection-interval
    #
    # min_collection_interval: 15

    ## @param empty_default_hostname - boolean - optional - default: false
    ## This forces the check to send metrics with no hostname.
    ##
    ## This is useful for cluster-level checks.
    #
    # empty_default_hostname: false

## All options defined here are available to all instances.
#
init_config:

    ## @param proxy - mapping - optional
    ## Set HTTP or HTTPS proxies for all instances. Use the `no_proxy` list
    ## to specify hosts that must bypass proxies.
    ##
    ## The SOCKS protocol is also supported like so:
    ##
    ##   socks5://user:pass@host:port
    ##
    ## Using the scheme `socks5` causes the DNS resolution to happen on the
    ## client, rather than on the proxy server. This is in line with `curl`,
    ## which uses the scheme to decide whether to do the DNS resolution on
    ## the client or proxy. If you want to resolve the domains on the proxy
    ## server, use `socks5h` as the scheme.
    #
    # proxy:
    #   http: http://<PROXY_SERVER_FOR_HTTP>:<PORT>
    #   https: https://<PROXY_SERVER_FOR_HTTPS>:<PORT>
    #   no_proxy:
    #   - <HOSTNAME_1>
    #   - <HOSTNAME_2>

    ## @param skip_proxy - boolean - optional - default: false
    ## If set to `true`, this makes the check bypass any proxy
    ## settings enabled and attempt to reach services directly.
    #
    # skip_proxy: false

    ## @param timeout - number - optional - default: 10
    ## The timeout for connecting to services.
    #
    # timeout: 10

    ## @param service - string - optional
    ## Attach the tag `service:<SERVICE>` to every metric, event, and service check emitted by this integration.
    ##
    ## Additionally, this sets the default `service` for every log source.
    #
    # service: <SERVICE>

    ## @param allowed_metrics - list of strings - optional
    ## The list of legacy metrics to extract from Prometheus.
    #
    # allowed_metrics:
    #   - go_gc_duration_seconds
    #   - go_gc_duration_seconds_sum
    #   - go_gc_duration_seconds_count
    #   - go_goroutines
    #   - go_memstats_alloc_bytes
    #   - go_memstats_alloc_bytes_total
    #   - go_memstats_buck_hash_sys_bytes
    #   - go_memstats_frees_total
    #   - go_memstats_gc_cpu_fraction
    #   - go_memstats_gc_sys_bytes
    #   - go_memstats_heap_alloc_bytes
    #   - go_memstats_heap_idle_bytes
    #   - go_memstats_heap_inuse_bytes
    #   - go_memstats_heap_objects
    #   - go_memstats_heap_released_bytes_total
    #   - go_memstats_heap_sys_bytes
    #   - go_memstats_last_gc_time_seconds
    #   - go_memstats_lookups_total
    #   - go_memstats_mallocs_total
    #   - go_memstats_mcache_inuse_bytes
    #   - go_memstats_mcache_sys_bytes
    #   - go_memstats_mspan_inuse_bytes
    #   - go_memstats_mspan_sys_bytes
    #   - go_memstats_next_gc_bytes
    #   - go_memstats_other_sys_bytes
    #   - go_memstats_stack_inuse_bytes
    #   - go_memstats_stack_inuse_bytes
    #   - go_memstats_stack_sys_bytes
    #   - go_memstats_sys_bytes
    #   - go_threads
    #   - http_request_duration_microseconds
    #   - http_request_size_bytes
    #   - http_requests_total
    #   - http_response_size_bytes
    #   - process_cpu_seconds_total
    #   - process_max_fds
    #   - process_open_fds
    #   - process_resident_memory_bytes
    #   - process_start_time_seconds
    #   - process_virtual_memory_bytes
    #   - prometheus_build_info
    #   - prometheus_config_last_reload_success_timestamp_seconds
    #   - prometheus_config_last_reload_successful
    #   - prometheus_engine_queries
    #   - prometheus_engine_queries_concurrent_max
    #   - prometheus_engine_query_duration_seconds
    #   - prometheus_evaluator_duration_seconds
    #   - prometheus_evaluator_iterations_missed_total
    #   - prometheus_evaluator_iterations_skipped_total
    #   - prometheus_evaluator_iterations_total
    #   - prometheus_local_storage_checkpoint_duration_seconds
    #   - prometheus_local_storage_checkpoint_last_duration_seconds
    #   - prometheus_local_storage_checkpoint_last_size_bytes
    #   - prometheus_local_storage_checkpoint_series_chunks_written
    #   - prometheus_local_storage_checkpointing
    #   - prometheus_local_storage_chunk_ops_total
    #   - prometheus_local_storage_chunks_to_persist
    #   - prometheus_local_storage_fingerprint_mappings_total
    #   - prometheus_local_storage_inconsistencies_total
    #   - prometheus_local_storage_indexing_batch_duration_seconds
    #   - prometheus_local_storage_indexing_batch_sizes
    #   - prometheus_local_storage_indexing_queue_capacity
    #   - prometheus_local_storage_indexing_queue_length
    #   - prometheus_local_storage_ingested_samples_total
    #   - prometheus_local_storage_maintain_series_duration_seconds
    #   - prometheus_local_storage_memory_chunkdescs
    #   - prometheus_local_storage_memory_chunks
    #   - prometheus_local_storage_memory_dirty_series
    #   - prometheus_local_storage_memory_series
    #   - prometheus_local_storage_non_existent_series_matches_total
    #   - prometheus_local_storage_open_head_chunks
    #   - prometheus_local_storage_out_of_order_samples_total
    #   - prometheus_local_storage_persist_errors_total
    #   - prometheus_local_storage_persistence_urgency_score
    #   - prometheus_local_storage_queued_chunks_to_persist_total
    #   - prometheus_local_storage_rushed_mode
    #   - prometheus_local_storage_series_chunks_persisted
    #   - prometheus_local_storage_series_ops_total
    #   - prometheus_local_storage_started_dirty
    #   - prometheus_local_storage_target_heap_size_bytes
    #   - prometheus_notifications_alertmanagers_discovered
    #   - prometheus_notifications_dropped_total
    #   - prometheus_notifications_queue_capacity
    #   - prometheus_notifications_queue_length
    #   - prometheus_rule_evaluation_failures_total
    #   - prometheus_sd_azure_refresh_duration_seconds
    #   - prometheus_sd_azure_refresh_failures_total
    #   - prometheus_sd_consul_rpc_duration_seconds
    #   - prometheus_sd_consul_rpc_failures_total
    #   - prometheus_sd_dns_lookup_failures_total
    #   - prometheus_sd_dns_lookups_total
    #   - prometheus_sd_ec2_refresh_duration_seconds
    #   - prometheus_sd_ec2_refresh_failures_total
    #   - prometheus_sd_file_read_errors_total
    #   - prometheus_sd_file_scan_duration_seconds
    #   - prometheus_sd_gce_refresh_duration
    #   - prometheus_sd_gce_refresh_failures_total
    #   - prometheus_sd_kubernetes_events_total
    #   - prometheus_sd_marathon_refresh_duration_seconds
    #   - prometheus_sd_marathon_refresh_failures_total
    #   - prometheus_sd_openstack_refresh_duration_seconds
    #   - prometheus_sd_openstack_refresh_failures_total
    #   - prometheus_sd_triton_refresh_duration_seconds
    #   - prometheus_sd_triton_refresh_failures_total
    #   - prometheus_target_interval_length_seconds
    #   - prometheus_target_scrape_pool_sync_total
    #   - prometheus_target_scrapes_exceeded_sample_limit_total
    #   - prometheus_target_skipped_scrapes_total
    #   - prometheus_target_sync_length_seconds
    #   - prometheus_treecache_watcher_goroutines
    #   - prometheus_treecache_zookeeper_failures_total

## Log Section
##
## type - required - Type of log input source (tcp / udp / file / windows_event)
## port / path / channel_path - required - Set port if type is tcp or udp.
##                                         Set path if type is file.
##                                         Set channel_path if type is windows_event.
## source  - required - Attribute that defines which Integration sent the logs.
## service - optional - The name of the service that generates the log.
##                      Overrides any `service` defined in the `init_config` section.
## tags - optional - Add tags to the collected logs.
##
## Discover Datadog log collection: https://docs.datadoghq.com/logs/log_collection/
#
# logs:
#   - type: file
#     path: /var/log/gitlab/gitlab-rails/production_json.log
#     service: <SERVICE_NAME>
#     source: gitlab
#   - type: file
#     path: /var/log/gitlab/gitlab-rails/integrations_json.log
#     service: <SERVICE_NAME>
#     source: gitlab
#   - type: file
#     path: /var/log/gitlab/gitlab-rails/production.log
#     service: <SERVICE_NAME>
#     source: gitlab
#     log_processing_rules:
#     - type: multi_line
#       pattern: Started [A-Z]+ "[^"]+" for
#       name: new_log_start_pattern
#   - type: file
#     path: /var/log/gitlab/gitlab-rails/api_json.log
#     service: <SERVICE_NAME>
#     source: gitlab
#   - type: file
#     path: /var/log/gitlab/gitlab-rails/application.log
#     service: <SERVICE_NAME>
#     source: gitlab
#   - type: file
#     path: /var/log/gitlab/gitlab-rails/integrations_json.log
#     service: <SERVICE_NAME>
#     source: gitlab
#   - type: file
#     path: /var/log/gitlab/gitlab-rails/kubernetes.log
#     service: <SERVICE_NAME>
#     source: gitlab
#   - type: file
#     path: /var/log/gitlab/gitlab-rails/audit_json.log
#     service: <SERVICE_NAME>
#     source: gitlab
#   - type: file
#     path: /var/log/gitlab/gitlab-rails/sidekiq.log
#     service: <SERVICE_NAME>
#     source: gitlab
#   - type: file
#     path: /var/log/gitlab/gitlab-rails/gitlab-shell.log
#     service: <SERVICE_NAME>
#     source: gitlab
#   - type: file
#     path: /var/log/gitlab/gitlab-shell/gitlab-shell.log
#     service: <SERVICE_NAME>
#     source: gitlab
#   - type: file
#     path: /var/log/gitlab/gitlab-rails/unicorn_stderr.log
#     service: <SERVICE_NAME>
#     source: gitlab
#   - type: file
#     path: /var/log/gitlab/gitlab-rails/graphql_json.log
#     service: <SERVICE_NAME>
#     source: gitlab
#   - type: file
#     path: /var/log/gitlab/gitlab-rails/sidekiq_exporter.log
#     service: <SERVICE_NAME>
#     source: gitlab
#     log_processing_rules:
#     - type: multi_line
#       pattern: Started [A-Z]+ "[^"]+" for
#       name: new_log_start_pattern
#   - type: file
#     path: /var/log/gitlab/gitaly/current
#     service: <SERVICE_NAME>
#     source: gitlab
#   - type: file
#     path: /var/log/gitlab/alertmanager/current
#     service: <SERVICE_NAME>
#     source: gitlab
#   - type: file
#     path: /var/log/gitlab/gitlab-workhorse/current
#     service: <SERVICE_NAME>
#     source: gitlab
#   - type: file
#     path: /var/log/gitlab/postgres-exporter/current
#     service: <SERVICE_NAME>
#     source: gitlab
#   - type: file
#     path: /var/log/gitlab/prometheus/current
#     service: <SERVICE_NAME>
#     source: gitlab
#   - type: file
#     path: /var/log/gitlab/redis-exporter/current
#     service: <SERVICE_NAME>
#     source: gitlab
#   - type: file
#     path: /var/log/gitlab/unicorn/*.log
#     service: <SERVICE_NAME>
#     source: gitlab
#   - type: file
#     path: /var/log/gitlab/nginx/*.log
#     service: <SERVICE_NAME>
#     source: nginx
